[
  {
    "id": "A1",
    "question": "Vertex AIを使って、アップロードされた画像から有名な絵画を認識するアプリケーションを開発しました。\nこのアプリケーションをテストするために、24時間後に特定の人が画像をアップロードできるようにしたい。すべてのユーザーがGoogleアカウントを持っているわけではありません。\nどのようにしてユーザーに画像をアップロードさせるべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "アプリケーションにOAuth認証を追加し、ユーザーにGoogleアカウントでログインさせる"
      },
      {
        "id": "B",
        "text": "Cloud Storageバケットに公開アクセスを許可し、誰でもアップロードできるようにする"
      },
      {
        "id": "C",
        "text": "24時間後に有効期限が切れる署名付きのURLを使って、ユーザーに画像をCloud Storageにアップロードさせる"
      },
      {
        "id": "D",
        "text": "Cloud Functionsを使って、ユーザーのアップロード要求ごとに個別の認証トークンを発行する"
      }
    ],
    "answer": ["C"],
    "explanation": "### 全体的な説明\n今回のケースのようにシナリオによっては、クラウド ストレージにアクセスするためにユーザーに Google アカウントを要求したくない場合があります。\n\n署名付きURLはクエリ文字列に認証情報を含んでおり、認証情報を持たないユーザーがリソースに対して特定のアクションを実行できるようにします。\n\nしたがって正解は以下の通りです。\n\n> \"24時間後に有効期限が切れる署名付きのURLを使って、ユーザーに画像をCloud Storageにアップロードさせる\"\n\n📚 参考リンク:\nhttps://cloud.google.com/storage/docs/access-control/signed-urls"
  },
  {
    "id": "A2",
    "question": "ある組織では、Google Cloud Platform上の同じネットワークに3つの層のWebアプリケーションを展開しています。各層（ウェブ、API、データベース）は、他の層とは独立してスケールします。ネットワークトラフィックは、Web を通して API 層に流れ、さらにデータベース層に流れます。ウェブ層とデータベース層の間にはトラフィックは流れてはいけません。\n\nネットワークはどのように構成すればよいのでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "各層にタグを追加し、目的のトラフィックフローを可能にするルートを設定する"
      },
      {
        "id": "B",
        "text": "各階層を別のサブネットワークに追加する"
      },
      {
        "id": "C",
        "text": "個々のVMにソフトウェアベースのファイアウォールを設定する"
      },
      {
        "id": "D",
        "text": "各階層にタグを追加し、目的のトラフィックフローを許可するファイアウォールルールを設定する"
      }
    ],
    "answer": ["D"],
    "explanation": "### 全体的な説明\nGoogle Cloud Platform(GCP)は、ルールとタグによってファイアウォールルールを適用します。\n\nファイアウォールルールによって、各層のトラフィックを制御することが可能になります。\n\nまた、GCPのルールとタグは一度定義すれば、すべてのリージョンで使用することができます。\n\nしたがって正解は以下の通りです。\n\n> \"各階層にタグを追加し、目的のトラフィックフローを許可するファイアウォールルールを設定する\"\n\n📚 参考リンク:\n- https://cloud.google.com/docs/compare/openstack/\n- https://cloud.google.com/solutions/best-practices-vpc-design"
  },
  {
    "id": "A3",
    "question": "オンプレミスのソリューションをいくつかのフェーズに分けてGoogle Cloudに移行しています。移行が完了するまでの間、Cloud VPN を使用してオンプレミス システムと Google Cloud との接続を維持します。この期間中、すべてのオンプレミスシステムにアクセスできることを確認したいと思います。\n\nGoogle Cloudではどのようにネットワークを構築すればよいのでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "プライマリIPレンジにはオンプレミスと同じGoogle Cloud上のIPレンジを使用し、セカンダリIPレンジにはオンプレミスで使用しているレンジと重複しないものを使用する。"
      },
      {
        "id": "B",
        "text": "オンプレミスで使用しているのと同じIPレンジをGoogle Cloudで使用する"
      },
      {
        "id": "C",
        "text": "プライマリIP範囲にオンプレミスで使用している範囲と重複しないGoogle Cloud上のIP範囲を使用し、セカンダリ範囲にオンプレミスで使用している範囲と同じIP範囲を使用する。"
      },
      {
        "id": "D",
        "text": "オンプレミスで使用している範囲と重複しないGoogle Cloud上のIP範囲を使用する。"
      }
    ],
    "answer": ["D"],
    "explanation": "### 全体的な説明\nVPCネットワークと他のネットワークをCloud VPN、専用Interconnect、パートナーInterconnectで接続している場合、プライマリとセカンダリの範囲はオンプレミスのIP範囲と競合させることができません。\n\nしたがって正解は以下の通りです。\n\n> \"オンプレミスで使用している範囲と重複しないGoogle Cloud上のIP範囲を使用する\"\n\n📚 参考リンク:\nhttps://cloud.google.com/vpc/docs/using-vpc"
  },
  {
    "id": "A4",
    "question": "あなたは、データ分析を行うデータウェアハウスチームで働いています。このチームは、外部パートナーからのデータを処理する必要がありますが、そのデータには個人を特定できる情報（PII）が含まれています。あなたは、PIIデータを一切保存することなく、データを処理して保存する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "外部パートナーに、すべてのデータをCloud Storageにアップロードするよう依頼する。バケットにBucket Lockを設定する。バケットからデータを読み込むためのDataflowパイプラインを作成する。パイプラインの一部として、Cloud Data Loss Prevention（クラウドDLP）APIを使用して、PIIデータを削除する。結果を BigQuery に保存する。"
      },
      {
        "id": "B",
        "text": "外部パートナーに、BigQuery データセットのすべてのデータをインポートするよう依頼する。Dataflow パイプラインを作成して、データを新しいテーブルにコピーする。Dataflowのバケットの一部として、PII データを持つ列のすべてのデータをスキップする。"
      },
      {
        "id": "C",
        "text": "Dataflow パイプラインを作成して、外部ソースからデータを取得する。パイプラインの一部として、すべての非PIIデータをBigQueryに保存し、すべてのPIIデータを保持ポリシーが設定されているCloud Storageのバケットに保存する。"
      },
      {
        "id": "D",
        "text": "外部ソースからデータを取得するためのDataflowパイプラインを作成する。パイプラインの一部として、Cloud Data Loss Prevention（クラウドDLP）APIを使用して、PIIデータを削除する。結果をBigQueryに保存する。"
      }
    ],
    "answer": ["D"],
    "explanation": "### 全体的な説明\n機密データを適正に処理するにあたって第一歩となるのは、データ ワークロードのどこに機密データがあるかを把握することです。\n\nこれは、データの厳重な保護に役立つだけでなく、機密情報の管理ミスが深刻なコスト増につながる今日の規制環境のもとでは不可欠な要素となっています。\n\nDLP API は、クレジットカード番号、社会保障番号、氏名のような個人識別情報（PII）などの機密データを識別するのに役立つツールです。\n\n機密データの在りかがわかったら、リダクションやマスキング、トークン化などのテクニックを使って機密データを特定できないようにしなければなりませんが、DLP API はそのための機能を提供します。\n\nこうした機能は、機密データを分析や顧客サポートなどの重要な業務に活用しつつ、同時に保護することに役立ちます。\n\nしかも、DLP API はクラウドかオンプレミスかを問わず、ほぼあらゆるワークロードで使えるように設計されているため、API にデータを渡して機密データの検出や非特定化の機能を利用するのは簡単です。\n\nしたがって正解は以下の通りです。\n\n> \"外部ソースからデータを取得するためのDataflowパイプラインを作成する。パイプラインの一部として、Cloud Data Loss Prevention（クラウドDLP）APIを使用して、PIIデータを削除する。結果をBigQueryに保存する\"\n\n📚 参考リンク:\n- https://cloud.google.com/blog/ja/products/gcp/take-charge-of-your-sensitive-data-with-the-cloud-dlp-api\n- https://cloud.google.com/solutions/pci-dss-compliance-in-gcp#using_data_loss_prevention_api_to_sanitize_data"
  },
  {
    "id": "A5",
    "question": "あなたは現在、90日以上前のバックアップファイルを、バックアップ用Cloud Storageのバケットから削除するソリューションを作成しています。Cloud Storageにかかる費用を最適化したい。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "JSONでライフサイクル管理ルールを書いて、gsutilでバケットにプッシュする"
      },
      {
        "id": "B",
        "text": "ライフサイクルマネジメントのルールをXMLで記述し、それをgsutilでバケットにプッシュする"
      },
      {
        "id": "C",
        "text": "gsutil ls -l gs://backups/** を使って、cronスクリプトをスケジュールし、90日よりも古いアイテムを見つけて削除する。"
      },
      {
        "id": "D",
        "text": "gsutil ls -lr gs://backups/**を使って、cronスクリプトをスケジュールし、90日よりも古いアイテムを見つけて削除する。"
      }
    ],
    "answer": ["A"],
    "explanation": "### 全体的な説明\nライフサイクル管理ルールをJSONで入力し、それをgsutilを使ってBucketにプッシュする PUT APIからのコールリクエスト（\\\"gsutil lifecycle\\\" のコマンド）を使って、既存のBucketにライフサイクルセットアップを設定することができます。\n\nライフサイクル設定を含むリクエストボディには、JSONドキュメントを含める必要があります。\n\n以下のJSONの例は、90日以上経過したオブジェクトを削除するライフサイクル設定ルールです。\n\n```json\n{\n    \\\"lifecycle\\\" : {\n        \\\"rule\\\" : [\n            {\n                \\\"action\\\": {\n                    \\\"type\\\": \\\"Delete\\\"\n                },\n                \\\"condition\\\": {\n                    \\\"age\\\": 90\n                }\n            }\n        ]\n    }\n}\n```\n\nこの設定によって、オブジェクトの保存期間が90日を経過した場合、定期的な処理のためのCronジョブを使用して、それらを削除することができます。\n\nなお、バージョンアップしたオブジェクトをリストアップするには、`gsutil ls -lr gs://backups/**` が必要です。バージョンアップしたアーカイブは、`gsutil ls -l gs://backups/**` では削除されません。\n\nしたがって正解は以下の通りです。\n\n> \\\"JSONでライフサイクル管理ルールを書いて、gsutilでバケットにプッシュする\\\"\n\n📚 参考リンク:\n- https://cloud.google.com/storage/docs/gsutil/commands/lifecycle\n- https://cloud.google.com/storage/docs/xml-api/put-bucket-lifecycle\n- https://cloud.google.com/storage/docs/json_api/v1/buckets/update"
  },
  {
    "id": "A6",
    "question": "あなたは、自社の大規模なWebサイトポートフォリオのクリックデータのストレージシステムを選択するよう求められています。このデータは、カスタムのWebサイト分析パッケージから、通常1分間に6,000クリックの割合でストリーミングされています。また、最大で毎秒8,500クリックにもなります。これらのデータは、データサイエンスチームやユーザーエクスペリエンスチームが将来分析するために保存されます。\n\nどのストレージインフラを選ぶべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Google Cloud SQL"
      },
      {
        "id": "B",
        "text": "Google Cloud Datastore"
      },
      {
        "id": "C",
        "text": "Google Cloud Storage"
      },
      {
        "id": "D",
        "text": "Google Cloud Bigtable"
      }
    ],
    "answer": ["D"],
    "explanation": "### 全体的な説明\nGoogle Cloud Bigtableは、スケーラブルでフルマネージドなNoSQLワイドカラムデータベースで、リアルタイムアクセスにも分析ワークロードにも適しています。\n\nクリックデータのようなイベントデータを保存する際にも適しています。\n\nしたがって正解は以下の通りです。\n\n> \\\"Google Cloud Bigtable\\\"\n\n📚 参考リンク:\nhttps://cloud.google.com/storage-options/"
  },
  {
    "id": "A7",
    "question": "あなたが現在設計しているアーキテクチャでは、プロジェクト内のすべての管理者アクティビティとVMシステムログを集中的に収集することが求められています。\n\nVMとサービスの両方からこれらのログをどのように収集するべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "単一のコンピュートインスタンスにOps Agentをインストールし、環境のすべての監査ログとアクセスログを収集させる。"
      },
      {
        "id": "B",
        "text": "カスタムsyslogdコンピュートインスタンスを起動し、すべてのログをそこに転送するようにGCPプロジェクトとVMを構成する。"
      },
      {
        "id": "C",
        "text": "Cloud Loggingは、ほとんどのサービスの管理者アクティビティログを自動的に収集する。システムログを収集するには、各インスタンスにOps Agentをインストールする必要があります。"
      },
      {
        "id": "D",
        "text": "すべての管理者およびVMシステムのログはCloud Loggingによって自動的に収集されます。"
      }
    ],
    "answer": ["C"],
    "explanation": "### 全体的な説明\nGoogle Cloudがネイティブにサポートするログ収集方法を選択する必要があります。\n\n今回の要件であるログ種のうち、管理者ログとイベントログはデフォルトで設定されています。\n\n一方で、VM システムログは、Ops Agentを設定する必要があります。\n\nOps Agentは、デフォルトの構成では、一般的なサードパーティ アプリケーションやシステム ソフトウェアからのログを、Logging にストリーミングします。\n\n加えて、VMのシステムログを収集することも可能です。\n\nしたがって正解は以下の通りです。\n\n> \\\"Cloud logging は、ほとんどのサービスの管理者アクティビティログを自動的に収集する。システムログを収集するには、各インスタンスにOps Agentをインストールする必要があります。\\\"\n\n📚 参考リンク:\n- https://cloud.google.com/logging/docs/agent/logging/installation#before_you_begin"
  },
  {
    "id": "A8",
    "question": "あなたの会社では、Google Cloudのリソースの利用を開始したいと考えていますが、ID管理のためにオンプレミスのActive Directoryドメインコントローラを残したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Admin Directory APIを使用して、Active Directoryドメインコントローラに対して認証を行う。"
      },
      {
        "id": "B",
        "text": "Cloud Identity-Aware Proxy を使用して、オンプレミスの Active Directory ドメインコントローラを ID プロバイダとして使用するように設定する。"
      },
      {
        "id": "C",
        "text": "Google Cloud Directory Syncを使用して、Active Directoryのユーザー名とクラウドのIDを同期し、SAML SSOを設定する。"
      },
      {
        "id": "D",
        "text": "Compute Engineを使用して、Google Cloud Directory Syncを使用して、オンプレミスのADドメインコントローラのレプリカであるActive Directory（AD）ドメインコントローラを作成する。"
      }
    ],
    "answer": ["C"],
    "explanation": "### 全体的な説明\nGoogle Cloud では、認証とアクセス管理に Google ID が使用されます。\n\nすべての従業員がすでに Active Directory にアカウントを持っている場合、各従業員の Google ID を手動で管理すると、不要な管理オーバーヘッドが発生する場合があります。\n\nGoogle Cloud と既存の ID 管理システムの間でユーザー ID を連携させることで、Google ID のメンテナンスを自動化できます。\nさらに、Google ID のライフサイクルを Active Directory の既存ユーザーに結び付けることができます。\n\n**Google Cloud Directory Sync**: Google が無料で提供している、同期プロセスを実装するツールです。\n\nGoogle Cloud Directory Sync はセキュア ソケットレイヤ（SSL）を使用して Google Cloud と通信します。\n通常、このツールは既存のコンピューティング環境内で稼働します。\n\nしたがって正解は以下の通りです。\n\n> \\\"Google Cloud Directory Syncを使用して、Active Directoryのユーザー名とクラウドのIDを同期し、SAML SSOを設定する\\\"\n\n📚 参考リンク:\n- https://cloud.google.com/blog/products/identity-security/using-your-existing-identity-management-system-with-google-cloud-platform"
  },
  {
    "id": "A9",
    "question": "あなたの会社では、グローバルに分散している数千の物理デバイスからデータを収集するGoogle Cloud上で動作するアプリケーションを使用しています。データはPub/Subに公開され、Dataflowパイプラインを経由してSSDのCloud Bigtableクラスタにリアルタイムでストリーミングされます。運用チームから、Cloud Bigtableクラスタにホットスポットがあり、クエリに予想以上の時間がかかっているとの連絡がありました。あなたはこの問題を解決し、今後発生しないようにする必要があります。\n\n問題解決のためにどういった方法が適切ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "NodeJSのAPIではなく、HBaseのAPIを使うように顧客にアドバイスする。"
      },
      {
        "id": "B",
        "text": "現在持っているノードの数を2倍にする。"
      },
      {
        "id": "C",
        "text": "RowKey戦略を見直し、キーがアルファベットに均等になるようにする。"
      },
      {
        "id": "D",
        "text": "30日以上前のレコードを削除する。"
      }
    ],
    "answer": ["C"],
    "explanation": "### 全体的な説明\nBigtableの行キーの分散に偏りが生じるとホットスポットが発生します。\n\n行キーの偏りは、タイムスタンプやシーケンシャル数値IDなどを使用すると発生し、パフォーマンスの極端な低下につながります。\n\nホットスポットを解消するためには、Googleが推奨する行キーの設定方法にすることが必要です。\n\nしたがって正解は以下の通りです。\n\n> \\\"RowKey戦略を見直し、キーがアルファベットに均等になるようにする\\\"\n\n📚 参考リンク:\n- https://cloud.google.com/bigtable/docs/schema-design#row-keys\n- https://cloud.google.com/bigtable/docs/keyvis-overview"
  },
  {
    "id": "A10",
    "question": "あなたの会社は、数ペタバイトのデータセットをクラウドに移行することを計画しています。このデータセットは24時間利用可能でなければなりません。ビジネスアナリストは、SQLインターフェースの使用経験しかありません。\n\nアナリストが即座に分析に取り掛かれるようにするためには、どのようにデータを保存すればよいですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Google BigQueryにデータを読み込む"
      },
      {
        "id": "B",
        "text": "Google Cloud SQL にデータを挿入する"
      },
      {
        "id": "C",
        "text": "Google Cloud Storageにフラットファイルを投入する"
      },
      {
        "id": "D",
        "text": "Google Cloud Datastoreにデータをストリームする"
      }
    ],
    "answer": ["A"],
    "explanation": "### 全体的な説明\nBigQueryは、すべてのデータアナリストの生産性を高めるために設計された、Googleのサーバーレス、高スケーラブル、低コストのエンタープライズデータウェアハウスです。\n\n管理すべきインフラがないため、使い慣れたSQLを使って意味のあるインサイトを見出すためのデータ分析に集中でき、データベース管理者も必要ありません。\n\nBigQueryは、管理されたカラムナーストレージ、オブジェクトストレージ、およびスプレッドシートのデータ上に論理データウェアハウスを作成することにより、すべてのデータを分析することが可能になります。\n\nしたがって正解は以下の通りです。\n\n> \\\"Google BigQueryにデータを読み込む\\\"\n\n📚 参考リンク:\n- https://cloud.google.com/bigquery/"
  },
  {
    "id": "A11",
    "question": "あなたの会社では、データウェアハウスのために BigQuery を使用する Google Cloud プロジェクトがあります。テーブルの中には、個人を特定できる情報（PII）が含まれているものがあります。PII にアクセスできるのは、コンプライアンス チームだけです。テーブル内のその他の情報は、データサイエンスチームが利用できるようにする必要があります。あなたは、コストとテーブルへの適切なアクセスを割り当てるための時間を最小限にしたいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "1.データサイエンスチームのデータセットを作成する\n2.PIIを除いて共有したいテーブルのビューを作成する\n3.データサイエンスチームのメンバーに、適切なプロジェクトレベルのIAMロールを割り当てる\n4.ビューを含むデータセットにアクセスコントロールを割り当てる\n5.ビューにソースデータセットへのアクセスを許可する"
      },
      {
        "id": "B",
        "text": "1.ソースデータのあるデータセットから、PIIを除いて共有したいテーブルのビューを作成する\n2.データサイエンスチームのメンバーに、適切なプロジェクトレベルのIAMロールを割り当てる\n3.ビューを含むデータセットにアクセスコントロールを割り当てる"
      },
      {
        "id": "C",
        "text": "1.ソースデータのあるデータセットから、PIIを除いて共有したいテーブルのマテリアライズドビューを作成する\n2.データサイエンスチームのメンバーに、適切なプロジェクトレベルのIAMロールを割り当てる\n3.ビューを含むデータセットにアクセス制御を割り当てる"
      },
      {
        "id": "D",
        "text": "1.データサイエンスチームのデータセットを作成する\n2.PIIを除いて共有したいテーブルのマテリアライズドビューを作成する\n3.データサイエンスチームのメンバーに、適切なプロジェクトレベルのIAMロールを割り当てる\n4.ビューを含むデータセットにアクセスコントロールを割り当てる\n5.ビューがソースデータセットにアクセスする権限を与える"
      }
    ],
    "answer": ["C"],
    "explanation": "### 全体的な説明\n今回のケースでは2つの観点を評価する必要があります。\n\n一つ目は、ビューを使用するかマテリアライズドビューを使用するかという点で、二つ目はテーブルへのアクセス制御についてです。\n\n一つ目の観点では、コストを削減したいという要件があるため、マテリアライズドビューが最適な選択です。\n\nBigQueryでは、Select文で読み取ったレコードボリュームに応じて料金が課金されます。\n\nビューを使用した場合、データサイエンティストがクエリをかけるたびに料金が加算されることになります。\n\n一方BigQuery マテリアライズド ビュー（MV）は事前に計算されたビューであり、パフォーマンスと効率の改善を目的としてクエリの結果を定期的にキャッシュに保存します。\n\nこの機能は、一般的なクエリを何度も繰り返し使用するような特性のワークロードにおいて、パフォーマンスを大幅に向上させ、コストの削減を実現します。\n\n二つ目の観点では、マテリアライズドビューがテーブルレベルでの権限を設定できるため、アクセスを割り当てるための時間を最小限にするという要件を踏まえると、ビューを含むデータセットにアクセス制御を割り当てる方法が適切です。\n\nしたがって正解は以下の通りです。\n\n> \"1.ソースデータのあるデータセットから、PIIを除いて共有したいテーブルのマテリアライズドビューを作成する\n> 2.データサイエンスチームのメンバーに、適切なプロジェクトレベルのIAMロールを割り当てる\n> 3.ビューを含むデータセットにアクセス制御を割り当てる\"\n\n📚 参考リンク:\n- https://cloud.google.com/bigquery/docs/materialized-views-intro\n- https://cloud.google.com/blog/products/data-analytics/bigquery-materialized-views-now-ga\n- https://cloud.google.com/bigquery/docs/table-access-controls-intro"
  },
  {
    "id": "A12",
    "question": "あなたの会社のアプリケーションでは、ステージング環境やテスト環境では見られなかったパフォーマンス上のバグが本番環境で発生しています。これによって多くのユーザーに悪影響が発生しています。今後この問題を避けるために、テストとデプロイメントの手順を見直したいと考えています。\n\nどういった手順が必要ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "本番環境に移行する前に、一部のユーザーに対して変更を適用する"
      },
      {
        "id": "B",
        "text": "本番環境へのリリース回数を減らす"
      },
      {
        "id": "C",
        "text": "テスト環境とステージング環境の負荷を上げる"
      },
      {
        "id": "D",
        "text": "より小さなリリースを本番環境に導入する"
      }
    ],
    "answer": ["A"],
    "explanation": "### 全体的な説明\n本番環境の全てのユーザーに対して最新リリースを提供するのではなく、まず一部ユーザーのみに限定して公開し、本番環境向けのテストを行ってから全てのユーザーに公開する手法を取ることが有効です。\n\nこの手法は、**カナリアリリース**と呼ばれています。\n\nこの手法には、本番環境で発生する不具合をあらかじめ解消し、より完成度の高い状態で全てのユーザーに公開できるメリットがあります。\n\nしたがって正解は以下の通りです。\n\n> \"本番環境に移行する前に、一部のユーザーに対して変更を適用する\"\n\n📚 参考リンク:\n- https://cloud.google.com/solutions/application-deployment-and-testing-strategies#canary_test_pattern"
  },
  {
    "id": "A13",
    "question": "US-Central リージョンにある本番用 Linux 仮想マシンのコピーを作成したい。本番用仮想マシンに変更があった場合、コピーを簡単に管理・交換できるようにしたい。そのコピーをUS-Eastリージョンの別のプロジェクトに新しいインスタンスとしてデプロイします。\n\nどのような手順を踏む必要がありますか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Linuxのddコマンドとnetcatコマンドを使用して、ルートディスクの内容をUS-Eastリージョンにある新しい仮想マシンインスタンスにコピーしてストリーミングする。"
      },
      {
        "id": "B",
        "text": "Linuxのddコマンドでルートディスクからイメージファイルを作成し、US-Eastリージョンに新しい仮想マシンインスタンスを作成する。"
      },
      {
        "id": "C",
        "text": "ルートディスクのスナップショットを作成し、US-Eastリージョンで新しい仮想マシンインスタンスを作成する際に、スナップショットをルートディスクとして選択する。"
      },
      {
        "id": "D",
        "text": "ルートディスクのスナップショットを作成し、そのスナップショットからGoogle Cloud Storageにイメージファイルを作成し、そのイメージファイルをルートディスクとしてUS-Eastリージョンに新しい仮想マシンインスタンスを作成する。"
      }
    ],
    "answer": ["D"],
    "explanation": "### 全体的な説明\nスナップショットはグローバルなリソースです。\n\n本番VMのコピーを作成するには、まずルートディスクのスナップショットを作成し、Cloud Storageでイメージファイルを作成し、このイメージファイルから新しいVMインスタンスを作成するか、us-eastリージョンで新しいVMを作成するときにルートディスクのスナップショットを使用することができます。\n\nしたがって正解は以下の通りです。\n\n> \"ルートディスクのスナップショットを作成し、そのスナップショットからGoogle Cloud Storageにイメージファイルを作成し、そのイメージファイルをルートディスクとしてUS-Eastリージョンに新しい仮想マシンインスタンスを作成する\"\n\n📚 参考リンク:\n- https://cloud.google.com/compute/docs/disks/create-snapshots#sharing_snapshots"
  },
  {
    "id": "A14",
    "question": "お客様の会社のオペレーションチームは、Cloud VPNのログイベントを1年間保存したいと考えています。あなたは、ログを保存するためにクラウドインフラストラクチャを設定する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Compute Engine APIを有効にしてから、保存したいトラフィックにマッチするファイアウォールルールのログを有効にする。"
      },
      {
        "id": "B",
        "text": "Cloud Loggingでフィルターを設定し、保存したいログのエクスポート先としてCloud Storageのバケットを設定する。"
      },
      {
        "id": "C",
        "text": "Cloud Loggingでフィルターを設定し、Pub/Subでトピックを設定してログを公開する。"
      },
      {
        "id": "D",
        "text": "Cloud VPN Logsというタイトルのクラウドロギングダッシュボードをセットアップし、1年間のVPNメトリクスを照会するチャートを追加する。"
      }
    ],
    "answer": ["B"],
    "explanation": "### 全体的な説明\nCloud VPN ゲートウェイはログ情報を Cloud Logging に送信し、Cloud VPN トンネルはモニタリングメトリクスを Cloud Monitoring に送信します。\n\nCloud Logging では、Cloud VPN ログは 30 日間のみ保存されます。それよりも長い期間ログを保持するには、ログを転送する必要があります。\n\nCloud VPN ログは、Cloud Storage、Cloud Pub/Sub または BigQuery に転送して分析できます。\n\n（一つ目の参照URLではCloud Storageの明記がありませんが、二つ目の参照URLにて、ログの転送先にCloud Storageが明記されています）\n\n今回の要件では1年間ログを保存する必要があるため、長期保存に適したCloud Storageが最適なサービスとなります。\n\nしたがって正解は以下の通りです。\n\n> \"Cloud Loggingでフィルターを設定し、保存したいログのエクスポート先としてCloud Storageのバケットを設定する。\"\n\n📚 参考リンク:\n- https://cloud.google.com/network-connectivity/docs/vpn/how-to/viewing-logs-metrics\n- https://cloud.google.com/logging/docs/routing/overview"
  },
  {
    "id": "A15",
    "question": "あなたは、金融機関で住宅ローンの稟議書をCloud Storageに保存しています。承認書類に変更があった場合は、別の承認ファイルとしてアップロードする必要があります。新たにアップロードされたファイルは5年間は削除や上書きができないようにしたいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "細かなアクセス制御が可能なバケットを作成し、サービスアカウントにオブジェクトライターの役割を付与する。新しいファイルのアップロードには、このサービスアカウントを使用する。"
      },
      {
        "id": "B",
        "text": "バケットレベルの均一なアクセス権でバケットを作成し、サービスアカウントにオブジェクトライターの役割を与えます。新しいファイルのアップロードには、このサービスアカウントを使用する。"
      },
      {
        "id": "C",
        "text": "バケットの暗号化には、お客様が管理する鍵を使用する。鍵は5年後にローテーションする。"
      },
      {
        "id": "D",
        "text": "バケットに 5 年間の保持ポリシーを作成する。保持ポリシーにロックを作成する。"
      }
    ],
    "answer": ["D"],
    "explanation": "### 全体的な説明\nバケットロック機能を使用すると、バケット内のオブジェクトの保持期間を制御するデータ保持ポリシーを Cloud Storage バケットに構成できます。\n\nまた、データ保持ポリシーをロックして、ポリシーの変更や削除を防止することもできます。\n\nバケットに保持ポリシーを追加して、保持期間を指定できます。\n\n- バケットに保持ポリシーがない場合は、バケット内のオブジェクトをいつでも削除または置き換えできます。\n- バケットに保持ポリシーが設定されている場合、バケット内のオブジェクトを削除または置き換えできるのは、所定の保持期間を経過した後です。\n- 保持ポリシーは、バケットに追加された新しいオブジェクトだけでなく、バケット内の既存のオブジェクトにさかのぼって適用されます。\n\n保持ポリシーは、バケットに永久に設定されるようにロックできます。\n\n- 保持ポリシーをロックすると、そのポリシーを削除したり、保持期間を短縮したりすることはできません。\n- バケット内のすべてのオブジェクトが保持期間を満たしていない限り、ロックされた保持ポリシーのバケットを削除することはできません。\n- ロックされた保持ポリシーの保持期間は延長できます。\n- 保持ポリシーのロックは記録保持規制の遵守に役立ちます。\n\n今回の例であれば、ファイルは5年間の削除や上書きを禁止する必要があり、そのルール自体も制御する必要があるので、バケットロック機能は最適です。\n\nしたがって正解は以下の通りです。\n\n> \"バケットに 5 年間の保持ポリシーを作成する。保持ポリシーにロックを作成する\"\n\n📚 参考:\n- https://cloud.google.com/storage/docs/using-bucket-lock"
  },
  {
    "id": "A16",
    "question": "あなたはクライアントから、アプリケーションインフラのGCPへの移行を主導するよう依頼されました。現在の問題の1つは、オンプレミスのハイパフォーマンスSANが、以下のような様々なワークロードに対応するために、頻繁で高価なアップグレードを必要としていることです。\n\n- 法的な理由で保持されている20TBのログアーカイブ\n- 500GBのVMブート/データボリュームとテンプレート\n- 500GBのイメージサムネイル\n- 200GBの顧客セッションステートデータ（数日間オフラインになってもセッションを再開できる）\n\nコストパフォーマンスに優れたストレージの割り当てに関する推奨事項を最もよく反映しているのは、次のうちどれですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "顧客のセッションステートデータ用のPersistent Disk SSDストレージでバックアップされたMemcache。VMブート/データボリューム用のSSDバックアップされたローカルインスタンスのバンドル。ログ・アーカイブとサムネイル用のCloud Storage。"
      },
      {
        "id": "B",
        "text": "顧客のセッションステートデータ用のローカルSSD。ログアーカイブ、サムネイル、VMブート/データボリューム用のライフサイクル管理されたCloud Storage。"
      },
      {
        "id": "C",
        "text": "顧客のセッションステートデータ用のCloud DatastoreでバックアップされたMemcache。ログ・アーカイブ、サムネイル、およびVMブート/データ・ボリューム用のライフサイクル管理されたCloud Storage。"
      },
      {
        "id": "D",
        "text": "お客様のセッション・ステート・データ用のCloud SQLでバックアップされたMemcache VMブート/データ・ボリューム用の各種ローカルSSDでバックアップされたインスタンス。ログ・アーカイブとサムネイル用のCloud Storage。"
      }
    ],
    "answer": ["C"],
    "explanation": "### 全体的な説明\nCloud Storageは様々なオブジェクトを保存することに適しています。\n\nこれは、ブートボリュームであっても可能で、カスタムイメージとして保存することで高い耐久性を持ったストレージに保管することが可能です。\n\nまた、揮発性の高いセッションデータについてはmemcacheへの保存が最適です。\nこの際Cloud Datastoreでバックアップをすることで、顧客のセッションデータの損失を防ぐことが可能です。\n\nしたがって正解は以下の通りです。\n\n> \"お客様のセッションステートデータ用のCloud DatastoreでバックアップされたMemcache。ログ・アーカイブ、サムネイル、およびVMブート/データ・ボリューム用のライフサイクル管理されたCloud Storage。\"\n\n📚 参考:\n- https://cloud.google.com/compute/docs/images/create-delete-deprecate-private-images#selecting_image_storage_location\n- https://cloud.google.com/appengine/docs/standard/python/memcache\n- https://cloud.google.com/solutions/image-management-best-practices"
  },
  {
    "id": "A17",
    "question": "あなたの会社では、Webアプリケーションを開発しています。本番用のデプロイメントがソースコードのコミットにリンクされ、完全に監査可能であることを確認する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "開発者が、デプロイメントにリンクするコメントをコミットに追加していることを確認する。"
      },
      {
        "id": "B",
        "text": "開発者がコードのコミットにコミットの日時をタグ付けしていることを確認する。"
      },
      {
        "id": "C",
        "text": "コンテナタグがソースコードのコミットハッシュと一致するようにする。"
      },
      {
        "id": "D",
        "text": "開発者がコミットに latest のタグを付けていることを確認する。"
      }
    ],
    "answer": ["C"],
    "explanation": "### 全体的な説明\nコードベースが変化していくなかで、コードがどのように変更されたのか、その変更がいつ行われたのかについて確認するためには、commit の完全なハッシュを確認することが適切です。\n\nベストプラクティスとして、CI/CDデリバリー システムを使用し、ソフトウェアを頻繁にリリースする場合は、ハッシュをバージョン番号として使用することが推奨されています。\n\nしたがって正解は以下の通りです。\n\n> \"コンテナタグがソースコードのコミットハッシュと一致するようにする\"\n\n📚 参考:\n- https://cloud.google.com/source-repositories/docs/commit-details-overview\n- https://cloud.google.com/architecture/best-practices-for-building-containers"
  },
  {
    "id": "A18",
    "question": "BigQuery プロジェクトには複数のユーザーがいます。監査のために、各ユーザーが先月に実行したクエリの数を確認する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "BigQuery インターフェイスで JOBS テーブルのクエリを実行し、必要な情報を取得する。"
      },
      {
        "id": "B",
        "text": "Cloud Audit Logsを表示するためにCloud Audit Loggingを使用し、必要な情報を取得するために問い合わせ操作にフィルタを作成する。"
      },
      {
        "id": "C",
        "text": "Google Data Studio を BigQuery に接続する。ユーザーのディメンションと、ユーザーごとのクエリ量のメトリックを作成する。"
      },
      {
        "id": "D",
        "text": "全てのジョブをリストアップするために、bq show を使用する。ジョブ毎に、bq lsを使用してジョブ情報をリストアップし、必要な情報を得る。"
      }
    ],
    "answer": ["B"],
    "explanation": "### 全体的な説明\nCloud Audit Logs は Google Cloud が提供するログの集まりで、Google Cloud サービスの使用に関連する運用上の情報を把握することができます。\n\nCloud Audit Logsは、管理者の活動、データアクセス、システムイベントなどの監査ログを保持します。BigQueryのクエリログデータも自動的にCloud Audit Logsへ送信されます。\n\nまた、Cloud Audit Logsのフィルタ機能を使うことで、関連するBigQuery Auditメッセージをフィルタリングすることができます。\n\nこれによって、各ユーザーごとにクエリ数を確認することもできます。\n\n> \"Cloud Audit Logsを表示するためにCloud Audit Loggingを使用し、必要な情報を取得するために問い合わせ操作にフィルタを作成する\"\n\n📚 参考リンク:\n- https://cloud.google.com/logging/docs/audit\n- https://cloud.google.com/bigquery/docs/reference/auditlogs#ids\n- https://cloud.google.com/bigquery/docs/reference/auditlogs#auditdata_examples"
  },
  {
    "id": "A19",
    "question": "最近の監査で、お客様のGCPプロジェクトに新しいネットワークが作成されていることが判明しました。このネットワークでは、GCEインスタンスのSSHポートが世界中に公開されています。あなたは、このネットワークの作成された記録を発見したいと考えています。\n\nどのような方法で発見することができますか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud Monitoring アラートコンソールで「Create VM」エントリを検索する。"
      },
      {
        "id": "B",
        "text": "[ホーム]セクションの[アクティビティ]ページに移動する。カテゴリを「データアクセス」に設定し、「VMの作成」エントリを検索する。"
      },
      {
        "id": "C",
        "text": "コンソールの[ログ]セクションで、[GCE Network]をログセクションとして指定する。Create Insert エントリを検索する。"
      },
      {
        "id": "D",
        "text": "プロジェクトの SSH キーを使用して GCE インスタンスに接続する。システムログで以前のログインを確認し、これらをプロジェクトのオーナーリストと照合する"
      }
    ],
    "answer": ["C"],
    "explanation": "### 全体的な説明\n監査ログは、いつ、どこで、誰が、何をしたかを特定するのに役立ちます。\n\nCloud Audit Loggingは、以下の2種類のログを提供します：\n\n- **管理者アクティビティログ**\n- **データアクセスログ**（get、list、aggregated listなど）\n\n新しいネットワークリソースの作成は、管理者アクティビティログで記録されるため、Cloud Logging で対象セクション（GCE Network）を指定して Create Insert イベントを検索するのが適切です。\n\n> \"コンソールの[ログ]セクションで、[GCE Network]をログセクションとして指定する。Create Insert エントリを検索する\"\n\n📚 参考:\n- https://cloud.google.com/logging/docs/audit"
  },

  {
    "id": "A20",
    "question": "あるアプリケーション開発チームがあなたにアドバイスを求めてきました。彼らは、開発言語としてGo 1.12を使ってHTTP（S）APIを書いてデプロイすることを計画しています。このAPIは、非常に予測不可能なワークロードを持ち、トラフィックのピーク時にも信頼性を維持しなければなりません。彼らは、このアプリケーションの運用上のオーバーヘッドを最小限にしたいと考えています。\n\nあなたはどのようなアプローチを推奨しますか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "App Engineの標準環境でアプリケーションを開発する。"
      },
      {
        "id": "B",
        "text": "Compute Engine にデプロイする場合は、マネージドインスタンスグループを使用する。"
      },
      {
        "id": "C",
        "text": "カスタムランタイムを使用して、App Engineフレキシブル環境用のアプリケーションを開発する。"
      },
      {
        "id": "D",
        "text": "コンテナでアプリケーションを開発し、Google Kubernetes Engineにデプロイする。"
      }
    ],
    "answer": ["A"],
    "explanation": "### 全体的な説明\nApp Engineは、マネージドサービスなので、少ないオーバーヘッドで柔軟な方法でアプリケーションを実行することができます。\n\n標準環境は迅速なスケーリングに対応し、Go 1.12 もサポートされています。これにより、トラフィックの急激な増加にも対応可能で、運用コストを最小限に抑えることができます。\n\n> \"App Engineの標準環境でアプリケーションを開発する\"\n\n📚 参考: https://cloud.google.com/appengine/docs/the-appengine-environments"
  },
  {
    "id": "A21",
    "question": "あなたのお客様は、Eコマースサイトでユーザーに商品をお勧めするために使用されるウェブサービスを運営しています。この会社は、結果の質を向上させるために、Google Cloud Platform上で機械学習モデルの実験を始めました。\n\nこのモデルの結果を改善するために、お客様は何をすべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "レコメンデーションの履歴と結果をBigQueryに保存し、トレーニングデータとして使用する。"
      },
      {
        "id": "B",
        "text": "Compute Engineの発表を監視し、新しいCPUアーキテクチャが利用可能になった時点でモデルをデプロイしてパフォーマンスを向上させる。"
      },
      {
        "id": "C",
        "text": "Cloud Machine Learning EngineのパフォーマンスメトリクスをCloud MonitoringからBigQueryにエクスポートし、モデルの効率性を分析するために使用する。"
      },
      {
        "id": "D",
        "text": "機械学習モデルのトレーニングを、より良い結果が得られるCloud GPUからCloud TPUに移行するためのロードマップを構築する。"
      }
    ],
    "answer": ["A"],
    "explanation": "### 全体的な説明\nモデルの精度向上には質の高いトレーニングデータが不可欠です。\nBigQuery にレコメンデーション結果と履歴を保存することで、より効果的な教師データを作成できます。\nBigQuery ML を使えば SQL ベースで機械学習モデルを作成・利用でき、データアナリストも活用しやすいです。\n\n> \"レコメンデーションの履歴と結果をBigQueryに保存し、トレーニングデータとして使用する\"\n\n📚 参考: https://cloud.google.com/bigquery-ml/docs/introduction"
  },
  {
    "id": "A22",
    "question": "Cloud StorageへのHTTPリクエストを行うアプリケーションがあります。時々、リクエストがHTTPステータスコード5xxや、429で失敗することがあります。\n\nこのようなエラーにはどのように対処すればよいでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "パフォーマンスを向上させるために、HTTPの代わりにgRPCを使用する。"
      },
      {
        "id": "B",
        "text": "Cloud Storageのバケットがマルチリージョンであることを確認し、地理的冗長性を確保する。"
      },
      {
        "id": "C",
        "text": "指数的バックオフ戦略を使用したリトライロジックを実装する。"
      },
      {
        "id": "D",
        "text": "https://status.cloud.google.com/feed.atom を監視し、Cloud Storageがインシデントを報告していない場合にのみリクエストを行う。"
      }
    ],
    "answer": ["C"],
    "explanation": "### 全体的な説明\nCloud Storage では高リクエスト負荷時に 429 や 5xx を返すことがあります。\nこのような一時的な過負荷状態には指数的バックオフによるリトライが有効です。\n\n> \"指数的バックオフ戦略を使用したリトライロジックを実装する\"\n\n📚 参考:\n- https://cloud.google.com/storage/docs/json_api/v1/status-codes\n- https://cloud.google.com/storage/docs/request-rate"
  },
  {
    "id": "A23",
    "question": "1つのCloud SQLインスタンスを使用して、特定のゾーンからアプリケーションを提供しています。高可用性を導入したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "フェイルオーバーレプリカインスタンスを別のリージョンに作成する"
      },
      {
        "id": "B",
        "text": "同じリージョンの別のゾーンにフェイルオーバーレプリカインスタンスを作成する"
      },
      {
        "id": "C",
        "text": "異なるリージョンにリードレプリカインスタンスを作成する"
      },
      {
        "id": "D",
        "text": "同じリージョンの異なるゾーンにリードレプリカインスタンスを作成する"
      }
    ],
    "answer": ["B"],
    "explanation": "### 全体的な説明\nCloud SQL の高可用性は、同じリージョン内の異なるゾーンに配置されたフェイルオーバーレプリカで実現されます。\nリードレプリカは読み取りパフォーマンスの向上には有効ですが、フェイルオーバーには使えません。\n\n> \"同じリージョンの別のゾーンにフェイルオーバーレプリカインスタンスを作成する\"\n\n📚 参考: https://cloud.google.com/sql/docs/mysql/configure-ha"
  },
  {
    "id": "A24",
    "question": "【ケーススタディ問題】この質問については、TerramEarthのケーススタディを参照してください。\n\nあなたはTerramEarthのマイクロサービスベースのアプリケーションを構築しています。このアプリケーションはDockerコンテナをベースにしています。Googleが推奨するプラクティスに従い、アプリケーションを継続的に構築し、成果物を保存したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "1分ごとにレポをチェックするSchedulerジョブを作成する。新しい変更があった場合、Cloud Buildを起動してマイクロサービス用のコンテナ・イメージを構築する。現在のタイムスタンプを使用してイメージにタグ付けし、コンテナ・レジストリにプッシュする"
      },
      {
        "id": "B",
        "text": "新しいソースの変更に対して、Cloud Buildにトリガーを設定する。トリガーはビルドジョブを起動し、マイクロサービス用のコンテナイメージをビルドする。イメージにバージョン番号をタグ付けして、Cloud Storageにプッシュする"
      },
      {
        "id": "C",
        "text": "新しいソース変更に対してCloud Buildでトリガーを構成する。Cloud Buildを起動してコンテナ・イメージを1つ構築し、イメージに「latest」というラベルを付けます。そのイメージをコンテナレジストリにプッシュする"
      },
      {
        "id": "D",
        "text": "新しいソース変更に対してCloud Buildでトリガーを構成する。Cloud Buildを起動して、各マイクロサービスのコンテナイメージを構築し、コードコミットハッシュを使ってタグ付けする。そのイメージをコンテナレジストリにプッシュする"
      }
    ],
    "answer": ["D"],
    "explanation": "Google Cloudでは、コードコミットハッシュを使ってタグ付けすることでバージョンの一意性と追跡性を確保できます。\n\n一方で \\\"latest\\\" タグは非推奨であり、常に上書きされる可能性があるため避けるべきです。\n\n📚 参考:\n- https://cloud.google.com/architecture/best-practices-for-building-containers#tagging_using_semantic_versioning\n- https://cloud.google.com/architecture/best-practices-for-building-containers#tagging_using_the_git_commit_hash"
  },
  {
    "id": "A25",
    "question": "2つのリージョンにまたがる単一のVPCにCompute Engineアプリケーションを構築したいと考えています。このアプリケーションは、オンプレミスのネットワークとVPNで通信する必要があります。\n\nどのようにしてVPNを導入するべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "IAMとVPC Sharingを使ってVPCをオンプレミスネットワークに公開する。"
      },
      {
        "id": "B",
        "text": "VPCとオンプレミスネットワークの間にVPCネットワークピアリングを使用する。"
      },
      {
        "id": "C",
        "text": "各リージョンにCloud VPNゲートウェイを展開する。各リージョンには、オンプレミスのピアゲートウェイへのVPNトンネルが少なくとも1つあることを確認する。"
      },
      {
        "id": "D",
        "text": "グローバルなCloud VPNゲートウェイを作成し、各リージョンからオンプレミスのピアゲートウェイへのVPNトンネルを設定する。"
      }
    ],
    "answer": ["C"],
    "explanation": "各リージョンにCloud VPNを設定し、対応するVPNトンネルを作成するのがベストプラクティスです。\n\nVPC ピアリングや IAM 設定はこの文脈では不適切です。\n\n📚 参考:\n- https://cloud.google.com/vpn/docs/how-to/creating-static-vpns\n- https://cloud.google.com/network-connectivity/docs/vpn/how-to/configuring-peer-gateway"
  },
  {
    "id": "A26",
    "question": "Google Kubernetes Engine（GKE）にアプリケーションをデプロイし、Cloud SQLプロキシコンテナを使用して、Kubernetes上で動作するサービスがCloud SQLデータベースを利用できるようにしています。アプリケーションがデータベース接続の問題を報告していることが通知されました。あなたの会社のポリシーでは、問題発生時は事後検証を必要としています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud SQL プロキシ・コンテナが使用するサービスアカウントに、Cloud Build Editor ロールが残っていることを確認する。"
      },
      {
        "id": "B",
        "text": "gcloud sql instances restart を使用する。"
      },
      {
        "id": "C",
        "text": "GCP コンソールで、Cloud SQL に移動する。最新のバックアップを復元する。kubectlを使用してすべてのポッドを再起動する。"
      },
      {
        "id": "D",
        "text": "GCP コンソールで、［Cloud Logging］に移動する。（GKE）とCloud SQLのログを参照する。"
      }
    ],
    "answer": ["D"],
    "explanation": "事後検証には、ログとメトリクスによる原因特定が必要です。\nGKE と Cloud SQL はデフォルトで Cloud Logging（現 Cloud Logging）と統合されています。\n\n📚 参考:\n- https://cloud.google.com/sql/docs/mysql/connect-kubernetes-engine#providing_the_service_account_to_the_proxy"
  },
  {
    "id": "A27",
    "question": "あなたの会社では、複数のCompute Engineインスタンス上でアプリケーションを実行しています。このアプリケーションが、内部IP経由で高いスループットを必要とするオンプレミスのサービスと、遅延を最小限に抑えながら通信できるようにする必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "オンプレミス環境とGoogle Cloudの間にダイレクトピアリング接続を構成する。"
      },
      {
        "id": "B",
        "text": "OpenVPNを使用して、オンプレミス環境とGoogle Cloudの間にVPNトンネルを構成する。"
      },
      {
        "id": "C",
        "text": "Cloud VPNを使用して、オンプレミス環境とGoogle Cloudの間にVPNトンネルを構成する。"
      },
      {
        "id": "D",
        "text": "オンプレミス環境とGoogle Cloudの間にCloud 専用 Interconnect接続を構成する。"
      }
    ],
    "answer": ["D"],
    "explanation": "今回の要件（高スループット・低遅延）に対して、最適なのは Cloud Dedicated Interconnect です。\n\nVPN や OpenVPN、ダイレクトピアリングは適用範囲や帯域に制限があります。\n\n📚 参考：\n- https://cloud.google.com/network-connectivity/docs/interconnect/concepts/dedicated-overview\n- https://cloud.google.com/architecture/setting-up-private-access-to-cloud-apis-through-vpn-tunnels"
  },
  {
    "id": "A28",
    "question": "あなたはマネージドインスタンスグループの作成を自動化したいと考えています。VMには多くのOSパッケージの依存性があります。また、インスタンスグループの新しいVMのスタートアップ時間を最小化したいとも考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Puppetを使用してマネージドインスタンスグループを作成し、OSパッケージの依存関係をインストールする。"
      },
      {
        "id": "B",
        "text": "すべてのOSパッケージの依存関係を持つカスタムVMイメージを作成する。Deployment Managerを使用して、VMイメージでマネージドインスタンスグループを作成する。"
      },
      {
        "id": "C",
        "text": "Deployment Manager を使用して管理対象のインスタンスグループを作成し、Ansible を使用して OS パッケージの依存関係をインストールする。"
      },
      {
        "id": "D",
        "text": "Terraformを使用してマネージドインスタンスグループを作成し、OSパッケージの依存関係をインストールするスタートアップスクリプトを作成する。"
      }
    ],
    "answer": ["B"],
    "explanation": "スタートアップ時間を最小限にするためには、依存関係を事前にインストールしたカスタムVMイメージを作ることが最適です。\n\nDeployment Manager を使えば、それをテンプレート化して自動化できます。\n\n📚 参考：\n- https://cloud.google.com/compute/docs/images\n- https://cloud.google.com/deployment-manager"
  },
  {
    "id": "A29",
    "question": "監査人が12ヶ月ごとにチームを訪問し、過去12ヶ月間に行われたGoogle Cloud Identity and Access Management （Cloud IAM）のポリシー変更をすべて確認するよう求められます。あなたは、分析と監査のプロセスを合理化し、迅速化この確認を行いたいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Google BigQueryへのログエクスポートを有効にし、ACLとビューを使用して監査人と共有するデータの範囲を設定する"
      },
      {
        "id": "B",
        "text": "Cloud Functionを使用してログエントリをGoogle Cloud SQLに転送し、ACLとビューを使用して監査人の閲覧を制限する"
      },
      {
        "id": "C",
        "text": "Google Cloud Storage (GCS)のログエクスポートを有効にして、GCSのバケットにログを出力し、そのバケットへのアクセスを監査人に付与する"
      },
      {
        "id": "D",
        "text": "Google Cloud Monitoringのカスタムアラートを作成し、監査人に送信する"
      }
    ],
    "answer": ["A"],
    "explanation": "Cloud IAM の監査データを効率的に確認・分析するには、BigQuery にログをエクスポートし、ビューや ACL を使って範囲を制御するのが最適です。\n\nBigQuery は分析性能が高く、ログ監査の高速化・効率化に最適です。\n\n📚 参考：\n- https://cloud.google.com/iam/docs/roles-audit-logging#scenario_external_auditors\n- https://cloud.google.com/bigquery/docs/table-access-controls-intro"
  },
  {
    "id": "A30",
    "question": "お客様の会社では、ローカルデータセンターで実行されるApache SparkとHadoopのジョブの数とサイズが急激に増加することが予想されています。クラウドを利用することで、運用作業やコードの変更を最小限に抑えながら、今後の需要に対応したいと考えています。\n\nどのサービスを使うべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Google Compute Engine"
      },
      {
        "id": "B",
        "text": "Google Cloud Dataflow"
      },
      {
        "id": "C",
        "text": "Google Cloud Dataproc"
      },
      {
        "id": "D",
        "text": "Google Kubernetes Engine"
      }
    ],
    "answer": ["C"],
    "explanation": "Dataproc は、Apache Spark および Hadoop のマネージドクラウドサービスで、最小限のコード変更でオンプレミスの処理をクラウドに移行できます。\n\nスケーラブルかつ他の GCP サービスとも統合しやすく、コスト効率にも優れています。\n\n📚 参考：\n- https://cloud.google.com/dataproc/docs/resources/faq"
  },
  {
    "id": "A31",
    "question": "あなたの開発チームでは新しいアプリケーションを構築しています。開発マネージャーはあなたに要件に基づいてどのようなクラウドテクノロジーを使用できるかを特定するよう依頼しました。このアプリケーションは以下の条件を満たす必要があります。\n\n1.クラウドへの移植性を考慮して、オープンソースの技術をベースにする\n2.需要に応じて計算能力を動的に拡張する\n3.継続的なソフトウェアデリバリーをサポートする\n4.同じアプリケーションスタックの複数の分離されたコピーを実行する\n5.ダイナミックテンプレートを使用してアプリケーションバンドルのデプロイする\n6. URL に基づいてネットワークトラフィックを特定のサービスにルーティングする\n\n彼の要求をすべて満たすテクノロジーの組み合わせはどれですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Google Kubernetes Engine, Cloud Load Balancing"
      },
      {
        "id": "B",
        "text": "Google Kubernetes Engine, Jenkins, Cloud Load Balancing"
      },
      {
        "id": "C",
        "text": "Google Kubernetes Engine, Jenkins, Helm"
      },
      {
        "id": "D",
        "text": "Google Kubernetes Engine, Cloud Deployment Manager"
      }
    ],
    "answer": ["C"],
    "explanation": "このアプリケーション要件のうち、動的スケーリング・マルチコピー実行・URLルーティングには GKE が対応可能であり、CI/CD には Jenkins、ダイナミックテンプレートによるデプロイには Helm が適しています。Cloud Load Balancing は GKE の Ingress に含まれる機能として提供されるため、重複構成は不要です。\n\n📚 参考：\n- https://helm.sh/ja/\n- https://cloud.google.com/solutions/jenkins-on-kubernetes-engine\n- https://cloud.google.com/kubernetes-engine/docs/tutorials/http-balancer"
  },
  {
    "id": "A32",
    "question": "カスタマーサポートツールでは、メールやチャットでの会話をすべてCloud Bigtableに記録して保存・分析しています。\n\nこのデータを保存する際に、個人情報やカード情報を消去するには、どのような方法がありますか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "楕円曲線暗号方式による全データの暗号化"
      },
      {
        "id": "B",
        "text": "すべてのデータをSHA256でハッシュ化"
      },
      {
        "id": "C",
        "text": "Cloud Data Loss Prevention(DLP) APIによるデータの非識別化"
      },
      {
        "id": "D",
        "text": "正規表現を使用して、電話番号、電子メールアドレス、クレジットカード番号を検索し、再編集する"
      }
    ],
    "answer": ["C"],
    "explanation": "Cloud DLP API は、PII（個人を特定できる情報）を自動的に識別し、マスキングや置換などの非識別化処理を行うための Google Cloud のサービスです。Bigtable などのストレージに記録する前に処理することで、データ活用とプライバシー保護を両立できます。\n\n📚 参考：\n- https://cloud.google.com/blog/ja/products/gcp/take-charge-of-your-sensitive-data-with-the-cloud-dlp-api\n- https://cloud.google.com/solutions/pci-dss-compliance-in-gcp#using_data_loss_prevention_api_to_sanitize_data"
  },
  {
    "id": "A33",
    "question": "あなたは開発プロジェクトの一環として、ステートフルなワークロードを Google Cloud に展開する必要があります。ワークロードは水平方向に拡張できますが、各インスタンスは同じPOSIXファイルシステムに読み書きする必要があります。高負荷時には、ステートフルワークロードは最大で100MB/sの書き込みをサポートする必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud Storageのバケットを作成し、gcsfuseを使用して各インスタンスにマウントする。"
      },
      {
        "id": "B",
        "text": "各インスタンスにリージョナル永続ディスクを使用する。"
      },
      {
        "id": "C",
        "text": "Cloud Filestoreインスタンスを作成し、各インスタンスにマウントする。"
      },
      {
        "id": "D",
        "text": "各インスタンスに永続ディスクを使用する。"
      }
    ],
    "answer": ["C"],
    "explanation": "Cloud Filestore は高スループットとPOSIX互換のファイル共有を提供するため、ステートフルなワークロードで複数のインスタンスから同一ファイルシステムへのアクセスが必要な場合に最適です。Filestore は最大 25GB/s のスループットを提供し、GKE や Compute Engine からマウント可能です。\n\n📚 参考：\nhttps://cloud.google.com/filestore"
  },
  {
    "id": "A34",
    "question": "【ケーススタディ問題】この質問については、EHR Healthcareのケーススタディを参照してください。\n\nGoogle Cloud にワークロードを安全にデプロイするための技術的なアーキテクチャを定義する必要があります。また、検証済みのコンテナのみがGoogle Cloudサービスを使用してデプロイされるようにする必要があります。\n\n要件を達成するためにするべきことは何ですか？(2つ選択)",
    "type": "multi",
    "options": [
      {
        "id": "A",
        "text": "信頼されたサービスアカウントのみがレジストリからコンテナを作成してデプロイできるようにContainer Registryを構成する。"
      },
      {
        "id": "B",
        "text": "ワークロードをデプロイする前に、脆弱性スキャンを使用して脆弱性がないことを確認するようにContainer Registryを構成する"
      },
      {
        "id": "C",
        "text": "GKEでBinary Authorizationを有効にし、CI/CDパイプラインの一部としてコンテナに署名する。"
      },
      {
        "id": "D",
        "text": "Jenkinsを構成し、CI/CDパイプラインの一部としてKritisを利用してコンテナに暗号署名を行う。"
      }
    ],
    "answer": ["B", "C"],
    "explanation": "Google Cloud において安全なコンテナデプロイを実現するには、Binary Authorization の利用と Container Analysis による脆弱性スキャンが重要です。これにより、CI/CD パイプラインの中で署名・検証・スキャンというセキュリティ対策が自動化され、未検証のコンテナのデプロイを防止できます。\n\n📚 参考：\nhttps://cloud.google.com/docs/ci-cd/overview\nhttps://cloud.google.com/security-command-center/docs/concepts-web-security-scanner-overview"
  },
  {
    "id": "A35",
    "question": "あなたの会社では、アプリケーションのワークロードをCompute Engineで実行しています。アプリケーションは、本番環境、ステージング環境、開発環境に展開されています。本番環境はビジネス・クリティカルで24時間365日使用されていますが、ステージング環境と開発環境は営業時間中のみ使用されています。CFOから、これらの環境を最適化して、利用されない時間帯のコスト削減を実現するよう求められています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud Schedulerを使用して、営業時間後に開発環境とステージング環境を停止し、営業時間直前にそれらを開始するCloud Functionをトリガーする。"
      },
      {
        "id": "B",
        "text": "gcloudコマンドを使用して、営業時間外に開発インスタンスとステージングインスタンスのマシンタイプをより小さいマシンタイプに変更するシェルスクリプトを作成する。タスクを自動化するために、本番インスタンスの1つでシェルスクリプトをスケジュールする。"
      },
      {
        "id": "C",
        "text": "管理されたインスタンスグループに開発用とステージング用のアプリケーションを配置し、オートスケーリングを有効にする。"
      },
      {
        "id": "D",
        "text": "本番環境には通常のCompute Engineインスタンスを使用し、ステージング環境と開発環境にはプリエンプティブルVMを使用する。"
      }
    ],
    "answer": ["A"],
    "explanation": "Cloud SchedulerとCloud Functionsを組み合わせることで、指定時間にVMの起動と停止を自動化でき、ステージングや開発環境における非稼働時間帯のコストを削減できます。\n\n📚 参考：\nhttps://cloud.google.com/blog/products/storage-data-transfer/save-money-by-stopping-and-starting-compute-engine-instances-on-schedule"
  },
  {
    "id": "A36",
    "question": "あなたはGitソースリポジトリに格納されているプロジェクトの継続的なデプロイメントパイプラインを構築しており、本番環境にデプロイする前にコードの変更を確実に検証したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Spinnaker を使用して本番環境にビルドを配置し、本番環境の配置でテストを実行する。"
      },
      {
        "id": "B",
        "text": "Jenkinsを使用して、ステージングブランチとマスターブランチを構築する。完全なロールアウトを行う前に、10％のユーザーに対して変更をビルドして本番環境にデプロイする。"
      },
      {
        "id": "C",
        "text": "Spinnakerを使用して、red/blackのデプロイメント戦略を使用してビルドを本番環境にデプロイし、変更を簡単にロールバックできるようにする。"
      },
      {
        "id": "D",
        "text": "Jenkins を使用して、リポジトリ内のタグを監視する。ステージングタグをテスト用のステージング環境にデプロイする。テスト後、本番用のリポジトリにタグを付け、本番環境にデプロイする。"
      }
    ],
    "answer": ["D"],
    "explanation": "タグベースのデプロイメントは、意図したコミットだけが本番に反映されるように管理できる安全な方法です。Jenkinsはタグトリガーを用いてパイプラインを分岐させ、ステージングと本番の区別を明確に保ちます。\n\n📚 参考：\nhttps://stackify.com/continuous-delivery-git-jenkins/"
  },
  {
    "id": "A37",
    "question": "あなたの会社のユーザーフィードバックポータルは、2つのゾーンにレプリケートされた標準的なLAMPスタックで構成されています。us-central1 リージョンに配置され、データベースを除くすべてのレイヤーで自動スケールのマネージドインスタンスグループが使用されています。現在、このポータルサイトにアクセスできるのは、一部のお客様のみとなっており、この条件下では、ポータルは 99,99% の可用性 SLA を満たしています。しかし、次の四半期には、未登録のユーザーを含むあらゆるのユーザーがポータルを利用できるようにする予定です。あなたは、追加のユーザー負荷が発生したときにシステムがSLAを維持することを保証するために、アプリケーションのレジリエンスに関するテスト戦略を策定する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "ランダムなユーザ入力を作成し、少なくとも1つの層でオートスケールが発生するまで負荷を再生する。また、両方のゾーンのランダムなリソースを終了させることで、システムにカオスエンジニアリングを導入する。"
      },
      {
        "id": "B",
        "text": "新しいシステムをより多くのユーザグループに公開し、すべての層でオートスケール・ロジックが起動するまで、日ごとにグループサイズを大きくする。同時に、両方のゾーンのランダムなリソースを終了させる。"
      },
      {
        "id": "C",
        "text": "既存のユーザーの入力をキャプチャし、すべてのレイヤーでオートスケールがトリガーされるまで、キャプチャしたユーザーの負荷を再生する。同時に、いずれかのゾーンのすべてのリソースを終了させます。"
      },
      {
        "id": "D",
        "text": "既存ユーザーの入力を取得し、リソース使用率が80%を超えるまで、取得したユーザー負荷を再生する。また、既存ユーザのアプリ使用状況から推定ユーザ数を算出し、想定負荷の200%を処理できるだけのリソースを配置する。"
      }
    ],
    "answer": ["A"],
    "explanation": "現実に近いレジリエンステストには、ランダムな負荷と障害を導入する \"カオスエンジニアリング\" の実践が有効です。ゾーンごとのリソース障害やスケーリングの動作確認を通じて、99.99% SLA維持をテストできます。\n\n📚 参考： https://cloud.google.com/architecture/scalable-and-resilient-apps#test_your_resilience"
  },
  {
    "id": "A38",
    "question": "【ケーススタディ問題】この質問については、Helicopter Racing League (HRL) のケーススタディを参照してください。\n\nHRLは、テレメトリーなどのレースデータを保存するためのコスト効率の良い方法を探しています。彼らは、すべての過去の記録を保持し、前シーズンのデータのみを使用してモデルをトレーニングし、ボリュームと収集された情報の面でデータ蓄積の促進を計画したいと考えています。あなたは、データソリューションを提案する必要があります。\n\nHRLのビジネス要件とCEOのS.ホーク氏が表明した目標を踏まえた最適なソリューションは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "ストレージの増加を自動的に管理する機能と、MySQLとの互換性があるCloud SQLを使用する。シーズンごとに別々のデータベースインスタンスを使用する"
      },
      {
        "id": "B",
        "text": "拡張性が高く、ダウンタイムなしでスキーマのバージョンを変更できるCloud Spannerを使用する。シーズンを主キーとしてレースデータを分割する"
      },
      {
        "id": "C",
        "text": "スケーラビリティーとスキーマへのカラム追加機能を備えたBigQueryを使用する。シーズンに基づいてレースデータを分割する"
      },
      {
        "id": "D",
        "text": "拡張性と柔軟性に優れたドキュメントベースのデータベースであるFirestoreを使用する。コレクションを使用して、シーズンやイベントごとにレースデータを集約する"
      }
    ],
    "answer": ["C"],
    "explanation": "BigQueryは、コスト効率・スケーラビリティ・柔軟なスキーマ拡張に優れた分析データベースであり、過去データの保持・前シーズン限定のモデル学習・継続的なデータ蓄積に適します。\n\n📚 参考： https://cloud.google.com/bigquery"
  },
  {
    "id": "A39",
    "question": "【ケーススタディ問題】この質問については、Mountkirk Gamesのケーススタディを参照してください。\n\nMountkirk Gamesは、とあるリソースの物理的なロケーションを、Google Cloudのあるリージョンに限定したいと考えています。要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "リソースの配備先を制限する組織ポリシーを設定する"
      },
      {
        "id": "B",
        "text": "Cloud Monitoringでカスタムアラートを設定し、他のリージョンで作成されたリソースを無効にできるようにする"
      },
      {
        "id": "C",
        "text": "IAM条件を設定して、設定できるリソースを制限する"
      },
      {
        "id": "D",
        "text": "使用されていないリージョンのリソースのクォータを0に設定する"
      }
    ],
    "answer": ["A"],
    "explanation": "Google Cloudでは、組織ポリシーを使って、リソースの物理的ロケーションを制限できます。これにより、特定のリージョンにのみリソースを作成できるようになり、コンプライアンスやデータ主権要件に対応できます。\n\n📚 参考：https://cloud.google.com/resource-manager/docs/organization-policy/defining-locations"
  },
  {
    "id": "A40",
    "question": "ある会社では、レポートのソースとなる複数のオンプレミスのシステムがあります。これらのデータはメンテナンスが行き届いておらず、時間の経過とともに劣化しています。\n\nこれらのデータに対して、Googleが推奨する方法でデータの異常を検出したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud Datalabをオンプレミスシステムに接続する。Cloud Datalabを使用して、データを調査し、クリーニングする"
      },
      {
        "id": "B",
        "text": "Cloud Dataprepをオンプレミスシステムに接続する。Cloud Dataprepを使用して、データの探索とクリーニングを行う"
      },
      {
        "id": "C",
        "text": "Cloud Storageにファイルをアップロードする。Cloud Dataprepを使用して、データの検索とクリーニングを行う"
      },
      {
        "id": "D",
        "text": "Cloud Storageにファイルをアップロードする。Cloud Datalabを使用して、データの探索とクリーニングを行う"
      }
    ],
    "answer": ["C"],
    "explanation": "Cloud DataprepはGoogle Cloud上で提供される、非構造化・半構造化データの探索とクリーニングに特化したツールです。オンプレミスデータをCloud Storageにアップロードし、Dataprepで処理するのが推奨アーキテクチャです。\n\n📚 参考：https://cloud.google.com/dataprep"
  },
  {
    "id": "A41",
    "question": "【ケーススタディ問題】この質問については、Helicopter Racing League (HRL) のケーススタディを参照してください。\n\nHRLは、機械学習を使用した予測モデルの予測精度を向上させたいと考えています。彼らは、予測モデルの出力結果に対して解釈性を持たせるために、GoogleのAIプラットフォームを使用したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Google Cloudのオペレーションスイートを使用する"
      },
      {
        "id": "B",
        "text": "説明可能なAIを使う"
      },
      {
        "id": "C",
        "text": "Jupyter Notebooksを使う"
      },
      {
        "id": "D",
        "text": "Vision AIを使う"
      }
    ],
    "answer": ["B"],
    "explanation": "AI Explanations（説明可能なAI）は、機械学習モデルの各特徴量が予測にどの程度寄与したかを示すことで、モデルの出力の解釈を可能にします。これにより、HRLのような組織は、モデルの精度向上と透明性を確保できます。\n\n📚 参考：https://cloud.google.com/ai-platform/prediction/docs/ai-explanations/overview"
  },
  {
    "id": "A42",
    "question": "ミッションクリティカルなアプリケーションの災害対策をテストするための手順を作成する必要があります。Googleが推奨する方法とGCPのネイティブ機能を使用したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Deployment Managerを使用してサービスプロビジョニングを自動化する。Activity Logsを使用して、テストの監視とデバッグを行う。"
      },
      {
        "id": "B",
        "text": "gcloud スクリプトを使用してサービスプロビジョニングを自動化する。Cloud Operationsを使用して、テストの監視とデバッグを行う。"
      },
      {
        "id": "C",
        "text": "Deployment Manager を使用してサービス プロビジョニングを自動化する。Cloud Operations使用して、テストの監視とデバッグを行う。"
      },
      {
        "id": "D",
        "text": "gcloud スクリプトを使用してサービスプロビジョニングを自動化する。Activity Logs を使用してテストの監視とデバッグを行う。"
      }
    ],
    "answer": ["C"],
    "explanation": "Google が推奨する DR（災害復旧）戦略のひとつに、Deployment Manager を利用した構成管理と、Cloud Operationsによるモニタリング・ロギングの活用があります。これにより、テストの自動化と復旧プロセスの可視化が可能となり、ミッションクリティカルなアプリケーションの信頼性が向上します。\n\n📚 参考：https://cloud.google.com/solutions/dr-scenarios-planning-guide"
  },
  {
    "id": "A43",
    "question": "あなたの組織が公開しているアプリケーションは、将来の監査のために、すべてのメトリクスを5年間保持することが必要です。\n\nどのようなアプローチをとるべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "すべてのプロジェクトにCloud Monitoringを設定し、Google Cloud Storageにエクスポートする"
      },
      {
        "id": "B",
        "text": "すべてのプロジェクトにCloud Monitoringを設定し、BigQueryにエクスポートする。"
      },
      {
        "id": "C",
        "text": "セキュリティチームに各プロジェクトのログへのアクセス権を付与する。"
      },
      {
        "id": "D",
        "text": "すべてのプロジェクトにCloud Monitoringを設定し、デフォルトの保持ポリシーを適用する。"
      }
    ],
    "answer": ["A"],
    "explanation": "Cloud Monitoring（現在はCloud Monitoring）で収集したメトリクスを長期間保持する場合、Cloud Storageへのエクスポートが最適です。特に5年間の保持が求められるような場合、Coldline ストレージやアーカイブクラスを使用することでコストを抑えることができます。\n\n📚 参考：\nhttps://cloud.google.com/monitoring/monitoring-logs-export"
  },
  {
    "id": "A44",
    "question": "あなたの会社では、Compute Engineの複数のインスタンス上で実行されているアプリケーションがあります。このアプリケーションは、1日あたり1TBのログを生成します。コンプライアンス上の理由から、ログは最低でも2年間は保存する必要があります。ログは、30日間はアクティブなクエリに利用できる必要があります。その後は、監査目的のためだけに保存する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "すべてのインスタンスで実行される、パーティション化されたBigQueryテーブルにログをアップロードする毎日のcronジョブを作成する。time_partitioning_expiration を 30 日間に設定する。"
      },
      {
        "id": "B",
        "text": "すべてのインスタンスにOps Agentをインストールする。\nリージョンのCloud Storageのバケットにログをエクスポートするシンクを作成する。\n1ヶ月後にファイルをColdline Cloud Storageバケットに移動するObject Lifecycleルールを作成する。\nバケットロックを使って、バケットレベルのリテンションポリシーを設定する。"
      },
      {
        "id": "C",
        "text": "すべてのインスタンスで実行される毎日のcronジョブを書き、ログをCloud Storageのバケットにアップロードする。\nログをリージョンのCloud Storageバケットにエクスポートするシンクを作成する。\n1ヶ月後にファイルをColdline Cloud Storageバケットに移動するObject Lifecycleルールを作成する。"
      },
      {
        "id": "D",
        "text": "すべてのインスタンスにクラウドOps Agentをインストールする。\nログをパーティション化されたBigQueryテーブルにエクスポートするシンクを作成する。\ntime_partitioning_expirationを30日に設定する。"
      }
    ],
    "answer": ["B"],
    "explanation": "長期保持とコスト最適化を両立させるには、Cloud Logging から Cloud Storage にログをエクスポートし、Coldline ストレージへの移行を Object Lifecycle で設定するのがベストプラクティスです。さらに、リテンション期間の保証にはバケットロックの使用が必須です。\n\n📚 参考：https://cloud.google.com/logging/docs/export/configure_export_v2"
  },
  {
    "id": "A45",
    "question": "【ケーススタディ問題】この質問については、EHR Healthcareのケーススタディを参照してください。\n\nあなたは、EHRによるGoogle Cloudの使用が、来るべきプライバシーコンプライアンス監査に通過することを保証する責任があります。\n\n監査のためにするべきことは何ですか？（2つ選択）",
    "type": "multi",
    "options": [
      {
        "id": "A",
        "text": "Prometheusを導入して、EHRのWebベースのアプリケーションにおけるセキュリティ侵害を検知・防止する。"
      },
      {
        "id": "B",
        "text": "すべてのKubernetesワークロードにGKEプライベートクラスターを使用する"
      },
      {
        "id": "C",
        "text": "EHRのプロダクトの使用状況を、Google Cloudのコンプライアンスページにある準拠サービスリストと照合する。"
      },
      {
        "id": "D",
        "text": "EHRに対し、Google Cloudとの間でビジネスアソシエイト契約（BAA）を締結するよう助言する。"
      },
      {
        "id": "E",
        "text": "EHRのユーザー向けアプリケーションにFirebase認証を使用する。"
      }
    ],
    "answer": ["C", "D"],
    "explanation": "EHR HealthcareがHIPAAなどのプライバシー規制に準拠するには、Google Cloudの提供する準拠済みサービスの利用確認と、Googleとの間にBAA（業務提携契約）を締結することが必要です。これらは監査を通過するための公式かつ推奨される対応です。\n\n📚 参考：https://cloud.google.com/security/compliance/hipaa"
  },
  {
    "id": "A46",
    "question": "【ケーススタディ問題】この質問については、EHR Healthcareのケーススタディを参照してください。\n\n過去に設定ミスにより、インターネットからアクセスできないはずのバックエンドサーバーにパブリックIPアドレスが設定されていました。誰もバックエンドのCompute Engineインスタンスに外部IPアドレスを設定できないようにし、外部IPアドレスはフロントエンドのCompute Engineインスタンスでのみ設定できるようにする必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "フロントエンドのCompute Engineインスタンスでのみ外部IPアドレスを許可するという制約条件を持つ組織ポリシーを作成する"
      },
      {
        "id": "B",
        "text": "フロントエンドのCompute Engineインスタンスを持つプロジェクトのすべてのユーザーからcompute.networkAdminロールを取り消する"
      },
      {
        "id": "C",
        "text": "GCE_FRONTENDという名前のIdentity and Access Management (IAM)ロールを作成し、compute.addresss.create権限を付与する"
      },
      {
        "id": "D",
        "text": "組織のITスタッフをcompute.networkAdminロールにマッピングするIdentity and Access Management (IAM)ポリシーを作成する"
      }
    ],
    "answer": ["A"],
    "explanation": "特定のVMにのみ外部IPアドレスを許可したい場合、最適な方法は組織ポリシーで制約を設けることです。これにより、誤った構成によるデータ漏洩などのリスクを根本的に排除できます。\n\n📚 参考：https://cloud.google.com/resource-manager/docs/organization-policy/tags-organization-policy"
  },
  {
    "id": "A47",
    "question": "GCP上にMicrosoft SQL Serverをセットアップする必要があります。経営陣は、GCPリージョン内のいずれかのゾーンでデータセンターが停止した場合に、ダウンタイムが発生しないようにすることを要求しています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "高可用性を有効にして、Cloud SQLインスタンスを構成する。"
      },
      {
        "id": "B",
        "text": "Windows Failover Clusteringを使用してSQL ServerのAlways On Availability Groupsを設定する。ノードを異なるゾーンに配置する。"
      },
      {
        "id": "C",
        "text": "Cloud Spannerインスタンスをリージョン別インスタンス構成で構成する。"
      },
      {
        "id": "D",
        "text": "Windows Failover Clusteringを使用したAlways On Availability Groupsを使用して、Compute Engine上でSQL Serverを設定する。ノードを異なるサブネットに配置する。"
      }
    ],
    "answer": ["A"],
    "explanation": "高可用性（HA）構成を有効にしたCloud SQLインスタンスを使用することで、GCPリージョン内でゾーン障害が起きてもダウンタイムを最小化できます。HA構成ではプライマリとセカンダリにデータを冗長化して配置するため、インスタンスが利用不能になってもフェイルオーバーによって継続利用が可能です。\n\n📚 参考：https://cloud.google.com/sql/docs/sqlserver/high-availability"
  },
  {
    "id": "A48",
    "question": "お客様のアプリケーションでは、クレジットカードのトランザクションを処理する必要があります。PCI（Payment Card Industry）コンプライアンスの範囲を最小限にしたいが、トランザクションデータや、どの支払い方法が使われているかに関連するトレンド分析は行えるようにしたいと考えています。\n\nどのようにアーキテクチャを設計すべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "クレジットカードのデータのみを処理する別のプロジェクトを作成する"
      },
      {
        "id": "B",
        "text": "トークナイザサービスを作成し、トークン化されたデータのみを保存する"
      },
      {
        "id": "C",
        "text": "別のサブネットワークを作成し、クレジットカードデータを処理するコンポーネントを分離する"
      },
      {
        "id": "D",
        "text": "PCI データを処理するすべての仮想マシン（VM）にラベルを付けることで、監査の発見段階を効率化する"
      },
      {
        "id": "E",
        "text": "Google BigQuery へのログのエクスポートを有効にし、ACL とビューを使用して監査人と共有するデータの範囲を設定する"
      }
    ],
    "answer": ["B"],
    "explanation": "クレジットカードデータを直接保持せずに分析機能を維持するためには、トークン化（Tokenization）が有効です。トークン化により、PCI DSS の適用範囲を狭めることができ、かつ分析対象となるデータに対しても安全性を保てます。\n\n📚 参考：https://cloud.google.com/architecture/tokenizing-sensitive-cardholder-data-for-pci-dss"
  },
  {
    "id": "A49",
    "question": "あなたの会社は、ユーザーが会社のウェブサイトからダウンロードできるレンダリングソフトウェアを作成しています。お客様は世界中にいます。すべての顧客のために、遅延を最小限に抑えたいと考えています。Googleが推奨する方法に従いたいと考えています。\n\nファイルはどのように保存すればよいでしょうか。",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Multi-Regional Cloud Storageのバケットにファイルを保存する。"
      },
      {
        "id": "B",
        "text": "リージョナルCloud Storageのバケットにファイルを保存し、リージョンのゾーンごとに1つのバケットを作成する。"
      },
      {
        "id": "C",
        "text": "複数のリージョナルCloud Storageのバケットにファイルを保存し、リージョンごとにゾーンごとに1つのバケットを作成する。"
      },
      {
        "id": "D",
        "text": "複数のMulti-Regional Cloud Storageバケットにファイルを保存し、マルチリージョンごとに1つのバケットにする。"
      }
    ],
    "answer": ["D"],
    "explanation": "世界中のユーザーに対して遅延を最小限に抑えるには、Google Cloud のマルチリージョン Cloud Storage を活用するのが最適です。リージョン間の地理的な距離に応じて複数のマルチリージョンバケットを設けることで、より高速かつ冗長性の高い配信が可能となります。\n\n📚 参考: https://cloud.google.com/storage/docs/locations"
  },
  {
    "id": "A50",
    "question": "最近のクラウドインフラの財務監査で、ビデオエンコーディングとトランスコーディングに非常に多くのCompute Engineインスタンスが割り当てられていることが指摘されました。これらの仮想マシンは、ワークロードが完了した後も削除されなかったゾンビマシンであると疑われます。あなたは、どのVMインスタンスがアイドル状態であるかのリストを迅速に取得する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Google コンソールから、管理対象のインスタンスグループ内のどの Compute Engine インスタンスがヘルスチェックプローブに応答しなくなったかを特定する"
      },
      {
        "id": "B",
        "text": "gcloud compute instances listを使用して、idle: trueラベルが設定されている仮想マシンインスタンスをリストアップする。"
      },
      {
        "id": "C",
        "text": "各Compute Engineインスタンスにログインし、分析のためにディスク、CPU、メモリ、ネットワークの使用統計を収集する。"
      },
      {
        "id": "D",
        "text": "gcloud recommender コマンドを使用して、アイドル状態の仮想マシンインスタンスをリストアップする。"
      }
    ],
    "answer": ["D"],
    "explanation": "Google Cloud の Recommender API は、アイドル状態の仮想マシンを自動的に分析し、停止や削除の提案を行うことで、コスト最適化をサポートします。gcloud recommender コマンドを使えば、これらの推奨事項に基づいて即座に不要なリソースを特定できます。\n\n📚 参考: https://cloud.google.com/compute/docs/instances/viewing-and-applying-idle-vm-recommendations"
  },
  {
    "id": "B1",
    "question": "あなたの会社は、Linux RHEL 6.5+の仮想マシンをリフト＆シフト移行することを計画しています。仮想マシンは、オンプレミスのVMware環境で稼働しています。Googleが推奨する方法に従って、それらをCompute Engineに移行したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "現在のVMware環境で稼働している仮想マシンの評価を行う。\n移行プランを定義し、Migrate for Compute Engineの移行RunBookを準備し、移行を実行する"
      },
      {
        "id": "B",
        "text": "現在のVMware環境で稼働している仮想マシンの評価を行う。\n選択したすべての仮想マシンにサードパーティ製エージェントをインストールする。\nすべての仮想マシンをCompute Engineに移行する"
      },
      {
        "id": "C",
        "text": "現在のVMware環境で稼働している仮想マシンの評価を行う。\nすべてのディスクのイメージを作成するCompute Engine上のディスクをインポートする。\nブートディスクがインポートしたものである標準的な仮想マシンを作成する。"
      },
      {
        "id": "D",
        "text": "アプリケーションのリストとその依存関係に基づいて、移行計画を定義する。\nMigrate for Compute Engineを使用して、すべての仮想マシンを個別にCompute Engineに移行する"
      }
    ],
    "answer": ["A"],
    "explanation": "Google の推奨する移行方法では、依存関係やグルーピングを考慮して RunBook を使った段階的なマイグレーションがベストプラクティスです。\n仮想マシンを個別に移行する方法は非推奨で、サービスの連携や可用性を損なう可能性があります。\n\n📚 参考: https://cloud.google.com/architecture/migrating-vms-migrate-for-compute-engine-getting-started"
  },
  {
    "id": "B2",
    "question": "Cloud Run for Anthosにデプロイされたアプリケーションを管理しているあなたは、アプリケーションの新バージョンをデプロイするための戦略を定義する必要があります。新しいコードを本番トラフィックのサブセットで評価し、ロールアウトを続行するかどうかを決定したいと思います。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "新しいリビジョンでCloud Runをデプロイする。リビジョン間のトラフィックパーセンテージを設定する。"
      },
      {
        "id": "B",
        "text": "新しいサービスを新しいバージョンでCloud Runにデプロイする。両方のサービスの前にCloud Load Balancingインスタンスを追加する。"
      },
      {
        "id": "C",
        "text": "Cloud RunのGoogle Cloud Consoleページで、開発ブランチにCloud Buildを使用して継続的なデプロイメントを設定する。Cloud Buildのトリガーの一部として、置換変数TRAFFIC_PERCENTAGEに、新バージョンに誘導したいトラフィックの割合を設定する。"
      },
      {
        "id": "D",
        "text": "Google Cloud Consoleで、Cloud Run上のアプリケーションの新バージョンを指す新しいサービスでTraffic Directorを設定する。トラフィックの小さな割合をアプリケーションの新バージョンに送るようにTraffic Directorを設定する。"
      }
    ],
    "answer": ["A"],
    "explanation": "Cloud Runでは、複数のリビジョン間でトラフィックを段階的に移行することで、カナリアリリースのような戦略的なロールアウトが可能です。\nこの方法を使えば、問題があれば即座に以前のバージョンにロールバックできます。\n\n📚 参考: https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration"
  },
  {
    "id": "B3",
    "question": "データベース管理チームから、Google Compute Engine上で稼働している新しいデータベースサーバーのパフォーマンスを向上させるためのサポートを依頼されました。データベースは、パフォーマンス統計をインポートして正規化するためのもので、Debian Linux上のMySQLで構築されています。n1-standard-8の仮想マシンには、80GBのSSD永続ディスクが搭載されています。\n\nこのシステムからより良いパフォーマンスを得るために、何を変更すべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "PostgreSQLが動作する仮想マシンを新規に作成する"
      },
      {
        "id": "B",
        "text": "データベースへの一括挿入を使用するようにすべてのバッチジョブを変更する"
      },
      {
        "id": "C",
        "text": "仮想マシンのメモリを64GBに増設する。"
      },
      {
        "id": "D",
        "text": "パフォーマンス・メトリクス・ウェアハウスをBigQueryに移行する"
      },
      {
        "id": "E",
        "text": "SSD永続ディスクのサイズを動的に500GBに変更する"
      }
    ],
    "answer": ["E"],
    "explanation": "Google Cloud の永続ディスクは、ディスク容量が大きいほどスループットと IOPS が向上します。\n特にリージョナル SSD PD の場合、1 GB 増加するごとに 30 IOPS の性能向上が得られます。\nそのため、既存の 80GB から 500GB に増やすことで、MySQL データベースのパフォーマンスが顕著に向上します。\n\n📚 参考: https://cloud.google.com/compute/docs/disks"
  },
  {
    "id": "B4",
    "question": "あなたのお客様は、企業のアプリケーションをGoogle Cloud Platformに移行しています。セキュリティチームは、組織内のすべてのプロジェクトを詳細に把握したいと考えています。あなたは、Google Cloud Resource Managerをプロビジョニングし、自分を組織の管理者として設定します。\n\nセキュリティチームにどのようなGoogle Cloud Identity and Access Management（Cloud IAM）ロールを与えるべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "組織Viewer、プロジェクトViewer"
      },
      {
        "id": "B",
        "text": "組織Viewer、プロジェクトOwner"
      },
      {
        "id": "C",
        "text": "プロジェクトOwner、ネットワークAdministrator"
      },
      {
        "id": "D",
        "text": "組織Administrator、プロジェクトBrowser"
      }
    ],
    "answer": ["A"],
    "explanation": "セキュリティチームが組織内のすべてのプロジェクトの構成を確認できるようにするには、読み取り専用の IAM 権限が適しています。\nそのため「組織Viewer」と「プロジェクトViewer」の組み合わせが最も安全かつ適切な選択です。\n\n📚 参考: https://cloud.google.com/iam/docs/using-iam-securely"
  },
  {
    "id": "B5",
    "question": "あなたの会社では、オンプレミスのデータセンターをクラウドに移行しています。移行の一環として、ワークロードのオーケストレーションにGoogle Kubernetes Engine（GKE）を統合したいと考えています。また、アーキテクチャの一部はPCI DSSに準拠している必要があります。\n\n次のうち、最も正確な情報はどれですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "App Engineは、GCPのコンピュートプラットフォームの中で唯一、PCI DSSホスティングの認定を受けている。"
      },
      {
        "id": "B",
        "text": "GKE は共有ホスティングとみなされるため、PCI DSS で使用することはできない。"
      },
      {
        "id": "C",
        "text": "GKE は、PCI DSS に準拠した環境を構築するために必要なツールを提供する。"
      },
      {
        "id": "D",
        "text": "Google Cloud Platform は PCI に準拠していると認定されているため、すべての Google Cloud サービスを使用することができる。"
      }
    ],
    "answer": ["C"],
    "explanation": "GCPは、GKEをはじめとする複数のサービスにおいてPCI DSSの認定を受けていますが、すべてのサービスが対象ではありません。\nGKE は、PCI DSS 環境を構築するための必要なツールや設定を提供しています。\n\n📚 参考: https://cloud.google.com/security/compliance/pci-dss\nhttps://cloud.google.com/architecture/pci-dss-and-gke-guide"
  },
  {
    "id": "B6",
    "question": "あなたの会社では、App Engine Standardを使用したサポートチケットソリューションを導入しています。App Engineアプリケーションを含むプロジェクトには、Cloud VPNトンネルを通じて会社のオンプレミス環境に接続されたVirtual Private Cloud（VPC）ネットワークがすでにあります。あなたは、App Engineアプリケーションが会社のオンプレミス環境で実行されているデータベースと通信できるようにしたいと思います。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      { "id": "A", "text": "Google のプライベートアクセスを設定する。" },
      { "id": "B", "text": "サービスのプライベートアクセスを設定する。" },
      { "id": "C", "text": "サーバーレス VPC アクセスを構成する。" },
      {
        "id": "D",
        "text": "オンプレミスのホストのみにGoogleのプライベートアクセスを設定する。"
      }
    ],
    "answer": ["C"],
    "explanation": "サーバーレス VPC アクセスを使用すると、Google Cloud のサーバーレス環境（App Engine、Cloud Run、Cloud Functionsなど）から VPC ネットワークに内部 IP 経由でアクセスできます。\nこの設定により、App Engine アプリがオンプレミスにあるリソースと安全に通信できます。\n\n📚 参考: https://cloud.google.com/vpc/docs/serverless-vpc-access#use_cases"
  },
  {
    "id": "B7",
    "question": "あなたのWebアプリケーションは、Google Kubernetes Engineを使用して複数のワークロードを管理しています。あるワークロードは、ポッドのスケーリングや再起動後も一貫したホスト名のセットを必要とします。\n\nこれを実現するために、Kubernetesのどの機能を使うべきでしょうか？",
    "type": "single",
    "options": [
      { "id": "A", "text": "永続ボリューム" },
      { "id": "B", "text": "ロールベースのアクセスコントロール" },
      { "id": "C", "text": "コンテナの環境変数" },
      { "id": "D", "text": "StatefulSets" }
    ],
    "answer": ["D"],
    "explanation": "StatefulSet は、スケジュールされた場所にかかわらず GKE が保持する一意で永続的な ID と固有のホスト名を持つ Pod のセットを表します。Kafka や MySQL など、永続的な ID が必要なステートフルアプリケーションに適しています。\n\n📚 参考: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset"
  },
  {
    "id": "B8",
    "question": "TerramEarthには、クラウドに移行できないレガシーWebアプリケーションがあります。しかし、アプリケーションを監視するクラウドネイティブな方法を構築したいと考えています。アプリケーションがダウンした場合は、できるだけ早くURLが「Site is unavailable」ページを指すようにしたい。また、運用チームが問題の通知を受け取れるようにしたいと考えています。信頼性の高いソリューションを最小限のコストで構築する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud Runでスケジュールされたジョブを作成し、1分ごとにコンテナを起動する。このコンテナは、アプリケーションのURLをチェックする。アプリケーションがダウンしている場合は、URLを「サイトが利用できません」のページに切り替え、Opsチームに通知する"
      },
      {
        "id": "B",
        "text": "Compute Engine VM上に、1分ごとに実行されるcronジョブを作成する。cronジョブはPythonプログラムを起動して、アプリケーションのURLをチェックする。アプリケーションがダウンしている場合は、URLを「サイトが利用できません」ページに切り替えて、Opsチームに通知する"
      },
      {
        "id": "C",
        "text": "Cloud Error Reportingを使用して、アプリケーションのURLを確認する。アプリケーションがダウンしている場合は、URLを「サイトが利用できません」ページに切り替えて、運用チームに通知する"
      },
      {
        "id": "D",
        "text": "Cloud Monitoringのアップタイムチェックを作成して、アプリケーションのURLを検証する。失敗した場合は、URLを「サイトが利用できません」ページに切り替えるCloud FunctionをトリガーするPub/Subキューにメッセージを入れて、運用チームに通知する"
      }
    ],
    "answer": ["D"],
    "explanation": "Cloud Monitoring のアップタイムチェックにより、オンプレミスの URL をチェックし、失敗時に Cloud Function を介して自動的に通知やフェイルオーバー処理が行える構成が可能です。\n\n📚 参考: https://cloud.google.com/monitoring/uptime-checks"
  },
  {
    "id": "B9",
    "question": "Google Kubernetes Engineクラスターで、CPU負荷に応じて自動的にノードを追加・削除したい。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "デプロイメントを作成し、maxUnavailableとmaxSurgeのプロパティを設定する。gcloudコマンドを使用して、クラスタのオートスケーラを有効にする。"
      },
      {
        "id": "B",
        "text": "HorizontalPodAutoscalerを目標CPU使用率で設定する。GCPコンソールからCluster Autoscalerを有効にする。"
      },
      {
        "id": "C",
        "text": "HorizontalPodAutoscalerを目標CPU使用率で構成する。gcloudコマンドを使用して、クラスタの管理対象インスタンスグループでオートスケーリングを有効にする。"
      },
      {
        "id": "D",
        "text": "デプロイメントを作成し、maxUnavailable と maxSurge のプロパティを設定する。GCP コンソールから、クラスター管理下のインスタンスグループでオートスケーリングを有効にする。"
      }
    ],
    "answer": ["B"],
    "explanation": "Horizontal Pod Autoscalerは、CPU使用率などのメトリクスに基づいてPod数をスケーリングします。GKEではCluster Autoscalerを別途GCPコンソールから有効にする必要があり、Compute Engineのオートスケーラーと競合させないよう注意が必要です。\n\n📚 参考: https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler"
  },
  {
    "id": "B10",
    "question": "あなたはマイクロサービスベースのアプリケーションを公開していますが、一部のAPIリクエストは非常に長い時間がかかっていることが分かりました。APIへの各リクエストが多くのGCPサービスを横断することがわかっています。そのため、どのサービスが最も時間がかかるのかを知りたいと思っています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud Monitoring を使用して、API のレイテンシーが高いことを示すインサイトを探す"
      },
      {
        "id": "B",
        "text": "Cloud Trace を使ってアプリケーションを計測し、各マイクロサービスのリクエストの待ち時間を把握する"
      },
      {
        "id": "C",
        "text": "各リクエストのカスタムメトリクスをCloud Monitoringに送信する"
      },
      {
        "id": "D",
        "text": "アプリケーションにタイムアウトを設定することで、より早くリクエストを失敗させる"
      }
    ],
    "answer": ["B"],
    "explanation": "Cloud Traceは、マイクロサービス間の呼び出しにかかる遅延時間を視覚的に把握し、ボトルネックを特定するのに適しています。APIがどのサービスで時間を消費しているか詳細にトレース可能です。\n\n📚 参考: https://cloud.google.com/trace/docs"
  },
  {
    "id": "B11",
    "question": "Google Compute Engine上の本番用データベース仮想マシンには、データファイル用にext4形式の永続ディスクがあります。現在データベースのストレージ容量が逼迫しています。\n\n最小限のダウンタイムで問題を修復するにはどうすればよいでしょうか。",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "クラウドプラットフォームコンソールで、永続ディスクのスナップショットを作成し、そのスナップショットを新しいより大きなディスクに復元し、古いディスクをアンマウントし、新しいディスクをマウントし、データベースサービスを再起動する"
      },
      {
        "id": "B",
        "text": "Cloud Platform Consoleで、永続ディスクのサイズを増やし、Linuxのresize2fsコマンドを使用する"
      },
      {
        "id": "C",
        "text": "クラウドプラットフォームコンソールで、仮想マシンに接続された新しい永続ディスクを作成し、フォーマットしてマウントし、新しいディスクにファイルを移動するようにデータベースサービスを設定する"
      },
      {
        "id": "D",
        "text": "クラウドプラットフォームコンソールで、永続ディスクのサイズを増やし、Linuxのfdiskコマンドで新しいスペースが使用可能であることを確認する"
      },
      {
        "id": "E",
        "text": "仮想マシンをシャットダウンし、Cloud Platform Consoleを使用して永続ディスクのサイズを増やし、仮想マシンを再起動する"
      }
    ],
    "answer": ["B"],
    "explanation": "Linux の ext4 ファイルシステムでは、Cloud Console からディスクサイズを拡張した後に、`resize2fs` コマンドでファイルシステムを拡張することが可能です。これによりダウンタイムなしで容量拡張ができるため、本番環境に最適です。\n\n📚 参考: https://cloud.google.com/compute/docs/disks/add-persistent-disk"
  },
  {
    "id": "B12",
    "question": "全国展開している企業で、タイムクリティカルではないものも含め、複数のバッチワークロードにGCPを利用する予定です。また、HIPAA認証を受けたGCPサービスを利用し、サービスコストを管理する必要があります。\n\nGoogleのベストプラクティスを満たすためには、どのように設計すればよいでしょうか。",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "プリエンプト可能なVMをプロビジョニングし、コストを削減する。HIPAA に準拠していないすべての GCP サービスと API を無効にしてから使用を中止する。"
      },
      {
        "id": "B",
        "text": "同じリージョンで標準的な VM を提供してコストを削減する。HIPAAに対応していないすべてのGCPサービスとAPIの使用を中止する。"
      },
      {
        "id": "C",
        "text": "プリエンプト可能なVMをプロビジョニングし、コストを削減する。HIPAAに準拠していないすべてのGCPサービスおよびAPIの使用を中止する。"
      },
      {
        "id": "D",
        "text": "コストを削減するために、同じリージョンに標準的な VM をプロビジョニングする。HIPAAに準拠していないすべてのGCPサービスとAPIを無効にしてから使用を中止する。"
      }
    ],
    "answer": ["A"],
    "explanation": "バッチワークロードでタイムクリティカルでない処理には、コスト削減のためにプリエンプティブルVMが最適です。さらに、HIPAAに準拠する必要があるため、非準拠サービスは明示的に無効化し、使用を停止する必要があります。\n\n📚 参考: https://cloud.google.com/compute/docs/instances/preemptible\n📚 参考: https://cloud.google.com/security/compliance/hipaa"
  },
  {
    "id": "B13",
    "question": "Google Cloud Platformのリソースは、組織、フォルダ、プロジェクトを使って階層的に管理されています。\n\nクラウドのIAM（Identity and Access Management）ポリシーがこれらの異なるレベルに存在する場合、階層の特定のノードではどのようなポリシーが有効になるでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "有効なポリシーは、ノードで設定されたポリシーと、その継承元から継承したポリシーの組合わせ（和集合）である"
      },
      {
        "id": "B",
        "text": "有効なポリシーは、ノードで設定されたポリシーによってのみ決定される"
      },
      {
        "id": "C",
        "text": "有効なポリシーは、ノードで設定されたポリシーとその継承元から継承したポリシーに共通に含まれている（部分集合の）ポリシーである"
      },
      {
        "id": "D",
        "text": "有効なポリシーは、そのノードで設定されたポリシーであり、その継承元から継承したポリシーによって制限される"
      }
    ],
    "answer": ["A"],
    "explanation": "GCPのIAMポリシーは階層的に継承され、有効なアクセス権はノード自身に設定されたロールとその上位（親）リソースから継承されたロールの「和集合」によって構成されます。\n\n📚 参考: https://cloud.google.com/resource-manager/docs/cloud-platform-resource-hierarchy"
  },
  {
    "id": "B14",
    "question": "Webアプリケーションを提供するためにKubernetes Engine （GKE）上でクラスタを実行しています。ユーザーから、アプリケーションの特定の部分が応答しなくなったという報告がありました。デプロイメントのすべてのポッドが2秒後に再起動していることに気づきました。アプリケーションは、標準出力にログを書き込みます。あなたは、問題の原因を見つけるためにログを検査したいと考えています。\n\nどのように調査を行うことが適切ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "gcloud の認証情報を使用してクラスタに接続し、いずれかのポッドのコンテナに接続してログを読み取ります。"
      },
      {
        "id": "B",
        "text": "アプリケーションの応答しない部分を提供している特定のGKEコンテナのCloud Loggingログを確認する。"
      },
      {
        "id": "C",
        "text": "クラスターのノードとして機能している各Compute EngineインスタンスのCloud Loggingログを確認する。"
      },
      {
        "id": "D",
        "text": "クラスタのノードとして機能している各Compute EngineインスタンスのSerial Portログを確認する。"
      }
    ],
    "answer": ["B"],
    "explanation": "GKEではCloud Loggingがデフォルトで有効化されており、ポッドの標準出力に書かれたログは自動でCloud Loggingに転送されます。問題のコンテナに関するログを確認することで、アプリケーションの挙動を特定できます。\n\n📚 参考: https://cloud.google.com/kubernetes-engine/docs/how-to/logging"
  },
  {
    "id": "B15",
    "question": "Cloud Datastore のインデックスの欠落が原因で App Engine アプリケーションにエラーが発生しました。必要なインデックスを含むYAMLファイルを作成し、これらの新しいインデックスをCloud Datastoreにデプロイしたいと考えています。\n\nどのような方法でこのデプロイを完了させられますか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "設定ファイルにgcloud datastore create-indexesを指定する。"
      },
      {
        "id": "B",
        "text": "App EngineのデフォルトのCloud Storageバケットに設定ファイルをアップロードし、App Engineに新しいインデックスを検出させる。"
      },
      {
        "id": "C",
        "text": "組み込みのPythonモジュールにHTTPリクエストを作成し、インデックス設定ファイルをアプリケーションに送信する"
      },
      {
        "id": "D",
        "text": "GCPコンソールで、Datastore Adminを使用して現在のインデックスを削除し、新しい構成ファイルをアップロードする。"
      }
    ],
    "answer": ["A"],
    "explanation": "gcloud datastore create-indexes コマンドは、YAML形式のインデックス定義ファイルから必要なインデックスを Cloud Datastore にデプロイするための公式な方法です。これによりアプリケーションで発生するインデックス不足によるエラーを修正できます。\n\n📚 参考: https://cloud.google.com/appengine/docs/standard/python/datastore/indexes"
  },
  {
    "id": "B16",
    "question": "アップデートが必要なApp Engineアプリケーションがあります。現在のアプリケーションのバージョンを置き換える前に、本番トラフィックでアップデートをテストしたいと考えています。\n\nどのようにすればよいでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "新しいVPCにアップデートを配置し、GoogleのグローバルHTTPロードバランシングを使用して、アップデートと現行のアプリケーションの間でトラフィックを分割する。"
      },
      {
        "id": "B",
        "text": "Instance Group Updater を使用してアップデートを展開し、部分的なロールアウトを作成することで、カナリアテストを行うことができます。"
      },
      {
        "id": "C",
        "text": "App Engine アプリケーションに新しいバージョンとしてアップデートを展開し、新しいバージョンと現在のバージョンでトラフィックを分割する。"
      },
      {
        "id": "D",
        "text": "新しいApp Engineアプリケーションとしてアップデートを配置し、GoogleのグローバルHTTPロードバランシングを使用して、新しいアプリケーションと現在のアプリケーションの間でトラフィックを分割する。"
      }
    ],
    "answer": ["C"],
    "explanation": "App Engine では複数のバージョンを同一サービス内にデプロイし、トラフィックをバージョンごとに分割する機能があります。この仕組みを活用することで、本番トラフィックの一部を新バージョンに向けてテストを行う A/B テストやカナリアリリースが可能になります。\n\n📚 参考: https://cloud.google.com/appengine/docs/standard/python/splitting-traffic"
  },
  {
    "id": "B17",
    "question": "10TBのオンプレミスデータベースをCloud Storageに移行したいと考えています。この作業にかかる時間、全体のコスト、データベースの負荷を最小限に抑えたいと考えています。オンプレミス環境とGoogle Cloudの間の帯域幅は1 Gbpsです。移行にあたってはGoogleが推奨する方法に従いたいと考えています。\n\nどのようにすればよいでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "データベースから直接データを読み込んで、Cloud Storageに書き込むDataflowジョブを開発する。"
      },
      {
        "id": "B",
        "text": "商用パートナーのETLソリューションを使って、オンプレミスのデータベースからデータを抽出し、Cloud Storageにアップロードする。"
      },
      {
        "id": "C",
        "text": "Transfer Applianceを使用してオフライン移行を行う。"
      },
      {
        "id": "D",
        "text": "gsutil -m でデータを圧縮してアップロードし、マルチスレッドコピーを可能にする。"
      }
    ],
    "answer": ["D"],
    "explanation": "10TBのデータを1Gbpsの帯域幅で転送するには約30時間かかります。ネットワーク経由の高速転送が望ましい場合、gsutil の -m オプションで並列アップロードを行い、データを事前に圧縮して帯域効率を高めるのがベストプラクティスです。\n\n📚 参考: https://cloud.google.com/architecture/migration-to-google-cloud-transferring-your-large-datasets"
  },
  {
    "id": "B18",
    "question": "HRLの開発チームは、毎週火曜日の夜3時（UTC）に、レース結果を予想するアプリケーションの新バージョンをリポジトリにリリースしています。HRLのセキュリティチームは、Airwolfと呼ばれる社内侵入テスト用Cloud Functionを開発しました。セキュリティチームは、毎週火曜日にリリースされるこのアプリケーションに対してAirwolfを実行したいと考えています。あなたはAirwolfが毎週定期的に実行されるようにセットアップする必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud Functionを起動するPub/Subキューに通知するように展開ジョブを設定する"
      },
      {
        "id": "B",
        "text": "IAM（Identity and Access Management）とConfidential Computingを設定して、Cloud Functionをトリガーする"
      },
      {
        "id": "C",
        "text": "Cloud Tasksと、Cloud FunctionのトリガーとなるCloud Storageのバケットを設定する"
      },
      {
        "id": "D",
        "text": "Cloud Loggingシンクと、Cloud FunctionのトリガーとなるCloud Storageバケットを設定する"
      }
    ],
    "answer": ["A"],
    "explanation": "Pub/Sub と Cloud Function を連携させることで、イベントベースの自動実行が可能になります。特にCI/CDパイプラインの一部としてジョブをデプロイし、Pub/Sub経由で Cloud Function を起動することで、毎週のリリースに合わせた侵入テストを自動化できます。\n\n📚 参考: https://cloud.google.com/scheduler/docs/tut-pub-sub"
  },
  {
    "id": "B19",
    "question": "あなたはMountkirk GamesにFirestoreを実装しています。Mountkirk Gamesは、古いゲームのFirestoreデータベースに新しいゲームがプログラムでアクセスできるようにしたいと考えています。\n\nアクセスは可能な限り制限する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "古いゲームのGoogle Cloudプロジェクトでサービスアカウント（SA）を作成し、そのSAにFirebase Adminロールを与え、新しいゲームを古いゲームのプロジェクトに移行する"
      },
      {
        "id": "B",
        "text": "古いゲームのGoogle Cloudプロジェクトでサービスアカウント（SA）を作成し、SAにOrganization Adminロールを与え、さらに両方のプロジェクトでFirebase Adminロールを与える"
      },
      {
        "id": "C",
        "text": "古いゲームのGoogle Cloudプロジェクトでサービスアカウント（SA）を作成し、新しいゲームのIAMページでこのSAを追加し、両方のプロジェクトでFirebase Adminロールを与える"
      },
      {
        "id": "D",
        "text": "古いゲームのGoogle Cloudプロジェクトでサービスアカウント（SA）を作成し、新しいゲームのIAMページで2つ目のSAを追加し、両方のSAに組織管理者ロールを与える"
      }
    ],
    "answer": ["C"],
    "explanation": "新しいゲームが古いゲームのFirestoreにアクセスするためには、古いゲームのプロジェクトでサービスアカウント（SA）を作成し、そのSAを新しいゲーム側でIAMに追加し、アクセス許可を与えるのがベストプラクティスです。\n\n📚 参考: https://cloud.google.com/iam/docs/granting-changing-revoking-access"
  },
  {
    "id": "B20",
    "question": "あなたは、Compute Engine上で動作するアプリケーションの全体設計しています。ゾーン障害が発生した場合、アプリケーションは別のゾーンで最新のアプリケーションデータを使ってできるだけ早く復旧させる必要があります。あなたは、この要件を満たすためにソリューションを設計する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "アプリケーション用のインスタンステンプレートでCompute Engineインスタンスを構成し、アプリケーションデータにはリージョナル永続ディスクを使用する。ゾーン障害が発生するたびに、インスタンステンプレートを使用して、同じリージョン内の別のゾーンでアプリケーションをスピンアップする。"
      },
      {
        "id": "B",
        "text": "アプリケーション用のインスタンステンプレートでCompute Engineインスタンスを構成し、アプリケーションデータにはリージョンの永続ディスクを使用する。アプリケーションデータには、リージョンの永続ディスクを使用する。"
      },
      {
        "id": "C",
        "text": "アプリケーション用のインスタンステンプレートでCompute Engineインスタンスを構成し、アプリケーションデータ用にリージョナル永続ディスクを使用する"
      },
      {
        "id": "D",
        "text": "アプリケーションデータの入ったディスクのスナップショットスケジュールを作成する。ゾーン障害が発生するたびに、最新のスナップショットを使用して、同じリージョン内の別のゾーンのディスクを復元する。"
      }
    ],
    "answer": ["A"],
    "explanation": "リージョナル永続ディスクは、同一リージョンの2つのゾーンにわたって同期されるため、ゾーン障害が発生しても迅速に別ゾーンでサービスを復旧できます。\n\n📚 参考: https://cloud.google.com/compute/docs/disks/high-availability-regional-persistent-disk"
  },
  {
    "id": "B21",
    "question": "あなたは、ビジネスクリティカルなトランザクションデータを含む単一のCloud SQL MySQL第2世代データベースを実装しています。致命的な障害が発生した場合に、最小限のデータが失われることを保証したいと考えています。\n\n要件を達成するために、どの機能を実装する必要がありますか？（2つ選択）",
    "type": "multi",
    "options": [
      { "id": "A", "text": "バックアップの自動化" },
      { "id": "B", "text": "準同期レプリケーション" },
      { "id": "C", "text": "バイナリロギング" },
      { "id": "D", "text": "シャーディング" },
      { "id": "E", "text": "リードレプリカ" }
    ],
    "answer": ["A", "C"],
    "explanation": "Cloud SQLでデータ損失を最小限に抑えるには、**自動バックアップ**と**バイナリログ（Binary Logging）**の有効化が推奨されます。これにより、障害時でもバックアップとログを使ってポイントインタイムリカバリが可能になります。\n\n📚 参考: https://cloud.google.com/sql/docs/mysql/backup-recovery/backups"
  },
  {
    "id": "B22",
    "question": "あなたの会社のテストスイートは、Linuxの仮想マシン上で1日中テストを実行するカスタムC++アプリケーションです。テスト用に確保された限られた数のオンプレミスサーバ上で、完全なテストスイートを実行するには数時間かかります。あなたの会社は、テストインフラをクラウドに移行して、システムへの変更を完全にテストするのにかかる時間を短縮しつつ、テストの変更をできる限り少なくしたいと考えています。\n\nあなたはどのクラウドインフラストラクチャを推奨しますか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Google Compute Engineのアンマネージドインスタンスグループとネットワークロードバランサー"
      },
      {
        "id": "B",
        "text": "Google App Engineとログ用のGoogle Cloud Logging"
      },
      {
        "id": "C",
        "text": "Google Cloud DataprocでApache Hadoopのジョブを実行し、各テストを処理する"
      },
      {
        "id": "D",
        "text": "オートスケーリング機能付きのCompute Engineのマネージドインスタンスグループ"
      }
    ],
    "answer": ["D"],
    "explanation": "長時間かかるテストスイートの高速化にはスケーラブルな環境が必要です。**Compute Engineのマネージドインスタンスグループ**は、スケーリングやテンプレート適用が可能なため、クラウドへの移行時に最小限の変更で高性能な実行環境を実現できます。\n\n📚 参考: https://cloud.google.com/compute/docs/instance-groups"
  },
  {
    "id": "B23",
    "question": "あなたの会社では、Compute Engine上で、ユーザーが好きな音楽を再生できるアプリケーションを実行しています。インスタンスの数は決まっています。ファイルはCloud Storageに保存され、データはユーザーに直接ストリーミングされます。ユーザーからの報告によると、人気のある曲の再生を何度も試みないと成功しないことがあるそうで、このアプリケーションのパフォーマンスを改善する必要があります。\n\n問題を解決するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "人気曲をCloudSQLにblobとしてコピーする。Cloud StorageがオーバーロードしたときにCloudSQLからデータを取得するようにアプリケーションコードを更新する。"
      },
      {
        "id": "B",
        "text": "Cloud Filestore NFSボリュームを作成し、Compute Engineにアタッチして人気のある曲をダウンロードする。インスタンスから音楽ファイルを直接提供する。"
      },
      {
        "id": "C",
        "text": "Compute Engineインスタンスでマネージドインスタンスグループを作成する。グローバルロードバランサーを作成し、次の2つのバックエンド（マネージドインスタンスグループとCloud Storageバケット）で構成する。バケットのバックエンドでCloud CDNを有効にする。"
      },
      {
        "id": "D",
        "text": "gcsfuseを使用してCloud Storageバケットをマウントし、Compute Engineインスタンスから音楽ファイルを直接配信する。"
      }
    ],
    "answer": ["C"],
    "explanation": "人気の音楽ファイルの読み込みパフォーマンスを向上させるには、Cloud CDN を有効にすることで世界中のユーザーに高速配信できます。ロードバランサを介して Cloud Storage バケットをバックエンドとして接続し、キャッシュを提供するのが Google のベストプラクティスです。\n\n📚 参考: https://cloud.google.com/cdn"
  },
  {
    "id": "B24",
    "question": "組織内のすべてのプロダクションプロジェクトのログを、他のプロジェクトのログを含めずに運用チームが保存できるようする必要があります。すべてのプロダクションプロジェクトは、1つのフォルダに格納されています。また、既存および新規のプロダクションプロジェクトのすべてのログが自動的に取り込まれるようにしたいとも考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "本番プロジェクトでログのエクスポートを作成し、ログシンクを本番プロジェクトのBigQueryデータセットに設定し、データセットでクエリを実行するためのIAMアクセスを運用チームに付与する。"
      },
      {
        "id": "B",
        "text": "運用プロジェクトでログのエクスポートを作成し、ログシンクを運用プロジェクトのCloud Storageバケットに設定する。"
      },
      {
        "id": "C",
        "text": "Productionフォルダに集約されたエクスポートを作成する。ログシンクを運用プロジェクトのCloud Storageのバケットに設定する。"
      },
      {
        "id": "D",
        "text": "Organizationリソースに集約されたエクスポートを作成する。ログシンクを運用プロジェクトのCloud Storageのバケットに設定する。"
      }
    ],
    "answer": ["C"],
    "explanation": "ログの自動集約には集約シンクの機能を利用します。Productionフォルダに対して集約シンクを作成すれば、今後追加されるプロダクションプロジェクトも含めてログを自動で収集し、Cloud Storage などに出力できます。\n\n📚 参考: https://cloud.google.com/logging/docs/export/aggregated_sinks"
  },
  {
    "id": "B25",
    "question": "あなたの会社は、外部ユーザーがファイルをアップロードして共有できるように、モノリシックな3層のアプリケーションを開発しました。このソリューションは簡単には拡張できず、信頼性にも欠けています。開発チームは、マイクロサービスと完全なマネージドサービスのアプローチを採用するために、アプリケーションを再構築したいと考えていますが、その努力が価値あるものであることをリーダーに納得させる必要があります。\n\nどのような利点をリーダーに強調すべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "このプロセスは、Migrate for Compute Engineで自動化できます。"
      },
      {
        "id": "B",
        "text": "モノリシックなソリューションは、Dockerを使ってコンテナに変換することができます。生成されたコンテナは、Kubernetesクラスターにデプロイすることができます。"
      },
      {
        "id": "C",
        "text": "新しいアプローチでは、コストが大幅に削減され、基礎となるインフラの管理が容易になり、CI/CDパイプラインを自動的に管理できるようになります。"
      },
      {
        "id": "D",
        "text": "新しいアプローチでは、インフラストラクチャとアプリケーションの切り離し、新機能の開発とリリース、基盤となるインフラストラクチャの管理、CI/CDパイプラインの管理とA/Bテストの実行、そして必要に応じたソリューションの拡張が容易になります。"
      }
    ],
    "answer": ["D"],
    "explanation": "モノリシックからマイクロサービスへの移行は、スケーラビリティ、可用性、開発の効率性を大幅に向上させます。インフラとアプリの分離、新機能の迅速なリリース、柔軟なスケールが可能となるため、リーダーにはこれらの利点を説明することが重要です。\n\n📚 参考: https://cloud.google.com/architecture/migrating-a-monolithic-app-to-microservices-gke"
  },
  {
    "id": "B26",
    "question": "あなたの開発チームは、毎晩のバッチ処理を高速化するために、Google Compute Engine （GCE） の仮想マシン （VM） のバッチサーバーに新しい Linux カーネルモジュールをインストールしました。インストールしてから2日後、50％のバッチサーバーが夜間のバッチ実行に失敗しました。あなたは、開発チームにフィードバックするために、失敗の詳細を収集したいと考えています。\n\nあなたはどのアクションを取るべきですか？（3つ選んでください。）",
    "type": "multi",
    "options": [
      {
        "id": "A",
        "text": "APIまたはCloud Consoleを使用して、デバッグGCEアクティビティログを読む"
      },
      {
        "id": "B",
        "text": "gcloudまたはCloud Consoleを使用してシリアルコンソールに接続し、ログを観察する"
      },
      {
        "id": "C",
        "text": "デバッグ VM をイメージにエクスポートし、そのイメージをローカルサーバで実行すると、カーネルログメッセージがネイティブ画面に表示される"
      },
      {
        "id": "D",
        "text": "Google Cloud Monitoring のタイムラインを障害発生時に合わせて調整し、バッチサーバのメトリクスを観察する"
      },
      {
        "id": "E",
        "text": "障害が発生したサーバのライブマイグレーションイベントが発生したかどうかを、アクティビティログで確認する"
      },
      {
        "id": "F",
        "text": "Cloud Loggingを使用して、モジュールのログエントリを検索する"
      }
    ],
    "answer": ["B", "D", "F"],
    "explanation": "Linux カーネルモジュールの影響調査には、Cloud Logging によるログ確認、Cloud Monitoring の時系列メトリクス分析、シリアルコンソールによる詳細確認が有効です。特に、障害のあった時間帯に焦点をあててログを調査することが問題の切り分けに繋がります。\n\n📚 参考:\n- https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console\n- https://cloud.google.com/monitoring\n- https://cloud.google.com/logging"
  },
  {
    "id": "B27",
    "question": "あなたの会社は、世界中に分散しているユーザーが写真をアップロードし、選択した他のユーザーと共有できるようにする新しいアプリケーションを開発しています。このアプリケーションは、数百万人の同時ユーザーをサポートする予定です。開発者は、基盤となるインフラを構築・維持することなく、コードの作成に専念できるようにしたいと考えています。\n\nこのアプリケーションのデプロイには、どのサービスを使うべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud Endpoints"
      },
      {
        "id": "B",
        "text": "Google Kubernetes Engine"
      },
      {
        "id": "C",
        "text": "Compute Engine"
      },
      {
        "id": "D",
        "text": "Google App Engine"
      }
    ],
    "answer": ["D"],
    "explanation": "Google App Engine は、開発者がインフラ管理に煩わされることなく、アプリケーションコードの開発に集中できるフルマネージド型のプラットフォームです。自動スケーリングやセキュリティ機能、グローバル配信に対応しており、大量ユーザーを前提としたアプリケーションに適しています。\n\n📚 参考: https://cloud.google.com/terms/services"
  },
  {
    "id": "B28",
    "question": "【ケーススタディ問題】この質問については、Mountkirk Gamesのケーススタディを参照してください。\n\nMountkirk Games は、新しいゲーム アプリケーション プラットフォームから Google Cloud への接続を確保することを望んでいます。あなたは、プロセスを合理化し、Googleが推奨するプラクティスに従いたいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "デフォルトで難読化されているKubernetesのSecretを使用する。これらのシークレットをアプリケーションプラットフォームで使用するように設定する"
      },
      {
        "id": "B",
        "text": "秘密を保存するためにKubernetes Secretsを構成し、Application-Layer Secrets Encryptionを有効にして、Cloud Key Management Service (Cloud KMS)を使用して暗号化キーを管理する。これらのSecretsをアプリケーションプラットフォームが使用するように設定する"
      },
      {
        "id": "C",
        "text": "HashiCorp VaultをCompute Engine上で構成し、顧客が管理する暗号化キーとCloud Key Management Service（Cloud KMS）を使用して暗号化キーを管理する。これらのシークレットをアプリケーションプラットフォームで使用するように構成する"
      },
      {
        "id": "D",
        "text": "アプリケーションプラットフォームで使用されるWorkload Identityとサービスアカウントを設定する"
      }
    ],
    "answer": ["D"],
    "explanation": "GKE 上のアプリケーションが Google Cloud サービスに安全にアクセスするには、Workload Identity を使用するのが推奨されます。これにより、IAM サービスアカウントのキーを明示的に管理することなく、Kubernetes のサービスアカウントと IAM アカウントを安全に関連付けてアクセス制御できます。\n\n📚 参考: https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity"
  },
  {
    "id": "B29",
    "question": "ある会社は、Google Cloud上でWebサービスのインフラを実装しています。このWebサービスは、1秒間に50万件のリクエストからデータを受け取り、保存する必要があります。このデータは、属性セットの完全な一致に基づいて、バックエンドでリアルタイムで照会されます。一方で、ウェブサービスがリクエストを受け取らない期間もあります。サービスの展開にあたってはインフラのコストを最低限にしたいと考えています。\n\nこのアプリケーションには、どのWebサービスプラットフォームとデータベースを使用すべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud RunとBigQuery"
      },
      {
        "id": "B",
        "text": "Compute Engineのオートスケーリング・マネージドインスタンスグループとBigQuery"
      },
      {
        "id": "C",
        "text": "Compute Engineのオートスケーリング・マネージドインスタンスグループとCloud Bigtable"
      },
      {
        "id": "D",
        "text": "Cloud RunとCloud Bigtable"
      }
    ],
    "answer": ["D"],
    "explanation": "Cloud Run はトラフィックに応じてスケールするサーバーレスな実行環境で、リクエストがない時間帯は自動的にゼロスケールし、費用を抑えることができます。一方、Cloud Bigtable はリアルタイムな完全一致クエリに強く、高スループットを要するアプリケーションに最適です。BigQuery はバッチ分析向けであり、このようなリアルタイムクエリ用途には不向きです。\n\n📚 参考: https://cloud.google.com/run, https://cloud.google.com/bigtable"
  },
  {
    "id": "B30",
    "question": "あるアプリケーション開発チームは、現在使用しているログ収集ツールでは、新しいクラウドベースのプロダクトのニーズを満たせないと考えています。彼らは、エラーをキャプチャし、過去のログデータを分析するためのより良いツールを求めています。あなたは、彼らのニーズを満たすソリューションを見つける手助けをしたいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "ロギングのベストプラクティスに関するオンラインリソースのリストを送る"
      },
      {
        "id": "B",
        "text": "Google Cloud OperatinerのOps Agentをダウンロードしてインストールするように指示する"
      },
      {
        "id": "C",
        "text": "要件の定義と実行可能なロギングツールの評価を支援する"
      },
      {
        "id": "D",
        "text": "新機能を利用するために、現在のツールのアップグレードを支援する"
      }
    ],
    "answer": ["B"],
    "explanation": "Ops Agentは、アプリケーションやシステムのログを Cloud Logging に転送するための公式ツールで、GCP やハイブリッド環境に対応しています。リアルタイムエラー監視やログ解析のニーズに対応でき、Google が推奨する導入方法です。\n\n📚 参考: https://cloud.google.com/logging/docs/agent"
  },
  {
    "id": "B31",
    "question": "あなたは、30のマイクロサービスからなる大規模な分散型アプリケーションを設計しています。分散したマイクロサービスのそれぞれがデータベースのバックエンドに接続する必要があり、その接続に関わる認証情報を安全に保管したいと考えています。\n\nどこに認証情報を保存すべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "ACLでアクセスを制限した設定ファイルの中"
      },
      {
        "id": "B",
        "text": "環境変数の中"
      },
      {
        "id": "C",
        "text": "ソースコードの中"
      },
      {
        "id": "D",
        "text": "シークレット管理システムの中"
      }
    ],
    "answer": ["D"],
    "explanation": "認証情報はセキュリティ上、コードや設定ファイルに直接含めるべきではありません。Google Cloud では Secret Manager のような専用のシークレット管理システムを使用することで、アクセス制御、監査ログ、暗号化などの機能を通じて安全に管理できます。\n\n📚 参考: https://cloud.google.com/secret-manager"
  },
  {
    "id": "B32",
    "question": "あなたの会社のウェブホスティングプラットフォームで、エラーを含む本番環境のデプロイによる計画外のロールバック回数を減らす必要があります。QA/テストプロセスの改善により、80%の削減が達成されました。\n\nロールバックをさらに減らすために、あなたはさらにどの2つのアプローチを取ることができますか？（2つ選択）",
    "type": "multiple",
    "options": [
      {
        "id": "A",
        "text": "リレーショナルデータベースシステムへの依存度を低減する"
      },
      {
        "id": "B",
        "text": "モノリシックなプラットフォームをマイクロサービスに分割する"
      },
      {
        "id": "C",
        "text": "リレーショナルデータベースをNoSQLデータベースで置き換える"
      },
      {
        "id": "D",
        "text": "グリーン・ブルーのデプロイモデルを導入する"
      },
      {
        "id": "E",
        "text": "QA環境をカナリア・リリースで置き換える"
      }
    ],
    "answer": ["B", "D"],
    "explanation": "マイクロサービスへの分割は、障害の影響範囲を限定し、部分的なロールバックや迅速な修正が可能になります。\n\nまた、グリーン・ブルー・デプロイモデルは段階的な切り替えを通じて、安全かつ迅速なリリースが可能です。これらはいずれも本番ロールバックの頻度を下げる効果的な戦略です。\n\n📚 参考: https://cloud.google.com/architecture/implementing-deployment-and-testing-strategies-on-gke"
  },
  {
    "id": "B33",
    "question": "【ケーススタディ問題】この質問については、TerramEarthのケーススタディを参照してください。\n\nTerramEarthは、プライベートデータセンターに約1ペタバイト（PB）の車両テストデータを持っています。このデータを機械学習チームのためにCloud Storageに移動させたいと考えています。現在、1Gbpsの相互接続リンクが利用できます。機械学習チームは、1ヶ月後にデータの使用を開始したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Google CloudからStorage Transferサービスを設定して、データセンターからCloud Storageにデータを送信する。"
      },
      {
        "id": "B",
        "text": "暗号化されたUSBデバイスにファイルをエクスポートし、そのデバイスをGoogle Cloudに送信して、Cloud Storageへのデータのインポートを要求する"
      },
      {
        "id": "C",
        "text": "Google CloudからTransfer Appliancesをリクエストし、データをアプライアンスにエクスポートし、アプライアンスをGoogle Cloudに返却する。"
      },
      {
        "id": "D",
        "text": "他のユーザーが1Gbpsのリンクを消費していないことを確認し、マルチスレッド転送を使用してデータをCloud Storageにアップロードする。"
      }
    ],
    "answer": ["C"],
    "explanation": "1PB のデータを 1Gbps のネットワーク経由で転送すると約 123 日かかります。要件として 1 ヶ月以内に使用開始する必要があるため、物理デバイスによるオフライン移行（Transfer Appliance）が最も適しています。\n\n📚 参考: https://cloud.google.com/transfer-appliance"
  },
  {
    "id": "B34",
    "question": "【ケーススタディ問題】この質問については、Mountkirk Gamesのケーススタディを参照してください。\n\nあなたは、定義されたビジネス要件と技術要件を満たす新しいゲームのために、ネットワークIngressを実装する必要があります。Mountkirk Gamesは、各地にある物理的なゲームインスタンスを複数のGoogle Cloudリージョンに配置したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "グローバルロードバランサーとGoogle Kubernetes Engineでkubemciを構成する"
      },
      {
        "id": "B",
        "text": "Compute Engineインスタンスを実行するマネージドインスタンスグループに接続するグローバルロードバランサーを設定する"
      },
      {
        "id": "C",
        "text": "AnthosのIngressをグローバルロードバランサーとGoogle Kubernetes Engineで構成する"
      },
      {
        "id": "D",
        "text": "Google Kubernetes Engineでグローバルロードバランサーを構成する"
      }
    ],
    "answer": ["C"],
    "explanation": "マルチリージョンに展開された GKE クラスタでグローバル Ingress を構成するには、推奨される方法は Anthos Ingress の使用です。\nkubemci は非推奨であり、マルチクラスタIngress構成は Anthos でサポートされています。\n\n📚 参考: https://cloud.google.com/kubernetes-engine/docs/concepts/multi-cluster-ingress"
  },
  {
    "id": "B35",
    "question": "あなたの会社は最近、ユーザーを管理するためにCloud Identityを有効にしました。また、Google Cloud Organization も設定されています。セキュリティチームは、組織の一部となるプロジェクトを保護する必要があります。今後、ドメイン外のIAMユーザーがパーミッションを取得することを禁止したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "ドメインごとにIDを制限する組織ポリシーを設定する"
      },
      {
        "id": "B",
        "text": "1時間ごとにCloud Identityドメインに属さない全てのユーザーを全てのプロジェクトから削除するCloud Functionを実行するようにCloud Schedulerを設定する"
      },
      {
        "id": "C",
        "text": "技術系ユーザー(例: crawler@yourdomain.com)を作成し、ルート組織レベルでのプロジェクトオーナーの役割を与える。以下のようなbashスクリプトを作成します\n- 組織内の全プロジェクトのIAMルールをすべてリストアップする\n- 会社ドメインに属さないすべてのユーザーを削除する。組織内のプロジェクトにCompute Engineインスタンスを作成し、テクニカルユーザー認証で実行されるようにgcloudを構成する。bashスクリプトを1時間ごとに実行するcronジョブを設定します"
      },
      {
        "id": "D",
        "text": "サービスアカウントの作成を禁止する組織ポリシーを設定する"
      }
    ],
    "answer": ["A"],
    "explanation": "IAM ポリシーでドメイン外ユーザーを禁止したい場合、Organization Policy によるドメイン制限（`constraints/iam.allowedPolicyMemberDomains`）を使うのが推奨される方法です。これにより、会社ドメインに属さないユーザーがアクセス権を持つことを防げます。\n\n📚 参考: https://cloud.google.com/resource-manager/docs/organization-policy/restricting-domains"
  },
  {
    "id": "B36",
    "question": "あなたの会社では、Compute Engine上のインスタンスとオンプレミスのデータセンターとの間にプライベート接続を構築する必要性が出てきました。接続に際しては、最低でも20Gbpsの帯域幅が必要です。また、Googleが推奨するプラクティスに従いたいとも考えています。\n\nどのように接続をセットアップしますか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "VPCを作成し、単一のCloud VPNを使用してオンプレミスのデータセンターに接続する"
      },
      {
        "id": "B",
        "text": "VPCを作成し、専用 Interconnectを使用してオンプレミスのデータセンターに接続する"
      },
      {
        "id": "C",
        "text": "Cloud Content Delivery Network（Cloud CDN）を作成し、専用 Interconnectを使用してオンプレミスデータセンターに接続する"
      },
      {
        "id": "D",
        "text": "Cloud Content Delivery Network（Cloud CDN）を作成し、単一のCloud VPNを使用してオンプレミス・データセンターに接続する"
      }
    ],
    "answer": ["B"],
    "explanation": "20Gbps 以上の帯域を確保する場合は、Cloud VPN や Partner Interconnect ではなく、**専用 Interconnect** を使うことが Google の推奨です。\n\n専用 Interconnect は最大 80Gbps にも対応可能で、安定・高速なオンプレミス接続が求められるユースケースに最適です。\n\n📚 参考: https://cloud.google.com/network-connectivity/docs/interconnect/concepts/overview"
  },
  {
    "id": "B37",
    "question": "あなたは、新しいプロダクトのローンチにあたってWebトラフィックを提供するために、オートスケーリングのインスタンスグループを設定しました。インスタンスグループをHTTP（S）ロードバランサーのバックエンドサービスとして設定した後、仮想マシン（VM）インスタンスが1分ごとに終了し、再起動していることに気づきます。インスタンスはパブリックIPアドレスを持っていません。\n\ncurlコマンドを使用して、各インスタンスから適切なWebレスポンスが得られていることを確認しています。バックエンドが正しく構成されていることを確認したいと思います。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "各インスタンスにロードバランサーの名前でタグを作成する。ロードバランサーの名前を送信元、インスタンスタグを送信先とするファイアウォールルールを設定する"
      },
      {
        "id": "B",
        "text": "各インスタンスにパブリックIPを割り当て、ロードバランサーがインスタンスのパブリックIPに到達することを許可するファイアウォールルールを設定する"
      },
      {
        "id": "C",
        "text": "HTTP/HTTPSのソーストラフィックがロードバランサーに到達することを許可するファイアウォールルールが存在することを確認する"
      },
      {
        "id": "D",
        "text": "ロードバランサーのヘルスチェックがインスタンスグループ内のインスタンスに到達することを許可するファイアウォールルールが存在することを確認する"
      }
    ],
    "answer": ["D"],
    "explanation": "インスタンスが定期的に再起動する場合、原因の一つとしてロードバランサーのヘルスチェックが失敗している可能性があります。Cloud Load Balancer のヘルスチェックは、対象インスタンスの特定ポートへのアクセスを行います。\n\nヘルスチェックが適切に通過できないと、インスタンスが不健全と見なされ、自動的に停止・再起動の処理が行われます。\n\nしたがって、ヘルスチェックのトラフィックがインスタンスに到達できるようにするファイアウォールルールの存在を確認することが重要です。\n\n📚 参考: https://cloud.google.com/load-balancing/docs/health-checks"
  },
  {
    "id": "B38",
    "question": "あなたの会社では、複数のマイクロサービスを実行しているアプリケーションをAnthosクラスタ（旧Anthos GKE）にデプロイしています。このクラスターには、Anthos Service Mesh と Anthos Config Management の両方が構成されています。エンドユーザーから、アプリケーションの応答が非常に遅いと連絡がありました。あなたは、遅延の原因となっているマイクロサービスを特定したいと思います。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud ConsoleのService Meshビジュアライゼーションを使用して、マイクロサービス間のテレメトリーを検査する。"
      },
      {
        "id": "B",
        "text": "リクエストレイテンシーを収集するために、デフォルトのistioプロファイルを使用してistioを再インストールする。Cloud Consoleでマイクロサービス間のテレメトリを評価する。"
      },
      {
        "id": "C",
        "text": "Anthos Config Managementを使用して、関連するクラスタを選択するClusterSelectorを作成する。Google Kubernetes EngineのGoogle Cloud Consoleページで、「Workloads」を表示し、クラスタにフィルタをかけます。フィルタリングされたワークロードの構成を検査する。"
      },
      {
        "id": "D",
        "text": "Anthos Config Managementを使用してnamespaceSelectorを作成し、該当するクラスタの名前空間を選択する。Google Kubernetes EngineのGoogle Cloud Consoleページで、「ワークロード」を表示し、ネームスペースにフィルタをかけます。フィルタリングされたワークロードの構成を検査する。"
      }
    ],
    "answer": ["A"],
    "explanation": "Anthos Service Mesh にはマイクロサービス間の可視化とトラフィックメトリクス表示機能が含まれており、Service Mesh ビジュアライゼーション機能により、各サービスのレイテンシーやエラー率、トラフィック量をグラフィカルに確認することができます。\n\n特にパフォーマンスの問題（レスポンス遅延）がある場合には、可視化によって問題のボトルネックとなるマイクロサービスを迅速に特定できます。\n\n📚 参考: https://cloud.google.com/service-mesh/docs/observability/explore-dashboard"
  },
  {
    "id": "B39",
    "question": "あなたの会社は、すべてのGoogle CloudログをCloud Loggingに送信しています。セキュリティチームは、このログを監視したいと考えています。望ましくないファイアウォールの変更やサーバーの侵害などの異常が検出された場合、セキュリティチームが迅速に対応できるようにしたいと考えています。監視にあたってはGoogleが推奨するプラクティスに従いたいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "ログをCloud Storageバケットにエクスポートし、関連するログイベントでCloud Runをトリガーする。"
      },
      {
        "id": "B",
        "text": "Cloud Schedulerでcronジョブをスケジュールする。スケジュールされたジョブは、関連するイベントのために1分ごとにログを照会する。"
      },
      {
        "id": "C",
        "text": "ログをBigQueryにエクスポートし、BigQueryでクエリを起動して関連イベントのログデータを処理する。"
      },
      {
        "id": "D",
        "text": "ログをPub/Subトピックにエクスポートし、関連するログイベントでCloud Functionをトリガーする。"
      }
    ],
    "answer": ["D"],
    "explanation": "Cloud Logging のログシンクを Pub/Sub に接続し、Pub/Sub トピックに送られたログイベントを Cloud Function で即時処理する構成は、Google が推奨するリアルタイム監視アーキテクチャです。\n\nファイアウォール変更や不正アクセスなどの特定イベントを検知し、即座にメール通知や自動修復プロセスを起動することが可能です。\n\n📚 参考: https://cloud.google.com/blog/products/management-tools/automate-your-response-to-a-cloud-logging-event"
  },
  {
    "id": "B40",
    "question": "あなたの会社では、Google Kubernetes Engine （GKE）クラスタ上にアプリケーションを実行しています。クラスタは開発用、ステージング用、本番用に分かれています。その中で、開発とステージングでデプロイメントをテストすることなく、チームが本番クラスタにDockerイメージをデプロイできることがわかりました。あなたは、チームの自律性を尊重したいと考えていますが、このようなことが起こらないようにしたいと考えています。また、最小限の労力で迅速に導入できるGoogle Cloudソリューションを求めています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Kubernetesのライフサイクルフックを設定して、所定の環境での使用が承認されていないコンテナの起動を防止する。"
      },
      {
        "id": "B",
        "text": "与えられた環境での使用が承認されていない場合、コンテナの起動を防止するためにKubernetesアドミッションコントローラを作成する。"
      },
      {
        "id": "C",
        "text": "Dockerイメージが以前の環境でテストされていない限り、チームがDockerイメージを環境にデプロイすることを防ぐために、企業ポリシーを導入する。"
      },
      {
        "id": "D",
        "text": "開発クラスター、ステージングクラスター、本番クラスターに対して、バイナリ認証ポリシーを設定する。CI/CDパイプラインの一部として認証を作成する。"
      }
    ],
    "answer": ["D"],
    "explanation": "Binary Authorization は、Google Cloud 上の GKE クラスタで使用されるコンテナイメージが、社内ポリシーで定義された署名と認証ステップを経ない限り本番環境にデプロイされないように制御するセキュリティ機能です。\n\nCI/CD パイプラインで署名を追加し、段階的な承認を経て本番環境に届くことで、テスト漏れのイメージが実行されることを防ぎます。\n\n📚 参考: https://cloud.google.com/binary-authorization/docs/overview"
  },
  {
    "id": "B41",
    "question": "【ケーススタディ問題】この質問については、EHR Healthcareのケーススタディを参照してください。\n\nあなたは、EHRのオンプレミスシステムとGoogle Cloudの間のハイブリッド接続のための技術的なアーキテクチャを定義する必要があります。本番レベルのアプリケーションに対しては、Googleの推奨するプラクティスに従いたいと考えています。\n\nEHRヘルスケアのビジネス要件と技術要件を考慮した上で必要となるアーキテクチャは次のうちどれですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "1つのメトロ（都市）で2つのパートナー Interconnect接続を構成し、Interconnect接続が異なるメトロゾーンに配置されていることを確認する。"
      },
      {
        "id": "B",
        "text": "1つのメトロ（都市）で2つの専用 Interconnect接続を構成し、別のメトロで2つの接続を構成し、Interconnect接続が異なるメトロゾーンに配置されていることを確認する"
      },
      {
        "id": "C",
        "text": "EHR HealthcareとGoogle Cloudの間にダイレクトピアリングを設定し、少なくとも2つのGoogleのロケーションとピアリングしていることを確認する。"
      },
      {
        "id": "D",
        "text": "オンプレミスからGoogle Cloudへの2つのVPN接続を構成し、オンプレミスのVPNデバイスが別々のラックに配置されていることを確認する。"
      }
    ],
    "answer": ["B"],
    "explanation": "99.9% の可用性要件を満たすには、Google Cloud の推奨構成に従い、2 つのメトロ（都市）でそれぞれ 2 本の専用 Interconnect を構成する必要があります。これにより冗長性と障害耐性が確保され、業務継続性が保証されます。\n\n📚 参考: https://cloud.google.com/network-connectivity/docs/interconnect/tutorials/production-level-overview"
  },
  {
    "id": "B42",
    "question": "Cloud CDNを使用して、Compute Engineのインスタンスグループにホストされている静的なHTTP（S）ウェブサイトコンテンツを配信しています。キャッシュヒット率を改善したいと考えています。\n\nどのようにすればよいでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "キャッシュキーをカスタマイズして、キーからプロトコルを省略する。"
      },
      {
        "id": "B",
        "text": "静的コンテンツをCloud Storageのバケットに複製する。そのバケットのロードバランサーにCloudCDNを向ける。"
      },
      {
        "id": "C",
        "text": "キャッシュされたオブジェクトの有効期限を短くする。"
      },
      {
        "id": "D",
        "text": "HTTP(S)ヘッダのCache-Regionがユーザの最も近いリージョンを指すようにする。"
      }
    ],
    "answer": ["A"],
    "explanation": "Cloud CDN のデフォルトキャッシュキーにはプロトコルや完全なリクエスト URL が含まれるため、わずかな違い（HTTP vs HTTPS やクエリ文字列）でもキャッシュが効かなくなります。\n\nキャッシュキーをカスタマイズし、プロトコルを省略することで同一コンテンツへのキャッシュヒット率を向上させることができます。\n\n📚 参考: https://cloud.google.com/cdn/docs/caching#cache-keys"
  },
  {
    "id": "B43",
    "question": "【ケーススタディ問題】この質問については、Mountkirk Gamesのケーススタディを参照してください。\n\n開発チームは、Google Kubernetes Engine 上で動作するゲームの新バージョンを毎日リリースしています。ユーザーの視点から新バージョンの品質を評価するサービスレベルメトリクス（SLI）を作成したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "サービスレベルメトリクスとして、Server UptimeとError Rateを作成する"
      },
      {
        "id": "B",
        "text": "GKEのCPU使用率とメモリ使用率をサービスレベルのメトリクスとして作成する"
      },
      {
        "id": "C",
        "text": "サービスレベルメトリクスとして、「CPU Utilization」と「Request Latency」を作成する"
      },
      {
        "id": "D",
        "text": "サービスレベルメトリクスとして、Request LatencyとError Rateを作成する"
      }
    ],
    "answer": ["D"],
    "explanation": "ユーザー視点での新バージョンの品質評価には、実際のユーザー体験に関連するメトリクスが重要です。\n\nCPUやメモリ使用率は内部のインフラ監視には有効ですが、SLI（Service Level Indicator）としては Request Latency（応答時間）と Error Rate（エラー発生率）がより適切です。\n\n📚 参考: https://sre.google/workbook/implementing-slos/"
  },
  {
    "id": "B44",
    "question": "あなたの会社では、お客様のニーズに迅速に対応することに高い価値を置いています。ビジネス上の主な目的は、リリースのスピードとアジリティです。あなたは、誤ってセキュリティエラーが発生する可能性を減らしたいと考えています。\n\nあなたはどの2つのアクションを取ることができますか？（2つ選択）",
    "type": "multiple",
    "options": [
      {
        "id": "A",
        "text": "CI/CDパイプラインに統合されたコード署名と信頼できるバイナリリポジトリを有効にする"
      },
      {
        "id": "B",
        "text": "ソースコードセキュリティアナライザをCI/CDパイプラインの一部として使用する"
      },
      {
        "id": "C",
        "text": "すべてのコードのチェックインがセキュリティSMEによってピアレビューされるようにする"
      },
      {
        "id": "D",
        "text": "CI/CDパイプラインの一部として、脆弱性セキュリティスキャナを実行する。"
      },
      {
        "id": "E",
        "text": "コンポーネント間のすべてのインターフェースをユニットテストするためのスタブを確保する"
      }
    ],
    "answer": ["B", "D"],
    "explanation": "リリーススピードとセキュリティの両立を実現するには、CI/CD パイプラインにセキュリティ対策を組み込むのが重要です。\n\n静的コード解析（SAST）ツールによるソースコードの自動スキャン（B）と、脆弱性スキャナによる依存関係や構成のチェック（D）が効果的です。\n\n📚 参考: https://cloud.google.com/container-registry/docs/container-analysis"
  },
  {
    "id": "B45",
    "question": "あなたの会社では、Cloud Storageのバケットに機密データを保存しています。データアナリストは、バケットを読むためのIAM（Identity Access Management）権限を持っています。あなたは、データアナリストがオフィスネットワークの外からバケット内のデータを取得することを防ぎたいと考えています。\n\nどのようにすればよいでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "バケットからIAM権限を削除するCloud Functionと、バケットにIAM権限を追加する別のCloud Functionを作成する。Cloud Schedulerで業務開始・終了にパーミッションの変更を行う。"
      },
      {
        "id": "B",
        "text": "オフィスネットワークへのCloud VPNを作成し、オンプレミスのホストにプライベート Google アクセスを設定する。"
      },
      {
        "id": "C",
        "text": "バケットのあるプロジェクトを含むVPC Service Controlsの境界を作成する。オフィスネットワークのCIDRでアクセスレベルを作成する。"
      },
      {
        "id": "D",
        "text": "仮想プライベートクラウド（VPC）ネットワーク内のすべてのインスタンスに、ソース範囲のファイアウォールルールを作成する。オフィスネットワークのCIDRを使用する。"
      }
    ],
    "answer": ["C"],
    "explanation": "VPC Service Controls は、Cloud Storage 等へのデータアクセスをネットワーク境界で制限するセキュリティ機能です。\nCIDR を用いたアクセスレベルと組み合わせることで、オフィスネットワーク外からのアクセスを制限できます。\n\n📚 参考: https://cloud.google.com/vpc-service-controls/docs/overview"
  },
  {
    "id": "B46",
    "question": "【ケーススタディ問題】この質問については、EHR Healthcareのケーススタディを参照してください。\n\nあなたは、EHRのカスタマーポータルチームの開発者です。あなたのチームは最近、カスタマーポータルアプリケーションをGoogle Cloudに移行しました。アプリケーションサーバーの負荷が増大し、アプリケーションは多くのタイムアウトエラーを記録しています。そのため最近、アプリケーションアーキテクチャにPub/Subを組み込みましたが、アプリケーションはPub/Subのパブリッシングエラーを記録していません。今後は、パブリッシングのレイテンシーを改善したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Pub/Subのサブスクライバーのプルモデルからプッシュモデルに移行する。"
      },
      {
        "id": "B",
        "text": "Pub/Sub Total Timeoutのリトライ値を大きくする。"
      },
      {
        "id": "C",
        "text": "Pub/Subメッセージのバッチ処理をオフにする。"
      },
      {
        "id": "D",
        "text": "バックアップのPub/Subメッセージキューを作成する。"
      }
    ],
    "answer": ["C"],
    "explanation": "Pub/Sub ではバッチ処理を有効にすると、メッセージがネットワーク送信までキューに溜まるため、個々のメッセージのレイテンシが増大する可能性があります。\nレイテンシー最小化が目的であれば、バッチ処理をオフにすべきです。\n\n📚 参考: https://cloud.google.com/pubsub/docs/publisher#batching"
  },
  {
    "id": "B47",
    "question": "マネージドインスタンスグループで実行されているアプリケーションで、クリティカルではないアップデートを開発し、リリースしたいアップデートを含む新しいインスタンステンプレートを作成しました。アプリケーションへの影響を防ぐために、実行中のインスタンスは更新しないようにします。今後マネージドインスタンスグループで作成された新しいインスタンスには、新しいアップデートが含まれるようにしたい。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "新しいローリングアップデートを開始する。Opportunistic updateモードを選択する。"
      },
      {
        "id": "B",
        "text": "新規のローリングアップデートを開始する。プロアクティブアップデートモードを選択する。"
      },
      {
        "id": "C",
        "text": "新しいローリングリプレースメント操作を開始する。"
      },
      {
        "id": "D",
        "text": "新規にローリングリスタート運転を開始する。"
      }
    ],
    "answer": ["A"],
    "explanation": "Opportunistic updateモードでは、既存のインスタンスには影響せず、今後新規に作成されるインスタンスのみ新しいテンプレートが反映されます。プロアクティブモードでは既存インスタンスも対象になるため不適切です。\n\n📚 参考: https://cloud.google.com/compute/docs/instance-groups/rolling-out-updates-to-managed-instance-groups"
  },
  {
    "id": "B48",
    "question": "あなたのチームのシニアエンジニアが、新しいアプリケーションの設計で、ウェブサーバーにロードバランスされていないWebSocketとHTTPセッションを使用していると話します。あなたは、彼のアプリケーションがGoogle Cloud Platform上で適切に動作することを保証するために、彼を支援したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "エンジニアがWebSocketのコードをHTTPストリーミングを使用するように変換できるようにする"
      },
      {
        "id": "B",
        "text": "セキュリティチームと一緒に、WebSocket接続の暗号化要件を確認する"
      },
      {
        "id": "C",
        "text": "クラウドオペレーションチームとエンジニアがロードバランサーのオプションについて話し合う"
      },
      {
        "id": "D",
        "text": "WebソケットとHTTPセッションに依存しない分散型ユーザーセッションサービスを使用するように、エンジニアがアプリケーションを再設計するのを支援する"
      }
    ],
    "answer": ["C"],
    "explanation": "Google Cloud の HTTP(S) ロードバランサーは WebSocket をネイティブサポートしており、セッション維持の必要がある場合もロードバランサー設定で適切に動作させられます。したがってまずロードバランサーの設計を見直すことが適切です。\n\n📚 参考: https://cloud.google.com/compute/docs/load-balancing/http/"
  },
  {
    "id": "B49",
    "question": "あなたは、Google Compute EngineとCloud Bigtable上で動作する主要なクラウドサービスの拡張性をテストするために、QAチームが新しいロードテストツールを展開するのを手伝っています。\n\nどの3つの要件を含めるべきですか？(3つ選んでください)",
    "type": "multiple",
    "options": [
      {
        "id": "A",
        "text": "負荷テストツールによる再現のために、すべてのトランザクションを記録するよう、本番サービスに機能を組み込む"
      },
      {
        "id": "B",
        "text": "負荷テストツールが本番環境に対して定期的に実行されるようスケジュールする"
      },
      {
        "id": "C",
        "text": "負荷テストツールおよび対象サービスに、詳細なロギングおよびメトリクスの収集機能を持たせる"
      },
      {
        "id": "D",
        "text": "負荷テストでCloud Bigtableの性能が検証されていることを確認する。"
      },
      {
        "id": "E",
        "text": "サービスが使用するすべてのサードパーティシステムが高負荷に対応できることを確認する"
      },
      {
        "id": "F",
        "text": "負荷テストの環境として、別のGoogle Cloudプロジェクトを作成する。"
      }
    ],
    "answer": ["C", "D", "F"],
    "explanation": "負荷テストにおける正しい要件は以下の3つ：\n- 詳細なメトリクスとロギングにより分析性と再現性を確保（C）\n- Cloud Bigtableの性能確認も含めて本番相当の実装性能を検証（D）\n- 権限や設定の分離のために独立したプロジェクトで検証を実施（F）\n\n📚 参考: https://cloud.google.com/bigtable/docs/performance"
  },
  {
    "id": "B50",
    "question": "あなたのチームは、視聴者、商品購入者、シーズンチケット保有者への請求に使用されるカード番号のために、支払いカードデータの保管システムの作成を担当しています。以下の要件を満たすカスタムカードトークナイゼーションサービスを実装する必要があります：\n\n- 最小限のコストで低遅延を実現すること\n- 重複したクレジットカードを識別でき、平文のカード番号を保存しないこと\n- 年1回の鍵のローテーションに対応していること\n\nトークン化サービスには、どのようなストレージ アプローチを採用すべきでしょうか。",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "データストアモードを使用して、Firestoreに保存された決定論的アルゴリズムでカードデータを暗号化する。"
      },
      {
        "id": "B",
        "text": "クエリを実行して重複を確認した後、カードデータをSecret Managerに保存する。"
      },
      {
        "id": "C",
        "text": "カードデータを決定論的アルゴリズムで暗号化し、複数のMemorystoreインスタンスにシャードする。"
      },
      {
        "id": "D",
        "text": "列レベルの暗号化を使用して、Cloud SQLにデータを保存する"
      }
    ],
    "answer": ["A"],
    "explanation": "Firestore（Datastore モード）を使った決定論的暗号化は、重複検出・コスト効率・低レイテンシ・鍵ローテーション対応をすべて満たすために最適です。\n\n📚 参考: https://cloud.google.com/community/tutorials/pci-tokenizer"
  },
  {
    "id": "C01",
    "question": "あなたの開発チームは、モバイルゲームアプリを作成しました。この新しいモバイルアプリを、様々な設定のAndroidとiOSデバイスでテストしたいと考えています。テストを効率的かつ費用対効果の高いものにしなければなりません。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Google Kubernetes Engine（GKE）にAndroidとiOSのコンテナを作成し、コンテナにモバイルアプリをインストールして、モバイルアプリをテストする"
      },
      {
        "id": "B",
        "text": "Firebase Test Labにモバイルアプリをアップロードし、AndroidおよびiOSデバイスでモバイルアプリをテストする"
      },
      {
        "id": "C",
        "text": "異なる構成のモバイルアプリをFirebase Hostingにアップロードし、それぞれの構成をテストする"
      },
      {
        "id": "D",
        "text": "Google Cloud上にAndroidとiOSのVMを作成し、VM上にモバイルアプリをインストールして、モバイルアプリをテストする"
      }
    ],
    "answer": ["B"],
    "explanation": "Firebase Test Labは、クラウドベースのモバイルアプリテストサービスであり、AndroidおよびiOSデバイスでの自動およびカスタムテストをサポートします。物理デバイスや仮想デバイスでの広範囲なテストが可能なため、コストと効率の両面で優れています。\n\n📚 参考: https://firebase.google.com/docs/test-lab"
  },
  {
    "id": "C02",
    "question": "最近アップデートしたGoogle App Engineアプリケーションのロードに約30秒かかるという報告を一部のユーザーから受けています。この現象は、アップデート前には報告されていませんでした。\n\nどのような対策をとるべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "安定稼働していたリリースにロールバックしてから、静かな時期に再度リリースをプッシュして調査する。その後、Cloud Trace and Logging を使用して問題を診断する"
      },
      {
        "id": "B",
        "text": "サポートチケットを開き、問題を診断するためにネットワークキャプチャとフローデータを要求し、アプリケーションをロールバックする"
      },
      {
        "id": "C",
        "text": "ユーザーのISPと協力して問題を診断する"
      },
      {
        "id": "D",
        "text": "安定稼働していたリリースにロールバックし、Cloud Trace and Logging を使用して開発/テスト/ステージング環境で問題を診断する"
      }
    ],
    "answer": ["D"],
    "explanation": "App Engineアプリケーションのパフォーマンス劣化がアップデート後に発生したため、まずは安定していたバージョンへロールバックするのが合理的です。さらに、Cloud Operationsツールを使って原因を特定すべく、開発やテスト環境で再現性を確認しながら診断します。\n\n📚 参考: https://cloud.google.com/logging"
  },
  {
    "id": "C03",
    "question": "GCP上のコンピューティングリソースで信頼性の高いタスクスケジューリングをサポートすることで、アプリケーションとオペレーションの信頼性を確保する必要があります。\n\nGoogleのベストプラクティスを参考に、どのように実装をすればよいでしょうか。",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "App Engineが提供するCronサービスを使って、Cloud Pub/Subトピックにメッセージを発行する。Compute Engineインスタンス上で動作するメッセージ処理ユーティリティサービスを使って、そのトピックにサブスクライブする。"
      },
      {
        "id": "B",
        "text": "GKEが提供するCronサービスを使用して、Cloud Pub/Subトピックにメッセージを発行する。Compute Engineインスタンス上で動作するメッセージ処理ユーティリティサービスを用いて、そのトピックにサブスクライブする"
      },
      {
        "id": "C",
        "text": "Google Kubernetes Engine (GKE)が提供するCronサービスを使って、Compute Engineインスタンス上で動作するメッセージ処理ユーティリティサービスに、直接メッセージを発行する。"
      },
      {
        "id": "D",
        "text": "App Engineが提供するCronサービスを使って、Compute Engineインスタンス上で動作するメッセージ処理ユーティリティサービスに直接メッセージを発行する。"
      }
    ],
    "answer": ["A"],
    "explanation": "App Engine Cron + Cloud Pub/Sub + Compute Engineの構成は、Googleが推奨する信頼性の高いスケジューリング方式です。Cloud SchedulerのようなマネージドサービスとPub/Subを活用することで、オートスケーリング構成における分散タスクの確実な実行を可能にします。\n\n📚 参考: https://cloud.google.com/solutions/reliable-task-scheduling-compute-engine"
  },
  {
    "id": "C04",
    "question": "あなたのオペレーションチームは現在、10TBのデータをサードパーティのオブジェクトストレージサービスに保存しています。Googleが推奨する方法で、このデータをできるだけ早くCloud Storageのバケットに移行したいと考えています。また、このデータ移行にかかるコストを最小限に抑えたいと考えています。\n\nどのようなアプローチをとるべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "オンプレミスのデータセンターにデータをダウンロードして、Cloud Storageのバケットにアップロードする"
      },
      {
        "id": "B",
        "text": "gsutil mvコマンドでデータを移動する"
      },
      {
        "id": "C",
        "text": "Storage Transfer Service を使用してデータを移動する"
      },
      {
        "id": "D",
        "text": "Transfer Applianceにデータをダウンロードして、Googleに出荷する"
      }
    ],
    "answer": ["C"],
    "explanation": "Storage Transfer Serviceは、他クラウドやオンプレミスからCloud Storageへのデータ移行を高速かつ低コストで行えるフルマネージドサービスです。10TB程度のデータにはTransfer Applianceはオーバースペックであり、ネットワーク転送が現実的です。\n\n📚 参考: https://cloud.google.com/storage-transfer-service"
  },
  {
    "id": "C05",
    "question": "お客様の会社では、Compute Engine上で動作するエンタープライズアプリケーションがあり、高可用性と高パフォーマンスが求められています。このアプリケーションは、同じリージョンの2つのゾーンにある2つのインスタンスに、アクティブ - パッシブモードで展開されています。このアプリケーションは、データを永続ディスクに書き込みます。1つのゾーンで障害が発生した場合、そのデータは他のゾーンにあるもう1つのインスタンスですぐに利用できるようにする必要があります。あなたは、ダウンタイムとデータ損失を最小限に抑えながら、パフォーマンスを最大化したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "1.最初のインスタンスにパーシステントSSDディスクを装着する。\n2.1時間ごとにスナップショットを作成する。\n3.ゾーン障害が発生した場合、作成したスナップショットからデータが来る2つ目のインスタンスにパーシステントSSDディスクを再作成する。"
      },
      {
        "id": "B",
        "text": "1.リージョナル SSD 永続ディスクを 1 つ目のインスタンスに取り付けます。\n2. ゾーン障害が発生した場合、ディスクをもう一方のインスタンスに強制的に取り付けます。"
      },
      {
        "id": "C",
        "text": "1.最初のインスタンスのディスクに、ローカルSSDを取り付けます。\n2. 1時間ごとにrsyncコマンドを実行する。ターゲットは、2番目のインスタンスに接続された永続的なSSDディスクです。\n3. ゾーンが停止した場合には、2つ目のインスタンスを使用する。"
      },
      {
        "id": "D",
        "text": "1.Cloud Storageのバケットを作成する。\n2. gcs-fuse を使ってバケットを 1 つ目のインスタンスにマウントする。\n3. ゾーン障害が発生した場合は、Cloud Storageのバケットを gcs-fuse で 2 番目のインスタンスにマウントする。"
      }
    ],
    "answer": ["B"],
    "explanation": "リージョンSSD永続ディスクは、同一リージョン内の2ゾーンにレプリケーションされ、高可用性・低レイテンシ・自動フェイルオーバーに対応。--force-attachで障害時にスタンバイへ即時移行可能です。\n\n📚 参考: https://cloud.google.com/compute/docs/disks/repd-failover"
  },
  {
    "id": "C06",
    "question": "あなたの会社は、小売店向けのレコメンデーションエンジンを提供しています。あなたは、小売顧客がユーザーIDを送信すると、APIがそのユーザーに対するレコメンデーションのリストを返すAPIを提供しています。あなたはAPIのライフサイクルに責任を持ち、APIが後方互換性のない変更を行った場合に備えて、顧客の安定性を確保したいと考えています。またGoogleが推奨するプラクティスに従いたいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "古いAPIを新しいAPIに置き換える少なくとも1ヶ月前に、すべてのお客様の配布リストを作成し、今後の後方互換性のない変更についてお知らせする。"
      },
      {
        "id": "B",
        "text": "後方互換性のない変更のたびに、現在のAPIのバージョン番号にDEPRECATEDという接尾辞を付加するAPIのバージョン戦略を使用する。新しいAPIには現在のバージョン番号を使用する。"
      },
      {
        "id": "C",
        "text": "APIドキュメントを生成する自動プロセスを作成し、APIの更新をデプロイする際にCI/CDプロセスの一部として公開APIドキュメントを更新する。"
      },
      {
        "id": "D",
        "text": "後方互換性のない変更ごとにバージョン番号を増加させるAPIのバージョン管理戦略を使用する。"
      }
    ],
    "answer": ["D"],
    "explanation": "APIの後方互換性を保ちつつ安定性を維持するには、メジャーバージョンのインクリメントによる明確なAPIバージョン管理が必要です。Googleの設計原則においても、破壊的変更時は必ず新バージョンとしてリリースすることが推奨されています。\n\n📚 参考: https://cloud.google.com/apis/design/versioning"
  },
  {
    "id": "C07",
    "question": "開発チームは、あなたにKubernetes Deploymentファイルを提供しました。あなたはまだインフラを持っていませんがアプリケーションをデプロイする必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "kubectl を使用して Kubernetes クラスタを作成する。kubectl を使用してデプロイメントを作成する。"
      },
      {
        "id": "B",
        "text": "kubectl を使用して Kubernetes クラスタを作成する。Deployment Manager を使用してデプロイメントを作成する。"
      },
      {
        "id": "C",
        "text": "gcloud を使用して Kubernetes クラスタを作成する。kubectl を使用してデプロイメントを作成する。"
      },
      {
        "id": "D",
        "text": "gcloud を使用して Kubernetes クラスタを作成する。Deployment Managerを使用して、デプロイメントを作成する。"
      }
    ],
    "answer": ["C"],
    "explanation": "まだクラスタが存在していないため、gcloud でクラスタを作成する必要があります。その後、kubectl で Deployment を適用するのが標準のワークフローです。\n\n📚 参考: https://cloud.google.com/kubernetes-engine/docs/how-to/creating-a-zonal-cluster"
  },
  {
    "id": "C08",
    "question": "あなたの会社は、オンプレミスのユーザー認証用PostgreSQLデータベースのバックアップレプリカをGoogle Cloud Platform上に構築することにしました。データベースは4TBで、大規模な更新が頻繁に行われます。レプリケーションにはプライベートアドレス空間での通信が必要です。\n\nあなたはどのネットワークアプローチを使用する必要がありますか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "データセンターのネットワークに接続されたGoogle Cloud VPN"
      },
      {
        "id": "B",
        "text": "Google Cloud 専用Interconnect"
      },
      {
        "id": "C",
        "text": "VPNサーバーがインストールされたGoogle Compute Engineインスタンスをデータセンターのネットワークに接続する"
      },
      {
        "id": "D",
        "text": "オンプレミスに設置されたNATとTLSの変換ゲートウェイ"
      }
    ],
    "answer": ["B"],
    "explanation": "4TBかつ更新が多いワークロードには、高帯域・低遅延・プライベートIP対応の専用Interconnectが最適です。VPNはスループットが制限され、TLSゲートウェイなどでは安定性・一貫性が不足します。\n\n📚 参考: https://cloud.google.com/interconnect/docs/details/dedicated"
  },
  {
    "id": "C09",
    "question": "あなたは、Compute Engine VMからの公共のインターネットアクセスが許可されていない、高度なセキュリティ環境で作業しています。オンプレミスのファイルサーバーにアクセスするためのVPN接続がまだありません。一方で、特定のソフトウェアをCompute Engineインスタンスにインストールする必要があります。\n\nどのようにソフトウェアをインストールすればよいでしょうか。",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "必要なインストールファイルをCloud Storageにアップロードし、ファイアウォールルールを使用して、Cloud StorageのIPアドレス範囲以外のすべてのトラフィックをブロックする。gsutilを使ってファイルをVMにダウンロードする。"
      },
      {
        "id": "B",
        "text": "必要なインストールファイルをCloud Storageにアップロードする。VMをGoogle Accessのプライベートサブネットに設定する。VMには、内部IPアドレスのみを割り当てる。gsutilを使ってVMにインストールファイルをダウンロードする。"
      },
      {
        "id": "C",
        "text": "必要なインストール・ファイルをCloud Source Repositoriesにアップロードする。VMをGoogle Accessのプライベートサブネット上に設定する。VMには、内部IPアドレスのみを割り当てる。gcloudを使ってインストールファイルをVMにダウンロードする。"
      },
      {
        "id": "D",
        "text": "必要なインストールファイルをCloud Source Repositoriesにアップロードし、ファイアウォールルールを使用して、Cloud Source RepositoriesのIPアドレス範囲以外のすべてのトラフィックをブロックする。gsutilを使ってファイルをVMにダウンロードする。"
      }
    ],
    "answer": ["B"],
    "explanation": "プライベート サービス アクセスを構成すれば、Compute Engine VMは外部IPを持たずにCloud Storageへアクセスできます。gsutilも使用可能です。\n\n📚 参考: https://cloud.google.com/vpc/docs/configure-private-services-access"
  },
  {
    "id": "C10",
    "question": "貴社はヘルスケア関連の新興企業を買収したため、顧客の医療情報を作成時期に応じて最大4年以上保持しなければなりません。あなたの会社の方針は、このデータを安全に保持し、規則の期限が過ぎたらすぐに削除することです。\n\nどのようなアプローチを取るべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud Storageにデータを保存し、期限切れのデータをすべて削除するバッチスクリプトを毎晩実行する。"
      },
      {
        "id": "B",
        "text": "Google Driveにデータを保存し、有効期限が切れたレコードを手動で削除する。"
      },
      {
        "id": "C",
        "text": "Cloud Storageにデータを保存し、ライフサイクル管理を使用して期限切れになったファイルを削除する。"
      },
      {
        "id": "D",
        "text": "Cloud Data Loss Prevention APIを使用してデータを匿名化し、無期限に保存する。"
      }
    ],
    "answer": ["C"],
    "explanation": "Cloud Storage のライフサイクル管理を利用することで、指定した期間が経過したファイルを自動的に削除できます。医療データの法的保持義務とコスト管理の両立が可能です。\n\n📚 参考: https://cloud.google.com/storage/docs/lifecycle"
  },
  {
    "id": "C11",
    "question": "リクエストされたURLのパスに基づいて、グローバルなロードバランシングを行うソリューションを設計する必要があります。Googleのベストプラクティスに基づいて、運用の信頼性とエンドツーエンドの転送中の暗号化を確保する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "URLマップを使ったクロスリージョンのロードバランサーを作成する。"
      },
      {
        "id": "B",
        "text": "グローバルフォワーディングルールを作成する。SSLプロキシのロードバランシングを設定する。"
      },
      {
        "id": "C",
        "text": "URL Mapsを使ってHTTPSロードバランサーを作成する。"
      },
      {
        "id": "D",
        "text": "適切なインスタンスグループとインスタンスを作成する。SSLプロキシのロードバランサーを設定する。"
      }
    ],
    "answer": ["C"],
    "explanation": "Google Cloud の HTTP(S) ロードバランサは URL Maps を利用して、URL パスごとのリクエストルーティングを可能にします。\nグローバルなHTTPS対応とパスベースの処理にはこれが最適です。\n\n📚 参考: https://cloud.google.com/load-balancing/docs/https/url-map"
  },
  {
    "id": "C12",
    "question": "あなたはCloud Shellを使用していて、数週間以内に使用するカスタムユーティリティをインストールする必要があります。\n\nデフォルトの実行パスにありセッションを超えて持続するようにするには、どこにファイルを保存すればよいでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "~/bin"
      },
      {
        "id": "B",
        "text": "Cloud Storage"
      },
      {
        "id": "C",
        "text": "/usr/local/bin"
      },
      {
        "id": "D",
        "text": "/google/scripts"
      }
    ],
    "answer": ["A"],
    "explanation": "Cloud Shell では、ユーザーのホームディレクトリ（~/）は永続ストレージにマウントされています。\n~/bin はデフォルトのPATHに含まれており、次回以降のセッションでも同じ場所からスクリプトが使用可能です。\n\n📚 参考: https://cloud.google.com/shell/docs/how-cloud-shell-works"
  },
  {
    "id": "C13",
    "question": "Google Kubernetes Engine （GKE） クラスタを Cloud Monitoring ワークスペースで監視しています。Site Reliability Engineer （SRE）として、インシデントが発生した場合は迅速に対処できるようになる必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "GKE ノードからメトリクスを収集し、これらのメトリクスを Pub/Sub トピックにパブリッシュし、データを BigQuery にエクスポートし、Data Studio ダッシュボードを作成するシェルスクリプトを記述する。"
      },
      {
        "id": "B",
        "text": "Cloud Monitoringのワークスペースで定義済みのダッシュボードを表示し、メトリクスを追加してアラートポリシーを作成する。"
      },
      {
        "id": "C",
        "text": "各インシデント用にCloud Monitoringワークスペースでカスタムダッシュボードを作成し、メトリクスを追加してアラートポリシーを作成する。"
      },
      {
        "id": "D",
        "text": "クラウド監視ワークスペースの定義済みダッシュボードをナビゲートし、カスタムメトリクスを作成し、Compute Engine インスタンスにアラートソフトウェアをインストールする。"
      }
    ],
    "answer": ["B"],
    "explanation": "Cloud Monitoring の定義済みダッシュボードを活用し、そこに必要なメトリクスとアラートポリシーを組み合わせることで、迅速な異常検知と対応が可能になります。\n\n📚 参考: https://cloud.google.com/monitoring/charts/predefined-dashboards"
  },
  {
    "id": "C14",
    "question": "GCPを利用したリモートリカバリーにおけるディザスターリカバリーのレジリエンスを検証する手順を作成する必要があります。本番環境はオンプレミスで運用されています。オンプレミスのネットワークとGCPのネットワークの間に、安全で冗長性のある接続を確立する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "専用 InterconnectがGCPにファイルをレプリケートできることを確認する。専用 Interconnectに障害が発生した場合、Cloud VPNがネットワーク間のセキュアな接続を確立できることを確認する。"
      },
      {
        "id": "B",
        "text": "Transfer Applianceが故障した場合に、Cloud VPNがネットワーク間に安全な接続を確立できることを確認する。"
      },
      {
        "id": "C",
        "text": "Transfer ApplianceがGCPにファイルを複製できることを確認する"
      },
      {
        "id": "D",
        "text": "専用 InterconnectがGCPにファイルをレプリケートできることを確認する。専用 Interconnectに障害が発生した場合、ダイレクトピアリングでネットワーク間の安全な接続を確立できることを確認する。"
      }
    ],
    "answer": ["A"],
    "explanation": "本番オンプレミス環境からのリモートリカバリー構成では、専用 Interconnect を利用した高速・安定な接続と、障害時には Cloud VPN による冗長接続を併用するのが推奨パターンです。\n\n📚 参考: https://cloud.google.com/hybrid-connectivity/"
  },
  {
    "id": "C15",
    "question": "あなたの会社は、アプリケーションの運用機能をアウトソーシングすることを決定しました。開発者がクラウドベースのアプリケーションの新バージョンを本番環境に簡単にステージングできるようにし、アウトソースされたオペレーションチームがステージングされたバージョンを本番環境に自律的にプロモートできるようにしたいと思います。このソリューションの運用にあたってはオーバーヘッドを最小限に抑えたいと考えています。\n\nどのGoogle Cloudサービスに移行するべきでしょうか？",
    "type": "single",
    "options": [
      { "id": "A", "text": "Google Kubernetes Engine" },
      { "id": "B", "text": "GKEオンプレミス" },
      { "id": "C", "text": "Compute Engine" },
      { "id": "D", "text": "Google App Engine" }
    ],
    "answer": ["D"],
    "explanation": "App Engineはサーバーレスで、オペレーションのオーバーヘッドを最小限に抑えつつ、ステージングと本番への自動プロモートが容易です。\n\n📚 参考: https://cloud.google.com/appengine/docs"
  },
  {
    "id": "C16",
    "question": "オペレーションチームのマネージャーから、J2EEアプリケーションをクラウドに移行する際に考慮すべき推奨プラクティスのリストを求められます。\n\nあなたはどの3つのプラクティスを推奨しますか？（3つ選択）",
    "type": "multiple",
    "options": [
      {
        "id": "A",
        "text": "自動テスト機能を備えた継続的インテグレーションツールをステージング環境に導入する"
      },
      {
        "id": "B",
        "text": "Cloud Dataflowをアプリケーションに統合し、リアルタイムメトリクスを取得する"
      },
      {
        "id": "C",
        "text": "MySQLから、Google Cloud DatastoreやBigtableなどのマネージドNoSQLデータベースに移行する"
      },
      {
        "id": "D",
        "text": "クラウドインフラストラクチャを確実にプロビジョニングするための自動化フレームワークの選択する"
      },
      {
        "id": "E",
        "text": "アプリケーションコードをGoogle App Engine上で動作するように移植する"
      },
      {
        "id": "F",
        "text": "Cloud Debuggerなどの監視ツールでアプリケーションを導入する"
      }
    ],
    "answer": ["A", "E", "F"],
    "explanation": "クラウド移行時のアプリケーションの最適化には、CI/CD導入（A）、App Engineへの移植（E）、Cloud Operationsによる監視強化（F）が推奨されます。\n\n📚 参考: https://cloud.google.com/appengine/docs/standard/java"
  },
  {
    "id": "C17",
    "question": "500TBのデータをGoogle Cloudに移行することになりました。現在利用可能なネットワーク帯域幅は1Gbpsです。保存先としてはCloud Storageを使用し、Googleが推奨する方法に従いたいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "データをTransfer Applianceに移する。Transfer Appliance Rehydratorを使用して、データをCloud Storageに復号する。"
      },
      {
        "id": "B",
        "text": "データを含む各サーバーに gsutil をインストールする。再開可能な転送を使用して、データをCloud Storageにアップロードする。"
      },
      {
        "id": "C",
        "text": "データを転送アプライアンスに移動させます。Cloud Dataprepを使用して、データをCloud Storageに復号する。"
      },
      {
        "id": "D",
        "text": "データを含む各サーバーに gsutil をインストールする。ストリーミング転送を使用してデータをCloud Storageにアップロードする。"
      }
    ],
    "answer": ["A"],
    "explanation": "1Gbps回線で500TBを転送すると約46日かかるため、Googleの推奨するオフライン物理移行手段であるTransfer Applianceが最適です。Transfer Appliance Rehydratorにより安全にCloud Storageへ復元可能です。\n\n📚 参考: https://cloud.google.com/blog/products/storage-data-transfer/introducing-transfer-appliance-in-the-eu-for-cloud-data-migration"
  },
  {
    "id": "C18",
    "question": "ある会社では、アプリケーションに保存されているデータの信頼性を担保することが、ビジネス上の主要な目的の1つです。アプリケーションのデータに対するすべての変更をログに記録したいと考えています。\n\nログの信頼性を検証するためには、どのようにログシステムを設計すればよいでしょうか。",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "SQLデータベースを使用し、ログテーブルを変更できる人を制限する"
      },
      {
        "id": "B",
        "text": "各ログエントリのJSONダンプを作成し、それをGoogle Cloud Storageに保存する"
      },
      { "id": "C", "text": "クラウドとオンプレミスで同時進行でログを書く" },
      {
        "id": "D",
        "text": "各タイムスタンプとログエントリにデジタル署名を行い、その署名を保存する"
      }
    ],
    "answer": ["D"],
    "explanation": "ログの信頼性を担保するには、ハッシュと秘密鍵によるデジタル署名を各ログに施し、署名の保存と検証を行うことで改ざん検出が可能になります。\n\n📚 参考: https://cloud.google.com/kms/docs/create-validate-signatures"
  },
  {
    "id": "C19",
    "question": "あなたは、スタートアップ企業が試験的にGoogle Cloudを使用することをサポートするために、ビジネスプロセスの分析と定義を行っています。一方で、この企業の製品に対する消費者の需要はまだわかりません。また上司からは、GCPサービスのコストを最小限に抑え、Googleのベストプラクティスを遵守するよう求められています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "無料期間およびコミットメント利用割引を利用する。サービスコスト管理に関するトレーニングをチームに提供する。"
      },
      {
        "id": "B",
        "text": "無料期間およびコミットメント利用割引を利用する。サービスコスト管理のためのスタッフを新たに配置する。"
      },
      {
        "id": "C",
        "text": "無料期間および継続利用割引を利用する。サービスコスト管理に関するトレーニングをチームに提供する。"
      },
      {
        "id": "D",
        "text": "無料期間および継続利用割引を活用する。サービスコスト管理のためのスタッフを新たに配置する。"
      }
    ],
    "answer": ["C"],
    "explanation": "消費者需要が不明瞭な初期フェーズでは、コミットメント利用割引よりも使用量に応じて自動で適用される継続利用割引（SUD）が適しています。また、コスト管理のスキルを既存チームに教育で付与することが、追加の人員を配置するよりもコスト効率が良好です。\n\n📚 参考: https://cloud.google.com/compute/docs/sustained-use-discounts"
  },
  {
    "id": "C20",
    "question": "あなたのチームの開発者の一人が、以下のDockerfileを使って、Google Container Engineにアプリケーションをデプロイしました。\nしかし、アプリケーションのデプロイに時間がかかりすぎていることがわかっています。\n\nFROM ubuntu:16.04\nCOPY . /src\nRUN apt-get update && apt-get install -y python python-pip\nRUN pip install -r requirements.txt\n\nあなたはこのDockerfileを最適化して、アプリケーションの機能に悪影響を与えることなく、デプロイ時間を短縮したいと考えています。\n\nあなたはどの2つのアクションを取るべきですか？（2つ選んでください。）",
    "type": "multiple",
    "options": [
      { "id": "A", "text": "pip実行後にPythonを削除する" },
      { "id": "B", "text": "requirements.txtから依存関係を削除する" },
      {
        "id": "C",
        "text": "Pythonやpipなどの依存パッケージをインストールしてからソースをコピーする"
      },
      {
        "id": "D",
        "text": "Google Container Engineのノードプールに大きなマシンタイプを使用する"
      },
      {
        "id": "E",
        "text": "Alpine Linuxのようなスリム化されたベースイメージを使用する"
      }
    ],
    "answer": ["C", "E"],
    "explanation": "Dockerイメージのビルド高速化には、キャッシュレイヤーの活用（依存関係→ソース順）と軽量なベースイメージの採用が有効です。Alpineは代表的なスリムOSであり、不要なサイズ増加を防ぎます。\n\n📚 参考: https://www.docker.com/blog/intro-guide-to-dockerfile-best-practices/"
  },
  {
    "id": "C21",
    "question": "あなたの顧客は、認証レイヤーのレジリエンステストを行いたいと考えています。このアプリケーションは、リージョンで管理されたインスタンスグループがパブリックREST APIを提供し、Cloud SQLインスタンスとの間で読み取りと書き込みを行うものです。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "災害シミュレーション演習を実施し、ゾーン内の全ての仮想マシンを停止させ、アプリケーションがどのように動作するかを確認する。"
      },
      {
        "id": "B",
        "text": "仮想マシンに侵入検知ソフトウェアを導入し、不正なアクセスを検知・記録する。"
      },
      {
        "id": "C",
        "text": "セキュリティ会社に依頼して、悪意のあるWebサイトのユーザ'の認証データを探すWebスクレーパーを実行してもらい、何か見つかった場合には通知してもらう。"
      },
      {
        "id": "D",
        "text": "マスターとは別のゾーンにあるCloud SQLインスタンスにリードレプリカを構成し、REST APIのKPIを監視しながら手動でフェイルオーバーをトリガーする。"
      }
    ],
    "answer": ["A"],
    "explanation": "アプリケーションのレジリエンス（回復力）を検証するには、インフラストラクチャ障害を模擬した災害シミュレーションを行うことが有効です。ゾーン内のVMを意図的に停止させ、システムがどのように対応するかを観察することで、フォールトトレランスや自動復旧能力を確認できます。\n\n📚 参考: https://cloud.google.com/solutions/scalable-and-resilient-apps"
  },
  {
    "id": "C22",
    "question": "ある企業では、既存のエンタープライズアプリケーションをオンプレミスのデータセンターからGoogle Cloud Platformに移行しようとしています。ビジネスオーナーは、ユーザーの混乱を最小限に抑えることを求めています。また、パスワードの保存に関しては、セキュリティチームの厳しい要求があります。\n\nどのような認証戦略を採用すべきでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "G Suite Password Sync を使用して、パスワードを Google に複製する"
      },
      {
        "id": "B",
        "text": "Google のパスワードを企業のパスワードと一致させるようにユーザに求める"
      },
      {
        "id": "C",
        "text": "Google Cloud Directory Sync ツールを使用して Google でユーザをプロビジョニングする"
      },
      {
        "id": "D",
        "text": "SAML 2.0 を使用して既存の ID プロバイダに認証を統合する"
      }
    ],
    "answer": ["D"],
    "explanation": "SAML 2.0 によるフェデレーション認証は、既存のIDプロバイダとの統合を可能にし、ユーザーに新しいパスワードの設定や運用変更を強いることなくセキュアなSSOを実現します。GCDSはユーザー属性の同期に用いますが、パスワード同期には対応していません。\n\n📚 参考: https://cloud.google.com/architecture/identity/federating-gcp-with-active-directory-synchronizing-user-accounts"
  },
  {
    "id": "C23",
    "question": "あなたの会社は他の会社を買収したばかりで、その会社の既存のGoogle Cloud環境をあなたの会社のデータセンターに統合するように依頼されています。調査の結果、新会社の仮想プライベートクラウド（VPC）で使用されているRFC 1918 IPレンジの一部が、あなたのデータセンターのIPスペースと重複していることがわかりました。\n\n接続を可能にし、接続が確立されたときにルーティングの競合が発生しないようにするためには、どうすればよいでしょうか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "新しいVPCからデータセンターへのCloud VPN接続を作成し、Cloud Routerを作成し、IP空間が重ならないように新しいIPアドレスを適用する。"
      },
      {
        "id": "B",
        "text": "新しいVPCからデータセンターへのCloud VPN接続を作成し、オーバーラップするIP空間をブロックするファイアウォールルールを適用する。"
      },
      {
        "id": "C",
        "text": "新しいVPCからデータセンターへのCloud VPN接続を作成し、Cloud Routerを作成し、カスタムルートアドバタイズメントを適用して重複するIPスペースをブロックする。"
      },
      {
        "id": "D",
        "text": "新しいVPCからデータセンターへのCloud VPN接続を作成し、Cloud NATインスタンスを作成して重複するIP空間にNATを実行する。"
      }
    ],
    "answer": ["A"],
    "explanation": "IPレンジの重複を避けるために、新たなVPCに変更し、Cloud VPN + Cloud Router を構成し、競合を回避する新しいIPアドレスレンジを適用します。\n\n📚 参考:\n- https://cloud.google.com/network-connectivity/docs/router/how-to/advertising-removing-routes\n- https://cloud.google.com/network-connectivity/docs/router/how-to/advertising-custom-ip"
  },
  {
    "id": "C24",
    "question": "あなたの会社は、Google Cloud上でデータレイクを設計しており、さまざまなソースから非構造化データを収集するために、さまざまな取り込みパイプラインを開発したいと考えています。データはGoogle Cloudに保存された後、いくつかのデータパイプラインで処理され、Webサイトのエンドユーザーに対するレコメンデーションエンジンを構築する予定です。ソースシステムから取得したデータの構造は、いつでも変更される可能性があります。データ構造が現在の処理パイプラインと互換性がない場合に備えて、再処理の目的でデータを取得したときとまったく同じように保存する必要があります。あなたはデータを取得した後のアーキテクチャを設計する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "データを処理パイプラインに送り、処理されたデータをBigQueryのテーブルに格納して再処理する。"
      },
      {
        "id": "B",
        "text": "データをBigQueryテーブルに格納する。テーブルからデータを取り出すための処理パイプラインを設計する。"
      },
      {
        "id": "C",
        "text": "処理パイプラインを通じてデータを送信し、処理されたデータを再処理のためにCloud Storageのバケットに保存する。"
      },
      {
        "id": "D",
        "text": "Cloud Storageのバケットにデータを保存する。バケットからデータを取り出すための処理パイプラインを設計する。"
      }
    ],
    "answer": ["D"],
    "explanation": "非構造化データは直接BigQueryには保存できず、Cloud Storage に原型のまま保存し、後続のパイプラインで処理するのが最適です。\n\n📚 参考:\n- https://cloud.google.com/blog/topics/developers-practitioners/map-storage-options-google-cloud\n- https://cloud.google.com/products/storage"
  },
  {
    "id": "C25",
    "question": "あなたの会社はGoogle Cloudを利用しています。組織の下にFinanceとShoppingのフォルダを持っています。開発チームのメンバーは、Googleグループに所属しています。開発チームグループには、組織のプロジェクト所有者ロールが割り当てられています。あなたは、開発チームがFinanceフォルダのプロジェクトにリソースを作成するのを防ぐよう権限設定をする必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "開発チームのグループにFinanceフォルダのProject Viewerロールを割り当て、開発チームのグループにShoppingフォルダのProject Ownerロールを割り当てる。"
      },
      {
        "id": "B",
        "text": "開発チームグループに、Shopping フォルダの Project Owner ロールのみを割り当てる。"
      },
      {
        "id": "C",
        "text": "開発チームグループにShoppingフォルダのProject Ownerロールを割り当て、開発チームグループのProject Ownerロールを組織から削除する。"
      },
      {
        "id": "D",
        "text": "開発チームのグループに、Finance フォルダの Project Viewer ロールのみを割り当てる。"
      }
    ],
    "answer": ["C"],
    "explanation": "IAM 権限は階層的に継承されるため、上位で与えたロールは下位にも適用されます。\n\nFinance フォルダへのアクセスを制限したい場合、まず組織レベルの Project Owner ロールを削除し、Shopping フォルダに対してのみ適切なロールを与える必要があります。\n\n📚 参考:\n- https://cloud.google.com/resource-manager/docs/creating-managing-folders"
  },
  {
    "id": "C26",
    "question": "あなたの会社では、1つの MySQL インスタンスで複数のデータベースを運用しています。特定のデータベースのバックアップを定期的に取る必要がある。バックアップアクティビティはできるだけ早く完了する必要があり、ディスクパフォーマンスに影響を与えることはできません。\n\nどのようにストレージを構成するべきでしょうか。",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "cronジョブを設定し、gcloudツールを使用して永続ディスクスナップショットを使用して定期的にバックアップを取る。"
      },
      {
        "id": "B",
        "text": "各仮想マシン（VM）インスタンスに追加の永続ボリュームを RAID10 アレイでマウントし、LVM を使用してスナップショットを作成し、Cloud Storage に送信する。"
      },
      {
        "id": "C",
        "text": "gcsfuse を使用して、Google Cloud Storage のバケットをボリュームとしてインスタンスに直接マウントし、mysqldump を使用してマウントされた場所にバックアップを書き込む。"
      },
      {
        "id": "D",
        "text": "ローカルSSDボリュームをバックアップ先としてマウントする。バックアップが完了したら、gsutilを使ってGoogle Cloud Storageにバックアップを移動する。"
      }
    ],
    "answer": ["D"],
    "explanation": "MySQL バックアップの際に本番ディスクのパフォーマンスに影響を与えたくない場合、ローカル SSD に一時保存してから GCS に転送する多階層アプローチが有効です。\n\nこれは処理速度と安全性の両方を確保できます。\n\n📚 参考:\n- https://cloud.google.com/compute/docs/instances/sql-server/best-practices#backing_up"
  },
  {
    "id": "C27",
    "question": "あなたは、クラスタの内部で完結する、異なるマイクロサービスを使用してアプリケーションを開発しています。各マイクロサービスに特定の数のレプリカを設定できるようにしたいと考えています。また、マイクロサービスのレプリカの数に関わらず、他のマイクロサービスから特定のマイクロサービスに統一的にアクセスできるようにしたいと考えています。このソリューションをGoogle Kubernetes Engineに実装する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "各マイクロサービスを「デプロイメント」として配置する。Ingress を使用してクラスタ内の Deployment を公開し、Ingress IP アドレスを使用してクラスタ内の他のマイクロサービスから Deployment のアドレスを指定する。"
      },
      {
        "id": "B",
        "text": "各マイクロサービスを「デプロイメント」として展開する。サービスを使用してクラスタ内でデプロイメントを公開し、クラスタ内の他のマイクロサービスからのアドレスにサービスのDNS名を使用する。"
      },
      {
        "id": "C",
        "text": "各マイクロサービスを「Pod」としてデプロイする。クラスタ内の Pod を Service を使用して公開し、Service の DNS 名を使用してクラスタ内の他のマイクロサービスからマイクロサービスのアドレスを指定する。"
      },
      {
        "id": "D",
        "text": "各マイクロサービスを「Pod」としてデプロイする。Ingressを使用してクラスタ内のPodを公開し、クラスタ内の他のマイクロサービスからPodのアドレスを指定するためにIngress IPアドレス名を使用する。"
      }
    ],
    "answer": ["B"],
    "explanation": "GKEではDeploymentでレプリカを管理し、Serviceを通じて各PodをDNS経由で統一的にアクセス可能にするのがベストプラクティスです。これによりスケーラブルかつ保守性の高いマイクロサービス間通信が可能になります。\n\n📚 参考:\n- https://kubernetes.io/docs/concepts/services-networking/service\n- https://cloud.google.com/kubernetes-engine/docs/concepts/service-discovery"
  },
  {
    "id": "C28",
    "question": "【ケーススタディ: TerramEarth】レガシーなモノリシックアプリケーションをいくつかのコンテナ化されたRESTfulなマイクロサービスに分解しました。これらのマイクロサービスをCloud Runで実行したいと考えています。また、顧客に対して低遅延で高可用性のあるサービスを提供したいと考えています。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud Runサービスを複数のリージョンにデプロイする。クラウドDNSで、サービスを指すレイテンシーベースのDNS名を作成する。"
      },
      {
        "id": "B",
        "text": "Cloud Runサービスを複数のアベイラビリティ・ゾーンにデプロイする。TCP/IPグローバルロードバランサーを作成する。そのバックエンドサービスにCloud Run Endpointsを追加する"
      },
      {
        "id": "C",
        "text": "Cloud Runサービスを複数のアベイラビリティーゾーンに展開する。サービスを指し示すCloud Endpointsを作成する。グローバルなHTTP(S) Load Balancingインスタンスを作成し、そのバックエンドにCloud Endpointsをアタッチする。"
      },
      {
        "id": "D",
        "text": "Cloud Runサービスを複数のリージョンにデプロイする。サービスを指すサーバーレスネットワークエンドポイントグループを作成する。グローバルHTTP(S)ロードバランシングインスタンスが使用するバックエンドサービスに、サーバーレスNEGを追加する。"
      }
    ],
    "answer": ["D"],
    "explanation": "Cloud Runはリージョンベースのサービスであり、グローバル負荷分散を実現するには、各リージョンにCloud Runをデプロイし、それらをサーバーレスNEG (Network Endpoint Group) を通じてHTTPSロードバランサに接続する構成が最適です。\n\n📚 参考:\n- https://cloud.google.com/load-balancing/docs/negs/serverless-neg-concepts\n- https://cloud.google.com/run/docs/multiple-regions"
  },
  {
    "id": "C29",
    "question": "あなたの会社は、低リスクでクラウドを試してみたいと考えています。約100TBのログデータをクラウドにアーカイブし、そこで利用できる分析機能をテストしたいと考えていますが、同時に長期的なディザスタリカバリのバックアップとしてデータを保持したいと考えています。\n\nあなたが取るべき2つのステップは？（2つ選択）",
    "type": "multiple",
    "options": [
      { "id": "A", "text": "Google Cloud SQLにログを読み込む" },
      { "id": "B", "text": "Google Cloud Bigtableにログを挿入する" },
      { "id": "C", "text": "Google Cloud Loggingにログを読み込む" },
      { "id": "D", "text": "Google BigQueryにログを読み込む" },
      {
        "id": "E",
        "text": "Google Cloud Storageにログファイルをアップロードする"
      }
    ],
    "answer": ["D", "E"],
    "explanation": "Cloud Storage は低頻度アクセス向けの Coldline ストレージクラスを提供し、長期的な災害復旧バックアップに最適です。\n\nBigQuery はフルマネージドなデータウェアハウスで、分析に最適です。Cloud Storage に保存したログデータをすぐにクエリできるため、低リスクかつ迅速にクラウド分析を試すことができます。\n\n**したがって正解は：**\n- Google BigQueryにログを読み込む（D）\n- Google Cloud Storageにログファイルをアップロードする（E）"
  },
  {
    "id": "C30",
    "question": "あなたはMySQLを使用するアプリケーションを、オンプレミスからGoogle Cloudに移行しています。このアプリケーションはCompute Engine上で動作し、Cloud SQLを使用します。アプリケーションのダウンタイムを最小限に抑え、顧客のデータを失うことなく、Compute Engineのデプロイメントに移行したいと考えています。また、最小限の変更でアプリケーションを移行したいと考えています。更に、カットオーバー戦略を決定する必要があります。\n\n要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud VPNを設定し、Compute EngineアプリケーションとオンプレミスのMySQLサーバーの間にプライベートネットワーク接続を提供する。\nオンプレミスのアプリケーションを停止する。\nmysqldumpを作成し、Cloud Storageにアップロード後、Cloud SQLにインポートする。\nアプリをCloud SQLとオンプレDB両方に対応させて起動する。"
      },
      {
        "id": "B",
        "text": "オンプレミスのアプリケーションを停止する。\nmysqldumpをCloud Storageにアップロードし、Cloud SQLにインポートする。\nCompute Engineでアプリケーションを起動する。"
      },
      {
        "id": "C",
        "text": "Cloud VPNを設定し、Compute EngineアプリケーションとオンプレミスのMySQL間に接続を確立する。\nCloud SQL にレプリカ構成を設定し、同期完了後に Cloud SQL を昇格し、Compute Engine アプリを再起動して切り替える。"
      },
      {
        "id": "D",
        "text": "Cloud SQL ProxyとMySQL Proxyを設定して、Cloud SQLにデータをインポートし、Compute Engineにアプリケーションを展開する。"
      }
    ],
    "answer": "C",
    "explanation": "**要件：** ダウンタイムを最小限に抑え、データ損失なしでCloud SQLに移行するには、MySQLレプリケーションを用いた移行が最適です。\n\nこのプロセスでは Cloud SQL をリードレプリカとして構成し、オンプレミスの MySQL サーバーと同期させた上で、最終的にスタンドアロン化（プロモート）して本番切り替えを行います。\n\n**したがって正解は：C**"
  },
  {
    "id": "C31",
    "question": "ニュースフィードのWebサービスは、Google App Engine上で次のようなコードを実行しています。負荷のピーク時には、ユーザーから「すでに見たニュース記事が表示される」という報告があります。この問題の最も可能性の高い原因は何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "キャッシュ機能を停止するには、HTTP Expires ヘッダーを -1 にする必要がある"
      },
      {
        "id": "B",
        "text": "キャッシュされないように、APIのURLを変更する必要がある"
      },
      {
        "id": "C",
        "text": "セッション変数がCloud Datastoreで上書きされている"
      },
      {
        "id": "D",
        "text": "セッション変数はインスタンス内のローカル変数である"
      }
    ],
    "answer": "D",
    "explanation": "コードを見てみると、セッション変数は1つのインスタンスの中に固有のローカル変数で、ユーザーのデータとそのユーザーが閲覧した記事が格納されます。負荷が高い場合、リクエストが別のインスタンスに送られると、そのインスタンスは履歴情報を持っていないため、「すでに見たニュース記事が表示される」現象が起こります。"
  },
  {
    "id": "C32",
    "question": "Google Compute Engineの仮想マシンからGoogle BigQueryに接続するためのPythonスクリプトを記述します。スクリプトは、BigQueryに接続できないというエラーを出力しています。スクリプトを修正するにはどうすればよいですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "BigQuery のアクセススコープを有効にした新しい仮想マシンでスクリプトを実行する"
      },
      {
        "id": "B",
        "text": "最新の BigQuery API クライアントライブラリ（Python 用）をインストールする"
      },
      {
        "id": "C",
        "text": "gcloud components install bq というコマンドで、gcloud 用の bq コンポーネントをインストールする"
      },
      {
        "id": "D",
        "text": "BigQuery のアクセス権を持つ新しいサービスアカウントを作成し、そのユーザーでスクリプトを実行する"
      }
    ],
    "answer": "D",
    "explanation": "サービスアカウントをVMに割り当てることがGCPにおけるベストプラクティスです。アクセススコープはレガシーであり、IAM権限のあるサービスアカウントを割り当てる方が推奨されます。"
  },
  {
    "id": "C33",
    "question": "Google Cloud でデータウェアハウスを設計しており、機密データを BigQuery に保存したいと考えています。会社は、暗号化キーをGoogle Cloudの外で生成することを要求しています。要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud KMS で新しいキーを生成する。customer-managed key オプションを使用して BigQuery でデータセットを作成し、作成したキーを選択する。"
      },
      {
        "id": "B",
        "text": "Cloud Key Management Service (Cloud KMS) で新しいキーを生成する。customer-managed keyオプションを使用してすべてのデータをCloud Storageに保存し、作成したキーを選択する。Dataflow・パイプラインをセットアップして、データを復号化し、新しいBigQueryデータセットに保存する。"
      },
      {
        "id": "C",
        "text": "Cloud KMS でキーをインポートする。顧客が提供するキーオプションを使用して BigQuery でデータセットを作成し、作成したキーを選択する。"
      },
      {
        "id": "D",
        "text": "Cloud KMS でキーをインポートする。customer-managed keyオプションを使用してすべてのデータをCloud Storageに保存し、作成したキーを選択する。データを復号化し、新しい BigQuery データセットに保存するための Dataflow パイプラインを設定する。"
      }
    ],
    "answer": "C",
    "explanation": "Cloud KMS で顧客が外部生成したキーをインポートし、それを BigQuery で CMEK（Customer-Managed Encryption Keys）として使用するのが、顧客の要件（Google Cloud外で生成された鍵を使う）を満たす方法です。"
  },
  {
    "id": "C34",
    "question": "あなたは、LinuxベースのアプリケーションをプライベートデータセンターからGoogle Cloudに移行しています。セキュリティチームから、最近のLinuxのCVE（Common Vulnerabilities and Exposures）について通知を受けました。これが移行に与える影響を理解するにはどうすればよいですか？（2つ選択）",
    "type": "multiple",
    "options": [
      {
        "id": "A",
        "text": "Google Cloud Platform Security Bulletins に掲載されている CVE情報を確認し、影響を把握する"
      },
      {
        "id": "B",
        "text": "Google CloudのディスカッショングループにCVEに関する質問を投稿し、説明を受ける"
      },
      {
        "id": "C",
        "text": "Google Cloud Status DashboardからCVEを読み、影響を理解する"
      },
      {
        "id": "D",
        "text": "Stack OverflowにCVEに関する質問を投稿し、説明を受ける"
      },
      {
        "id": "E",
        "text": "CVEに関するサポートケースを開き、サポートエンジニアとチャットする"
      }
    ],
    "answer": ["A", "E"],
    "explanation": "CVEの影響を把握するには、Google Cloudのセキュリティブリテン（Security Bulletins）を確認することと、サポートケースを開いて公式のエンジニアと相談するのが最適です。他の手段は信頼性や公式性に欠けます。"
  },
  {
    "id": "C35",
    "question": "あなたは、バックエンドにいくつかのCloud Functionを使用する新しいアプリケーションの構築を開始します。あるユースケースでは、Cloud Function func_displayが別のCloud Function func_queryを呼び出す必要があります。この時、func_displayからの呼び出しをfunc_queryだけが受け付けるようにする必要があります。また、Googleの推奨するベストプラクティスにも従いたいと考えています。要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "func_queryを「認証を必須にする」ようにする。固有のサービスアカウントを作成し、それをfunc_displayに関連付ける。func_queryにサービスアカウントのinvokerロールを付与する。func_displayにidトークンを作成し、func_queryの起動時にそのトークンをリクエストに含める"
      },
      {
        "id": "B",
        "text": "トークンを作成し、環境変数としてfunc_displayに渡する。func_queryを起動するときに、リクエストにトークンを含める。同じトークンをfunc_queryに渡し、トークンが異なる場合は呼び出しを拒否する"
      },
      {
        "id": "C",
        "text": "これらの2つのFunctionを同じプロジェクトとVPCに作成する。func_queryが内部トラフィックのみを受け入れるようにする。func_queryには、func_displayからのトラフィックのみを許可するingressファイアウォールを作成する。また、両方のFunctionが同じサービスアカウントを使用するようにする"
      },
      {
        "id": "D",
        "text": "func_queryを「認証を必須にする」ようにして、内部トラフィックのみを受け付けるようにする。この2つのFunctionを同じVPC内に作成する。func_queryにingressファイアウォールルールを作成し、func_displayからのトラフィックのみを許可する"
      }
    ],
    "answer": "A",
    "explanation": "特定のCloud Function間の安全な通信には、呼び出し元Functionのサービスアカウントに対して、呼び出し先FunctionにInvokerロールを付与し、IDトークンを使って認証させるのがGoogleのベストプラクティスです。"
  },
  {
    "id": "C36",
    "question": "あなたの会社はクラウドへの移行に成功し、業務を最適化するためにデータストリームを分析したいと考えています。現在この分析のための既存のコードがないため、あらゆる選択肢を検討しています。これらのオプションには、バッチ処理とストリーム処理の組み合わせが含まれています。要件を達成するためにどのサービスを使うべきですか？",
    "type": "single",
    "options": [
      { "id": "A", "text": "Google Compute Engine, Google BigQuery" },
      { "id": "B", "text": "Google Cloud Dataflow" },
      { "id": "C", "text": "Google Cloud Dataproc" },
      { "id": "D", "text": "Google Container Engine, Bigtable" }
    ],
    "answer": "B",
    "explanation": "Cloud Dataflowはバッチ処理とストリーム処理の両方に対応するフルマネージドのデータ処理サービスであり、今回の要件に最も適した選択肢です。"
  },
  {
    "id": "C37",
    "question": "VPC内のすべてのCompute Engineインスタンスは、特定のポートでActive Directoryサーバーに接続できる必要があります。インスタンスからのその他のトラフィックは許可されません。VPCのファイアウォールルールを使用してこれを強制したいと考えています。ファイアウォールルールはどのように設定すればよいでしょうか。",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "優先度 100 の egress ルールを作成して Active Directory トラフィックを許可する。すべてのインスタンスのすべてのトラフィックをブロックするために、優先度1000の暗黙の拒否のegressルールに依存する。"
      },
      {
        "id": "B",
        "text": "優先度1000のEgressルールを作成し、Active Directoryのトラフィックを許可する。すべてのインスタンスのすべてのトラフィックをブロックするために、優先度100の暗黙のdeny egressルールを利用する。"
      },
      {
        "id": "C",
        "text": "優先度100のEgressルールを作成し、すべてのインスタンスのすべてのトラフィックを拒否する。優先度1000の別のEgressルールを作成し、すべてのインスタンスのActive Directoryトラフィックを許可する。"
      },
      {
        "id": "D",
        "text": "優先度1000のEgressルールを作成し、すべてのインスタンスのすべてのトラフィックを拒否する。優先度100の別のEgressルールを作成し、すべてのインスタンスのActive Directoryトラフィックを許可する。"
      }
    ],
    "answer": "D",
    "explanation": "VPCファイアウォールでは、優先度の小さいルールが優先されます。特定のトラフィックを許可（Active Directory用）し、それ以外をブロックするには、まず優先度の高い（値が小さい）許可ルールを定義し、次にそれよりも優先度が低い（値が大きい）拒否ルールを定義します。"
  },
  {
    "id": "C38",
    "question": "あなたは、Compute Engine上で動作するアプリケーションを持っています。リージョンの障害が発生した場合に、アプリケーションを別のリージョンにフェイルオーバーさせるという災害復旧計画を考慮したアーキテクチャを設計する必要があります。要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "アプリケーションを2つのCompute Engineインスタンスグループに展開し、それぞれを別のプロジェクト、別のリージョンに配置する。最初のインスタンスグループでトラフィックを処理し、災害時にはHTTPロードバランシングサービスを使用してスタンバイインスタンスグループにフェイルオーバーする。"
      },
      {
        "id": "B",
        "text": "アプリケーションを2つのCompute Engineインスタンスグループにデプロイする。それぞれは同じプロジェクト内にあるが、異なるリージョンにデプロイする。最初のインスタンスグループでトラフィックを処理し、災害時にはHTTPロードバランシングサービスを使用してスタンバイインスタンスグループにフェイルオーバーする。"
      },
      {
        "id": "C",
        "text": "アプリケーションをCompute Engineインスタンスに配備する。災害時には、HTTPロードバランシングサービスを使用して構内のインスタンスにフェイルオーバーする。"
      },
      {
        "id": "D",
        "text": "アプリケーションを、同じプロジェクト内の、異なるリージョンにある2つのCompute Engineインスタンス上にデプロイする。トラフィックの処理には最初のインスタンスを使用し、災害時にはHTTPロードバランシングサービスを使用してスタンバイインスタンスにフェイルオーバーする。"
      }
    ],
    "answer": "B",
    "explanation": "災害復旧計画においては、耐障害性を高めるため、異なるリージョンにインスタンスグループを配置し、HTTP(S)ロードバランサを用いてフェイルオーバーを構成するのが推奨されるアーキテクチャです。"
  },
  {
    "id": "C39",
    "question": "Google Kubernetes Engine （GKE）で動作するアプリケーションがあります。この2週間で、アプリケーションの特定の部分が頻繁にエラーを返すという報告を顧客から受けました。現在、GKEクラスタではロギングやモニタリングのソリューションは有効になっていません。問題を診断したいがすることができず再現することもできないため、監視を有効化する必要があります。一方で、有効化するにあたってアプリケーションへの影響は最小限に抑えたいと考えています。要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Cloud Operations for GKE を有効にした新しい GKE クラスタを作成する。影響を受けるPodを新しいクラスターに移行し、それらのPodのトラフィックを新しいクラスターにリダイレクトする。GKE 監視ダッシュボードを使用して、影響を受ける Pod からのログを調査する。"
      },
      {
        "id": "B",
        "text": "GKEクラスターを更新してCloud Operations for GKEを使用し、Prometheusを展開する。アプリケーションがエラーを返すたびにトリガーするアラートを設定する。"
      },
      {
        "id": "C",
        "text": "GKE クラスタをアップデートして、Cloud Operations for GKE を使用するようにする。[GKE モニタリング] ダッシュボードを使用して、影響を受けるポッドからのログを調査する。"
      },
      {
        "id": "D",
        "text": "Cloud Operations for GKE を有効にした新しい GKE クラスターを作成し、Prometheus を展開する。影響を受けるPodを新しいクラスターに移行し、それらのPodのトラフィックを新しいクラスターにリダイレクトする。アプリケーションがエラーを返すたびにアラートが発生するように設定する。"
      }
    ],
    "answer": "C",
    "explanation": "Cloud Operations for GKE を既存クラスタに対して有効にすることで、アプリケーションを再デプロイせずにログやメトリクスを収集できます。影響を抑えるためには既存クラスタを更新し、GKE モニタリングダッシュボードを活用するのがベストプラクティスです。"
  },
  {
    "id": "C40",
    "question": "Mountkirk Gamesの新しいGoogle Cloudソリューションでは、Cloud Storageへのバッチファイル転送を最適化する必要があります。バッチファイルにはゲームの統計情報が含まれており、Cloud Storageにステージングされ、ETL（Extract Transform Load）ツールで処理される必要があります。要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "gsutilを使用して、ETLの最後の部分としてファイルをロードする"
      },
      { "id": "B", "text": "gsutilを使ってファイルを連続して一括移動する" },
      {
        "id": "C",
        "text": "gsutil を使用して、ファイルを並列に一括コピーする"
      },
      {
        "id": "D",
        "text": "ETLの最初の部分として、gsutilを使ってファイルを抽出する"
      }
    ],
    "answer": "C",
    "explanation": "gsutil -m cp を使用することで、複数のファイルを並列に高速転送でき、大量データのバッチアップロード時のパフォーマンスを最適化できます。これはCloud StorageでのETL前のステージングに適した方法です。"
  },
  {
    "id": "C41",
    "question": "EHRヘルスケアのビジネスと技術要件を考慮し、Google Kubernetes Engine (GKE) のネットワークアーキテクチャ設計で外部ネットワークへの露出を減らすには、どうすべきですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "マスター認証されたネットワークを有効にし、ファイアウォールルールを設定したパブリッククラスターを使用する"
      },
      {
        "id": "B",
        "text": "マスター認証されたネットワークが設定されたプライベートエンドポイントを持つプライベートクラスタを使用する"
      },
      {
        "id": "C",
        "text": "マスター認証されたネットワークが設定されたパブリックエンドポイントを持つプライベートクラスターを使用する"
      },
      {
        "id": "D",
        "text": "ファイアウォールルールとVPCルートを持つパブリッククラスターを使用する"
      }
    ],
    "answer": "B",
    "explanation": "GKE クラスタの外部露出を最小限に抑えるには、パブリックエンドポイントを無効にし、プライベートエンドポイントに認証されたネットワークのみからアクセス可能とするのがベストプラクティスです。EHRのようなセキュリティ重視のユースケースに適しています。"
  },
  {
    "id": "C42",
    "question": "サードパーティのアプリケーションをオンプレミスから Google Cloud に移行するにあたり、最小限のコストで最適な CPU とメモリ構成を決定するにはどうすべきですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "利用可能な最小のマシンタイプでインスタンステンプレートを作成し、平均CPU使用率を使ってオートスケールを構成する"
      },
      {
        "id": "B",
        "text": "CPUとメモリのオプションを変えた複数のCompute Engineインスタンスで高負荷テストを行い最適構成を決定する"
      },
      {
        "id": "C",
        "text": "App Engineフレキシブル環境を使い、オンプレミスのVMと同様のリソース設定でアプリを展開する"
      },
      {
        "id": "D",
        "text": "オンプレミスと同様の構成でCompute Engineを作成し、Ops Agentを使ってトラフィック負荷テスト後に最適サイズの推奨を参照する"
      }
    ],
    "answer": "D",
    "explanation": "最小コストで最適な構成を得るには、まず現在の構成と同様のVMを作成し、Cloud Monitoringで負荷を監視します。通常トラフィック下でのデータに基づくレコメンデーションを利用するのが、Google のベストプラクティスです。"
  },
  {
    "id": "C43",
    "question": "EHR Healthcareのネットワーク構成をアップグレードしてビジネスクリティカルな要件とセキュリティポリシーに準拠させるには、どのような対応が必要ですか？",
    "type": "single",
    "options": [
      { "id": "A", "text": "新しい専用 Interconnect接続を追加する" },
      { "id": "B", "text": "新しいCarrier Peering接続を追加する" },
      {
        "id": "C",
        "text": "専用Interconnect接続の帯域幅を100Gにアップグレードする"
      },
      { "id": "D", "text": "3つの新しいCloud VPN接続を追加する" }
    ],
    "answer": "A",
    "explanation": "EHRの要件には、オンプレミスとGoogle Cloud間で安全かつ高速な接続が求められています。これを満たすには、直接的な物理接続を提供する専用 Interconnect を新たに追加するのが最適です。"
  },
  {
    "id": "C44",
    "question": "あなたの会社はGoogle Cloud VPNを使ってオンプレミスのMySQLデータベースをGCPにレプリケートしていますが、レイテンシーとパケットロスの問題に直面しています。どう対応すべきですか？",
    "type": "single",
    "options": [
      { "id": "A", "text": "Google Cloud 専用 Interconnect を設定する" },
      { "id": "B", "text": "UDPを使用するようにレプリケーションを設定する" },
      {
        "id": "C",
        "text": "複製されたトランザクションをGoogle Cloud Pub/Subに送信する"
      },
      { "id": "D", "text": "VPN接続を追加し、負荷分散する" },
      {
        "id": "E",
        "text": "Google Cloud SQL を使用してデータベースを毎日リストアする"
      }
    ],
    "answer": "A",
    "explanation": "VPN接続ではスループットは改善できても、レイテンシーの根本的な解決にはなりません。専用 Interconnect を使えば、レイヤー2の低遅延・高信頼接続を確保でき、今回の問題に対処できます。"
  },
  {
    "id": "C45",
    "question": "組織内のインスタンスで外部IPアドレスの使用を、承認されたインスタンスのみに制限し、すべてのVPCにこのポリシーを適用したい場合、どうすべきですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "すべてのVPCでデフォルトルートを削除する。承認されたすべてのインスタンスを、インターネットゲートウェイへのデフォルトルートを持つ新しいサブネットに移動する。"
      },
      {
        "id": "B",
        "text": "カスタムモードで新しいVPCを作成する。承認されたインスタンスのために新しいサブネットを作成し、この新しいサブネットにインターネットゲートウェイへのデフォルトルートを設定する。"
      },
      {
        "id": "C",
        "text": "Cloud NATソリューションを導入し、外部IPアドレスの必要性を完全に排除する。"
      },
      {
        "id": "D",
        "text": "constraints/compute.vmExternalIpAccessを制約条件とする組織ポリシーを設定する。許可されたインスタンスをallowedValuesリストに列挙する。"
      }
    ],
    "answer": "D",
    "explanation": "組織ポリシー constraints/compute.vmExternalIpAccess を使うことで、外部IPアドレスを持てるVMを明示的に制限できます。allowedValues リストに許可インスタンスを追加することで要件を満たせます。"
  },
  {
    "id": "C46",
    "question": "Pub/SubからのメッセージをFilestoreに保存するKubernetesアプリケーションが、メッセージの処理に遅延しています。このI/O集中型の処理をスケーリングするにはどうすればよいですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "subscription/push_request_latenciesメトリックに基づいてKubernetesのオートスケーリング展開を構成する。"
      },
      {
        "id": "B",
        "text": "Kubernetes クラスタの作成時に --enable-autoscaling フラグを使用する。"
      },
      {
        "id": "C",
        "text": "kubectl autoscale deployment APP_NAME --max 6 --min 2 --cpu-percent 50 を使用して、Kubernetes のオートスケーリング展開を設定する。"
      },
      {
        "id": "D",
        "text": "subscription/num_undelivered_messagesメトリックに基づいてKubernetesのオートスケーリング展開を構成する。"
      }
    ],
    "answer": "D",
    "explanation": "subscription/num_undelivered_messages は未処理メッセージ数を示し、このメトリクスに基づくスケーリングはPub/Subバックログが原因の遅延を解消する最適な方法です。"
  },
  {
    "id": "C47",
    "question": "会社のセキュリティチームは、オンプレミスとGoogle Cloud間のVPN環境において、BigQueryを使用するプロジェクトのデータ流出を防ぎたいと考えています。悪意のあるインサイダーや偶発的な情報漏えいを防ぐために、どうすべきですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "VPC サービスコントロールを構成し、プライベート Google アクセスを構成する。"
      },
      {
        "id": "B",
        "text": "プライベート Google アクセスをオンプレミスのみに設定する。"
      },
      {
        "id": "C",
        "text": "サービス アカウントを作成し、BigQuery JobUserロールとStorage Readerロールを与え、他のすべての IAM アクセスを削除する。"
      },
      { "id": "D", "text": "プライベート Google アクセスを設定する。" }
    ],
    "answer": "A",
    "explanation": "VPC Service Controls は、BigQueryやCloud Storageなどのサービスに対してセキュリティ境界を作成することで、IAMに加えた多層的なデータ保護を提供します。プライベート Google アクセスと併用することで、オンプレミスやVPCからの安全なアクセスが可能になります。"
  },
  {
    "id": "C48",
    "question": "マーケティング部門が実施する大量アクセスが予想されるメールキャンペーンのため、運用管理の手間を抑えながら柔軟にスケール可能なインフラを選ぶ必要があります。どの2つの構成を推奨すべきですか？",
    "type": "multiple",
    "options": [
      {
        "id": "A",
        "text": "Google Container Engine クラスタを使用して Web サイトを提供し、データを永続ディスクに保存する"
      },
      {
        "id": "B",
        "text": "単一のCompute Engine仮想マシン（VM）を使用してWebサーバーをホストし、Google Cloud SQLでバックエンドを行う。"
      },
      {
        "id": "C",
        "text": "Google App Engineを使用してWebサイトを提供し、Google Cloud Datastoreを使用してユーザーデータを保存する"
      },
      {
        "id": "D",
        "text": "マネージドインスタンスグループを使用してWebサイトを提供し、Google Cloud Bigtableを使用してユーザーデータを保存する"
      }
    ],
    "answer": ["C", "D"],
    "explanation": "App Engineは運用負荷を軽減しながら自動スケーリング可能なプラットフォームであり、Cloud Datastoreとの組み合わせでクリック収集に適しています。MIGとBigtableの構成も高スケーラビリティと耐障害性を提供し、大量アクセスに対応できます。"
  },
  {
    "id": "C49",
    "question": "オンプレミス環境のファイルをCloud Storageにアップロードする必要があります。Cloud Storage上では、クライアントが用意した暗号化キーを使ってファイルを暗号化したいと考えています。要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "gsutil でバケットを作成し、フラグ --encryption-key で暗号化キーを指定する。gsutil を使用して、そのバケットにファイルをアップロードする。"
      },
      {
        "id": "B",
        "text": "暗号化キーを.boto設定ファイルに記述する。gsutilを使ってファイルをアップロードする。"
      },
      {
        "id": "C",
        "text": "gcloud config で暗号化キーを指定する。gsutilを使用して、そのバケットにファイルをアップロードする。"
      },
      {
        "id": "D",
        "text": "gsutilを使ってファイルをアップロードし、フラグ--encryption-keyを使って暗号化キーを指定する。"
      }
    ],
    "answer": "B",
    "explanation": "顧客提供の暗号鍵（CSEK）を使用してCloud Storageにファイルを暗号化する場合、gsutilの.boto設定ファイルに鍵を記述する必要があります。これにより、アップロード時にgsutilが自動的に指定された鍵を使用してファイルを暗号化します。"
  },
  {
    "id": "C50",
    "question": "開発者向けにAPIを改訂し、古いバージョンを維持しつつ、新しいAPIも試せるようにしたい。また、同じSSL証明書とDNSレコードを維持したい。要件を達成するにはどうすべきか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "古いAPIに、パスに基づいて新しいAPIにトラフィックを転送させる"
      },
      {
        "id": "B",
        "text": "新しいAPIの新しいエンドポイントを使用するように古いクライアントを再設定する"
      },
      {
        "id": "C",
        "text": "新しいバージョンのAPI用に新しいロードバランサーを設定する"
      },
      {
        "id": "D",
        "text": "ロードバランサーのバックエンドで、各APIパスに別々のバックエンドプールを使用する"
      }
    ],
    "answer": "D",
    "explanation": "HTTP(S)ロードバランサを使えば、同一のSSL証明書とDNS設定のもとで、URLパスごとに異なるバックエンドサービス（旧APIと新API）へトラフィックをルーティングできます。これにより、複数APIバージョンの共存とシームレスな移行が可能になります。"
  },
  {
    "id": "D1",
    "question": "リアルタイムで更新される天気図アプリケーションのパフォーマンスを最適化したいと考えています。データは、50,000個のセンサーが1秒間に10個の読み取り値を送信したもので、タイムスタンプとセンサーの読み取り値の形式で表示されます。このデータはどのストレージに保存すればよいのでしょうか？",
    "type": "single",
    "options": [
      { "id": "A", "text": "Google BigQuery" },
      { "id": "B", "text": "Google Cloud SQL" },
      { "id": "C", "text": "Google Cloud Bigtable" },
      { "id": "D", "text": "Google Cloud Storage" }
    ],
    "answer": "C",
    "explanation": "Google Cloud Bigtableは、低レイテンシーでの大量データの読み書きに適した、スケーラブルなNoSQLワイドカラムデータベースであり、リアルタイムかつ時系列データの取り扱いに向いています。天気センサーのようなIoTデータには理想的な選択肢です。"
  },
  {
    "id": "D2",
    "question": "開発インフラをオンプレミスの仮想マシンからGoogle Cloudに移行するにあたり、インスタンスは1日に何度も起動／停止を繰り返します。財務部門にコストの可視性を提供しながら、状態を保持した開発環境を構築するには、どの2つのステップを取るべきですか？",
    "type": "multi",
    "options": [
      {
        "id": "A",
        "text": "すべての永続ディスクに --auto-delete フラグを使用し、VMを終了させる"
      },
      {
        "id": "B",
        "text": "Google BigQuery の請求書のエクスポートとラベルを使用して、コストをグループに関連付ける"
      },
      {
        "id": "C",
        "text": "すべての状態をGoogle Cloud Storageに保存し、永続ディスクをスナップショットして、VMを終了させる"
      },
      {
        "id": "D",
        "text": "すべての永続ディスクに --no-auto-delete フラグを使用し、VM を停止する"
      },
      {
        "id": "E",
        "text": "すべての状態をローカルSSDに保存し、永続ディスクをスナップショットして、VMを終了させる"
      },
      {
        "id": "F",
        "text": "VM の CPU 使用率のラベルを適用して、BigQuery の請求書のエクスポートに含める"
      }
    ],
    "answer": ["B", "D"],
    "explanation": "永続ディスクを削除しないよう --no-auto-delete フラグを使えば、VMを停止してもデータを保持できます。また、BigQuery への請求書エクスポートとリソースへのラベル付けを活用すれば、部門別のコスト追跡が可能になります。これにより、開発環境の運用とコスト管理を効率的に両立できます。"
  },
  {
    "id": "D3",
    "question": "あなたの会社では、Anthosクラスターにアプリケーションを展開しています。会社のSREプラクティスによると、リクエストのレイテンシーが特定の閾値を超えた状態が一定時間続いた場合、アラートを出す必要があります。要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Anthos Config Managementをクラスターに設定し、SLOとアラートポリシーを定義するyamlファイルを作成する"
      },
      {
        "id": "B",
        "text": "Cloud Profilerを使用して、リクエストのレイテンシーを追跡し、カスタムメトリックに基づいてアラートポリシーを作成する"
      },
      {
        "id": "C",
        "text": "Anthos Service Meshをクラスタにインストールする。Google Cloud Consoleを使用してSLOを定義し、このSLOに基づいてアラートポリシーを作成する"
      },
      {
        "id": "D",
        "text": "Cloud Trace APIを有効にし、Cloud Monitoring Alertsでアラートを送信する"
      }
    ],
    "answer": "C",
    "explanation": "Anthos Service Meshを使えば、各サービスに対してSLOを定義し、Google Cloud Consoleからしきい値と期間に基づくアラートを設定できます。これにより、SREの要件を満たす信頼性の高い監視が可能になります。"
  },
  {
    "id": "D4",
    "question": "あなたの会社では、いくつかの重要なファイルをCloud Storageにアップロードする予定です。アップロード完了後に、アップロードされたコンテンツがオンプレミスのものと同一であるかどうかを確認したいと考えています。また、この確認作業にかかるコストと労力を最小限に抑えたいと考えています。要件を達成するためにするべきことは何ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "gsutil -m を使用してアップロードし、カスタムJavaアプリケーションでCRC32Cを計算して比較する"
      },
      {
        "id": "B",
        "text": "Linuxのshasumを使ってダイジェストを計算し、Cloud Storageからダウンロードして比較する"
      },
      {
        "id": "C",
        "text": "gsutil -m を使用してアップロードし、Linux diffで内容を比較する"
      },
      {
        "id": "D",
        "text": "gsutil -m でアップロードし、gsutil hash -c でローカルのCRC32Cハッシュを生成、gsutil ls -L でCloud Storage側と比較する"
      }
    ],
    "answer": "D",
    "explanation": "gsutil hash -c を使えばローカルファイルのCRC32Cを簡単に取得でき、gsutil ls -L でCloud Storage上のオブジェクトのCRC32Cを確認できます。両者を比較することで、データの整合性確認が低コストかつ容易に行えます。"
  },
  {
    "id": "D5",
    "question": "あなたの会社では、Google Network Intelligence Centerのファイアウォールインサイト機能を使用しています。Compute Engineインスタンスに複数のファイアウォールルールが適用されていますが、Firewall Insightsページにはログが表示されません。問題のトラブルシューティングのために何をすべきですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "ユーザーアカウントに compute.networkAdmin IAM ロールがあることを確認する"
      },
      {
        "id": "B",
        "text": "Google Cloud SDK を使ってファイアウォールログを確認する"
      },
      {
        "id": "C",
        "text": "監視対象のファイアウォールルールに対してファイアウォールルールロギングを有効にする"
      },
      { "id": "D", "text": "VPC のフローロギングを有効にする" }
    ],
    "answer": "C",
    "explanation": "Firewall Insights でルールの使用状況を確認するには、対象のファイアウォールルールでロギングを有効にする必要があります。ロギングが無効だとインサイトにデータが表示されません。"
  },
  {
    "id": "D6",
    "question": "大規模なCRMをCloud SQLで運用しています。ストレージの不足、CPU使用率の管理、レプリケーションの遅延（60秒以内）などの要件があります。これらの要件を満たすには、どのような設定が必要ですか？\n（三つ選択）",
    "type": "multiple",
    "options": [
      { "id": "A", "text": "インスタンスのストレージの自動増加を有効にする" },
      { "id": "B", "text": "memcachedを導入してCPU使用率を軽減する" },
      {
        "id": "C",
        "text": "CPU使用率が75%を超えたらCloud Monitoringアラートを作成し、より大きなマシンタイプに変更する"
      },
      {
        "id": "D",
        "text": "レプリケーションの遅延に対してCloud Monitoringアラートを作成し、データベースをシャード化して対応する"
      }
    ],
    "answer": ["A", "C", "D"],
    "explanation": "Cloud SQLの自動ストレージ増加、Cloud Monitoringアラートによる監視、インスタンスタイプのスケーリング、データベースのシャーディングは、可用性とスケーラビリティを確保するためのベストプラクティスです。memcachedの導入はこの文脈では最適解ではありません。"
  },
  {
    "id": "D7",
    "question": "アプリケーションサーバーVMからCloud Pub/Subへ機密トランザクションデータをプッシュしています。Googleが推奨する認証方法はどれですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "VMサービスアカウントがCloud Pub/Subへのアクセスを持っていないことを確認し、アクセススコープを使ってIAMロールを付与する"
      },
      {
        "id": "B",
        "text": "VMサービスアカウントに適切なCloud Pub/Sub IAMロールを付与する"
      },
      {
        "id": "C",
        "text": "OAuth2アクセストークンを生成し暗号化してCloud Storageに保存する"
      },
      {
        "id": "D",
        "text": "Cloud Functionをゲートウェイとして使い、そこにIAMロールを付与する"
      }
    ],
    "answer": "B",
    "explanation": "Google Cloudの推奨する方法は、各VMが割り当てられたサービスアカウントを使って必要なIAMロールで認証・認可することです。アクセストークン管理やCloud Function経由の迂回方法は非効率です。"
  },
  {
    "id": "D8",
    "question": "Cloud SQLをバックエンドに使うPHP App Engine Standardアプリケーションで、SQLクエリ数を最小限に抑えるにはどうすればよいですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "memcacheのサービスレベルをsharedにし、cronでcached_queriesキーに定期保存する"
      },
      {
        "id": "B",
        "text": "memcacheのサービスレベルを専用にし、クエリのハッシュからキーを作成し、memcacheから先に値を返す"
      },
      {
        "id": "C",
        "text": "memcacheのサービスレベルを専用にしてcronでキャッシュ投入する"
      },
      {
        "id": "D",
        "text": "memcacheのサービスレベルをsharedにし、cached_queries€キーを参照してクエリ結果を返す"
      }
    ],
    "answer": "B",
    "explanation": "最も効率的な方法は、専用memcacheを使用し、クエリのハッシュキーに基づいてキャッシュを先に参照し、該当がなければCloud SQLに問い合わせる方法です。これにより負荷とクエリ数が大きく削減されます。"
  },
  {
    "id": "D9",
    "question": "あなたの会社では物理的に分離されたハードウェアでワークロードを実行する必要があります。ノードグループを作成した上で、正しいノードにワークロードを展開するにはどうすればよいですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Compute Engineインスタンス作成時にノードグループ名に基づくノードアフィニティラベルを使用する"
      },
      {
        "id": "B",
        "text": "Compute Engineインスタンス作成時にノード名に基づくノードアフィニティラベルを使用する"
      },
      {
        "id": "C",
        "text": "Compute Engineインスタンス作成時にネットワークタグとしてノード名を追加する"
      },
      {
        "id": "D",
        "text": "Compute Engineインスタンス作成時にネットワークタグとしてノードグループ名を追加する"
      }
    ],
    "answer": "B",
    "explanation": "単一テナントノードにワークロードを割り当てるには、インスタンス作成時にノードの名前に基づいたノードアフィニティラベルを使用する必要があります。これはハードウェアレベルで物理的分離を保証するGoogle Cloudの仕組みです。"
  },
  {
    "id": "D10",
    "question": "GKEクラスタをus-central1に配置しています。アジアのユーザーのレイテンシを減らすにはどうすればよいですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "asia-southeast1に第2のGKEクラスタを作成し、LoadBalancer型のサービスで公開しDNSに登録する"
      },
      { "id": "B", "text": "クラスタ内のメモリとCPUを増やす" },
      {
        "id": "C",
        "text": "クラウドCDNを有効にしたグローバルHTTPロードバランサーを使う"
      },
      {
        "id": "D",
        "text": "asia-southeast1に第2のGKEクラスタを作成し、kubemciを使用してグローバルHTTP(s)ロードバランサーを作成する"
      }
    ],
    "answer": "D",
    "explanation": "Google CloudのグローバルHTTP(s)ロードバランサーとkubemciを使用することで、複数リージョンのGKEクラスタにまたがってトラフィックを自動で分散でき、アジア地域のレイテンシ低減に最適な構成となります。"
  },
  {
    "id": "D11",
    "question": "トラフィックが多い時間帯にリレーショナルデータベースのレプリカがマスターに昇格しなかった問題を今後回避するためには、何をすべきですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "より定期的にデータベースのスナップショットを作成する"
      },
      { "id": "B", "text": "データベースのフェイルオーバーを定期的に行う" },
      { "id": "C", "text": "別のデータベースを使用する" },
      { "id": "D", "text": "データベースのインスタンスを大きくする" }
    ],
    "answer": "B",
    "explanation": "レプリカの昇格失敗を避けるには、フェイルオーバーの動作検証が不可欠です。定期的なフェイルオーバーテストにより問題を早期に発見し、適切な対応が可能になります。"
  },
  {
    "id": "D12",
    "question": "GKE上で動作するマイクロサービスにおいて、クラッシュ時の動作を検証するにはどうすればよいですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "Istioのトラフィック管理機能を使って、クラッシュしたマイクロサービスからトラフィックを誘導する"
      },
      {
        "id": "B",
        "text": "Kubernetesノードにtaintを設定し、アンチアフィニティラベルで対象ポッドを配置しないようにする"
      },
      {
        "id": "C",
        "text": "Istioのフォールト・インジェクション機能を、不具合のある動作をシミュレートしたい特定のマイクロサービスに使用する"
      },
      {
        "id": "D",
        "text": "Kubernetesクラスタのノードの1つを破壊して挙動を観察する"
      }
    ],
    "answer": "C",
    "explanation": "Istioのフォールト・インジェクション機能は、遅延やエラーを意図的に発生させることで、アプリケーションの回復性や耐障害性をテストするのに最適な手段です。"
  },
  {
    "id": "D13",
    "question": "Kubernetes Engine上でマイクロサービスアーキテクチャを用いたアプリケーション開発において、developブランチへのコード変更が自動的にビルド・テスト・デプロイされ、かつそのプロセスに従っていることを保証するにはどうすればよいですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "開発ブランチにコードがプッシュされたときに、コードをテストしてコンテナをビルドするポストコミットフックをリモートリポジトリにインストールする。開発者が手動でデプロイする。"
      },
      {
        "id": "B",
        "text": "Cloud Buildトリガーを使ってdevelopブランチの変更でビルド・テスト・イメージ作成を自動化し、開発クラスターへの自動デプロイメントパイプラインを作成する。デプロイ権限はデプロイメントツールのみに与える。"
      },
      {
        "id": "C",
        "text": "脆弱性スキャンを含むCloud Buildプロセスを使って、開発ブランチの変更に基づいてコンテナをビルド・保存し、Cloud Buildから直接開発クラスタにデプロイする。"
      },
      {
        "id": "D",
        "text": "開発者のローカルにプリコミットフックを設定し、ビルド後に手動でクラスタへデプロイさせる。"
      }
    ],
    "answer": "B",
    "explanation": "Cloud Buildトリガーと自動デプロイメントパイプラインを組み合わせることで、継続的インテグレーションと継続的デリバリー（CI/CD）を実現できます。自動化と権限管理により、全コード変更の一貫性とセキュリティが確保されます。"
  },
  {
    "id": "D14",
    "question": "Compute Engine上で稼働するステートレスアプリケーションがピーク時に遅くなる問題を解消するために、どのような構成変更を行うべきですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "既存ディスクのスナップショットからインスタンステンプレートを作成し、それを使ってオートスケールのマネージドインスタンスグループを作成する"
      },
      {
        "id": "B",
        "text": "既存ディスクのスナップショットからカスタムイメージを作成し、それを元にマネージドインスタンスグループを構築する"
      },
      {
        "id": "C",
        "text": "既存のディスクからカスタムイメージを作成し、それからインスタンステンプレートを作成し、テンプレートを元にオートスケーリングのマネージドインスタンスグループを構築する"
      },
      {
        "id": "D",
        "text": "既存のディスクからインスタンステンプレートを直接作成し、そのテンプレートを使ってカスタムイメージを作成する"
      }
    ],
    "answer": "C",
    "explanation": "ステートレスアプリケーションの可用性とスケーラビリティを高めるには、カスタムイメージをベースとしたインスタンステンプレートと、オートスケーリング可能なマネージドインスタンスグループの構築が最適です。これにより即時スケーリングと高速起動が可能になります。"
  },
  {
    "id": "D15",
    "question": "Cloud Storage バケットに機密データを保存しており、規制対応のために使用する暗号化キーのローテーションが求められています。Googleの推奨に従うにはどうすればよいですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "AES-256 暗号化キーを生成し、お客様提供の暗号化キー機能（CSEK）を使ってバケットのデータを暗号化する"
      },
      {
        "id": "B",
        "text": "Cloud Key Management Service (KMS) で鍵を作成し、バケットの暗号化キーとして Cloud KMS キーを指定する"
      },
      {
        "id": "C",
        "text": "Cloud KMS の encrypt メソッドを使って手動でファイルを暗号化してからバケットにアップロードする"
      },
      {
        "id": "D",
        "text": "GPG キーを使ってデータを暗号化し、暗号化済みデータを Cloud Storage に保存する"
      }
    ],
    "answer": "B",
    "explanation": "Cloud KMS（CMEK）を使うことで、鍵のローテーションやアクセス制御を簡便に管理でき、Google Cloud のセキュリティベストプラクティスに合致します。"
  },
  {
    "id": "D16",
    "question": "Debian Linux ベースのアプリケーションを Google Cloud に展開する際、最小限の手動操作でアップデート対応を行うにはどのようにすべきですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "最新のDebianイメージを使ってCompute Engineインスタンステンプレートを作成し、アプリを起動スクリプトで設定する。アップデートごとにこの作業を繰り返す"
      },
      {
        "id": "B",
        "text": "Debianベースのインスタンスを作成し、アプリケーションを構成した後、OS Patch Managementを使って自動でパッチを適用する"
      },
      {
        "id": "C",
        "text": "最新のDebianイメージでインスタンスを作成し、SSHで手動構成し、Google が新しいイメージを出すたびに同じ作業を繰り返す"
      },
      {
        "id": "D",
        "text": "DebianベースのDockerイメージを作り、アプリを設定してGKEでホスティングし、更新ごとにコンテナを再構築・再起動する"
      }
    ],
    "answer": "B",
    "explanation": "OS Patch Management により、Google Cloud 上の VM へ自動で安全にセキュリティパッチを適用可能になり、手動操作の手間を最小限に抑えることができます。"
  },
  {
    "id": "D17",
    "question": "あなたの会社では、3つのリージョンにある1000の会議室で、毎秒センサーデータを送信するモーションセンサーを設置し、部屋の使用状況を追跡したいと考えています。データにはセンサーIDやロケーションなどの情報が含まれており、アナリストはユーザーや場所の情報と組み合わせて分析を行います。この用途に最も適したデータベースタイプはどれですか？",
    "type": "single",
    "options": [
      { "id": "A", "text": "Blobストア" },
      { "id": "B", "text": "NoSQL" },
      { "id": "C", "text": "リレーショナル" },
      { "id": "D", "text": "フラットファイル" }
    ],
    "answer": "B",
    "explanation": "センサーデータは構造が柔軟かつ大量で、時系列や非構造データが中心となるため、NoSQL（たとえば Bigtable など）のようなスケーラブルで柔軟なデータベースが最適です。"
  },
  {
    "id": "D18",
    "question": "データサイエンスチームの既存Hadoopジョブを、基盤構成の大幅な変更なしにGoogle Cloudへ移行したいと考えています。コストと運用管理の手間を最小限に抑えるにはどうすればよいですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "標準的なワーカーインスタンスを使用してDataprocクラスタを作成する"
      },
      {
        "id": "B",
        "text": "標準インスタンスを使ってCompute EngineにHadoopクラスタを手動で構築する"
      },
      {
        "id": "C",
        "text": "プリエンプト可能なインスタンスを使ってCompute EngineにHadoopクラスタを手動で構築する"
      },
      {
        "id": "D",
        "text": "プリエンプティブルワーカーインスタンスを使用して Dataproc クラスタを作成する"
      }
    ],
    "answer": "D",
    "explanation": "Dataproc は Hadoop ワークロードに最適なマネージドサービスであり、プリエンプティブルワーカーを用いることでコストをさらに削減できます。"
  },
  {
    "id": "D19",
    "question": "自社で運用するアプリケーションのリクエスト数に応じて、Google Kubernetes Engine クラスタを自動的にスケーリングしたいと考えています。最も適切な対応方法はどれですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "gcloud container clusters resize CLUSTER_NAME --size=10 を使ってノードを手動で追加する"
      },
      {
        "id": "B",
        "text": "gcloud compute instances add-tags INSTANCE --tags enable-autoscaling --max-nodes=10 でタグを追加する"
      },
      {
        "id": "C",
        "text": "gcloud container clusters update CLUSTER_NAME --enable-autoscaling --min-nodes=1 --max-nodes=10 を使ってクラスタを更新する"
      },
      {
        "id": "D",
        "text": "gcloud container clusters create CLUSTER_NAME --enable-autoscaling --min-nodes=1 --max-nodes=10 を使って新しいクラスタを作成する"
      }
    ],
    "answer": "C",
    "explanation": "すでに存在するクラスタに対してオートスケーリングを有効化するには、`gcloud container clusters update` コマンドを使用します。これにより、クラスタがリクエスト数に応じてノード数を自動調整できるようになります。"
  },
  {
    "id": "D20",
    "question": "インターネット上のサードパーティサービスへアクセスが必要な新しいアプリケーションを GKE クラスタ上に展開する予定です。ただし、セキュリティ方針により、Google Cloud 上の Compute Engine インスタンスにパブリック IP アドレスを持たせることは禁止されています。この条件を満たすためにはどの構成が適切ですか？",
    "type": "single",
    "options": [
      {
        "id": "A",
        "text": "GKE クラスタをルートベースのクラスタとして構成し、VPC にプライベート Google アクセスを構成する"
      },
      {
        "id": "B",
        "text": "GKE クラスタをプライベートクラスタとして構成し、VPC 上でプライベート Google アクセスを構成する"
      },
      {
        "id": "C",
        "text": "GKE クラスタをプライベートクラスタとして構成し、クラスタのサブネットに Cloud NAT Gateway を設定する"
      },
      {
        "id": "D",
        "text": "Compute Engine に NAT プロキシを構築し、すべてのトラフィックをそのプロキシ経由にする"
      }
    ],
    "answer": "C",
    "explanation": "Cloud NAT を使えば、パブリック IP を持たない GKE ノードや Pod がインターネットへ送信通信を行えるようになります。これは、セキュリティポリシーに準拠しつつ、外部サービスへのアクセスを可能にする推奨構成です。"
  }
]
